## 3유형의 핵심: '재판'으로 이해하는 가설 검정 ⚖️

모든 통계 검정은 "재판"입니다. 우리는 데이터라는 "증거"를 가지고 "용의자"를 재판대에 세웁니다.

  * **용의자:** 우리가 검증하고 싶은 가설 (예: "1등석과 3등석의 나이는 차이가 있다.")
  * **법정의 원칙 (무죄 추정):** **귀무가설 ($H_0$)**
      * "모든 것은 우연이며, 아무 차이도 없다." (예: "1등석과 3등석의 나이 평균은 같다.")
      * 이것이 우리가 \*\*기각(Rejection)\*\*시키고 싶은 대상입니다.
  * **검사의 주장 (우리의 주장):** **대립가설 ($H_1$)**
      * "우연이 아니다\! 여기엔 유의미한 차이가 있다\!" (예: "1등석과 3등석의 나이 평균은 다르다.")
  * **증거의 신뢰도:** **p-value (유의확률)**
      * 이것이 **가장 중요합니다.**
      * **p-value의 의미:** "귀무가설($H_0$)이 맞다(즉, 아무 차이가 없다)고 가정할 때, 지금 우리가 가진 이 데이터(증거)가 나올 확률"
      * **p-value가 낮다 (예: 0.01):** "아무 차이가 없는데 이런 데이터가 나올 확률이 1%라고? 말도 안 돼\! 이건 우연이 아니야\!"
      * **p-value가 높다 (예: 0.50):** "아무 차이가 없어도 이런 데이터는 50% 확률로 나올 수 있어. 충분히 우연일 수 있겠네."
  * **유죄 판결 기준:** **유의수준 ($\alpha$, alpha)**
      * "p-value가 이 기준보다 낮으면 유죄(대립가설 채택)로 판결하겠다\!"
      * 일반적으로 \*\*0.05 (5%)\*\*를 기준으로 씁니다.

### 📜 최종 판결 로직

> **`p-value <= 0.05` (5%보다 낮다)**
>
>   * "이 증거는 우연이라고 보기엔 너무 희귀하다\! (유의하다)"
>   * **판결:** **"귀무가설($H_0$)을 기각한다."**
>   * **결론:** 우리의 주장인 **대립가설($H_1$)을 채택**한다. (예: "두 집단의 나이 차이는 유의미하다\!")

> **`p-value > 0.05` (5%보다 높다)**
>
>   * "이 증거는 우연히 나올 수도 있다. (유의하지 않다)"
>   * **판결:** **"귀무가설($H_0$)을 기각하지 못한다."** (무죄 추정)
>   * **결론:** 대립가설을 채택할 근거가 부족하다. (예: "두 집단의 나이 차이가 있다고 말할 수 없다.")

-----

## 3유형 검정 '족보': 어떤 '재판'을 열어야 할까?

어떤 재판(검정)을 열지는 분석하려는 \*\*두 변수의 '타입'\*\*에 따라 결정됩니다.

| 변수 1 (X) | 변수 2 (Y) | 검정 방법 |
| :--- | :--- | :--- |
| **범주형 (2그룹)** | **수치형** | **t-검정 (t-test)** |
| **범주형 (3+그룹)**| **수치형** | **일원분산분석 (ANOVA)** |
| **범주형** | **범주형** | **카이제곱 검정 (Chi-squared)** |
| **수치형** | **수치형** | **피어슨 상관분석 (Pearson)** |

-----

## 1\. t-검정 (Independent t-test)

  * **🎯 언제 사용하나요?**
      * **"두 개의 그룹(범주형)"** 간의 \*\*"평균(수치형)"\*\*을 비교할 때.
  * **⚖️ 재판 비유:**
      * "타이타닉의 1등석 승객(`Pclass`=1)과 3등석 승객(`Pclass`=3)의 평균 나이(`Age`)는 다른가?"
      * $H_0$: "두 그룹의 평균 나이는 같다."
      * $H_1$: "두 그룹의 평균 나이는 다르다."
  * **❗ (필수) 사전 검토: 등분산 검정**
      * 본 재판(t-검정)을 열기 전, 두 그룹의 데이터가 얼마나 흩어져있는지(분산) 확인해야 합니다.
      * \*\*"두 그룹의 분산이 같은가?"\*\*를 먼저 검정합니다. (`scipy.stats.levene` 또는 F-검정)
      * 이 검정의 $H_0$: "두 그룹의 분산은 같다."
      * p-value \> 0.05 (분산이 같다) ➡️ `equal_var=True` 옵션
      * p-value \<= 0.05 (분산이 다르다) ➡️ `equal_var=False` 옵션
  * **🐍 Python 코드 예시:**
    ```python
    from scipy.stats import ttest_ind, levene

    # 1. 비교할 두 그룹의 'Age' 데이터 추출 (결측값 제거는 필수)
    group1 = df[df['Pclass'] == 1]['Age'].dropna()
    group3 = df[df['Pclass'] == 3]['Age'].dropna()

    # 2. (사전 검토) 레빈(Levene) 등분산 검정
    stat, p_levene = levene(group1, group3)
    print(f"등분산 검정 p-value: {p_levene}")

    is_equal_var = True # 기본값
    if p_levene <= 0.05:
        is_equal_var = False # 분산이 다르다고 판결

    # 3. (본 재판) t-검정 수행
    t_stat, p_value = ttest_ind(group1, group3, equal_var=is_equal_var)

    print(f"t-검정 p-value: {p_value}")
    if p_value <= 0.05:
        print("결론: 1등석과 3등석의 평균 나이는 유의미하게 다르다. (H0 기각)")
    else:
        print("결론: 평균 나이 차이가 유의미하다고 말할 수 없다. (H0 기각 실패)")
    ```

-----

## 2\. 일원분산분석 (ANOVA)

  * **🎯 언제 사용하나요?**
      * **"세 개 이상의 그룹(범주형)"** 간의 \*\*"평균(수치형)"\*\*을 비교할 때.
      * (t-검정의 '그룹 3개 이상' 버전)
  * **⚖️ 재판 비유:**
      * "1등석, 2등석, 3등석(`Pclass` 1, 2, 3) 간의 평균 나이(`Age`)는 다른가?"
      * $H_0$: "세 그룹의 평균 나이가 모두 같다."
      * $H_1$: "적어도 한 그룹의 평균 나이는 다르다."
      * **(주의\!)** ANOVA는 "누가" 다른지는 알려주지 않고, "다르다/안 다르다"만 알려줍니다.
  * **🐍 Python 코드 예시:**
    ```python
    from scipy.stats import f_oneway

    # 1. 비교할 세 그룹의 'Age' 데이터 추출 (결측값 제거 필수)
    group1 = df[df['Pclass'] == 1]['Age'].dropna()
    group2 = df[df['Pclass'] == 2]['Age'].dropna()
    group3 = df[df['Pclass'] == 3]['Age'].dropna()

    # 2. (본 재판) ANOVA 수행
    f_stat, p_value = f_oneway(group1, group2, group3)

    print(f"ANOVA p-value: {p_value}")
    if p_value <= 0.05:
        print("결론: 1, 2, 3등석 간 평균 나이는 유의미한 차이가 있다. (H0 기각)")
    else:
        print("결론: 등급 간 평균 나이 차이가 유의미하다고 말할 수 없다. (H0 기각 실패)")
    ```

-----

## 3\. 카이제곱 검정 (Chi-squared Test, $\chi^2$)

  * **🎯 언제 사용하나요?**
      * \*\*"범주형 변수"\*\*와 **"범주형 변수"** 간의 \*\*관련성(연관성)\*\*을 볼 때.
      * (평균이 아닌 '빈도수(count)'를 비교합니다.)
  * **⚖️ 재판 비유:**
      * "성별(`Sex`)과 생존 여부(`Survived`)는 서로 관련이 있는가?"
      * $H_0$: "성별과 생존 여부는 관련이 없다. (독립이다)"
      * $H_1$: "성별과 생존 여부는 관련이 있다. (독립이 아니다)"
  * **❗ (필수) 사전 작업: 교차표 (Crosstab)**
      * 카이제곱 검정은 "숫자"가 아닌 "표(table)"를 입력받습니다.
      * `pd.crosstab`을 사용해 두 변수의 빈도수를 표로 만듭니다.
  * **🐍 Python 코드 예시:**
    ```python
    import pandas as pd
    from scipy.stats import chi2_contingency

    # 1. (사전 작업) 교차표 생성
    crosstab = pd.crosstab(df['Sex'], df['Survived'])
    # print(crosstab)
    # Survived    0    1
    # Sex               
    # female     81  233
    # male      468  109

    # 2. (본 재판) 카이제곱 검정 수행
    # (통계량, p-value, 자유도, 기대빈도표)를 반환
    chi2_stat, p_value, dof, expected_freq = chi2_contingency(crosstab)

    print(f"카이제곱 p-value: {p_value}")
    if p_value <= 0.05:
        print("결론: 성별과 생존 여부는 유의미한 관련이 있다. (H0 기각)")
    else:
        print("결론: 성별과 생존 여부는 관련이 없다. (H0 기각 실패)")
    ```

-----

## 4\. 피어슨 상관분석 (Pearson Correlation)

  * **🎯 언제 사용하나요?**
      * \*\*"수치형 변수"\*\*와 **"수치형 변수"** 간의 \*\*"선형 관계"\*\*를 볼 때.
      * (한 변수가 증가할 때 다른 변수도 증가/감소하는가?)
  * **⚖️ 재판 비유:**
      * "승객의 나이(`Age`)와 지불한 요금(`Fare`)은 관계가 있는가?"
      * $H_0$: "두 변수는 선형 관계가 없다. (상관계수 = 0)"
      * $H_1$: "두 변수는 선형 관계가 있다. (상관계수 $\ne$ 0)"
  * **❗ (주의) p-value와 상관계수(r)는 다릅니다.**
      * **상관계수(r):** 관계의 **방향과 강도** (-1 \~ +1). 0.8이면 강한 양의 관계.
      * **p-value:** 이 관계가 **통계적으로 유의미한지(우연이 아닌지)**.
  * **🐍 Python 코드 예시:**
    ```python
    from scipy.stats import pearsonr

    # 1. 두 변수 추출 (결측값 제거 필수)
    # (두 변수에서 모두 결측값이 아닌 행만 사용해야 함)
    clean_df = df[['Age', 'Fare']].dropna()

    # 2. (본 재판) 피어슨 상관분석 수행
    # (상관계수, p-value)를 반환
    corr_r, p_value = pearsonr(clean_df['Age'], clean_df['Fare'])

    print(f"상관계수(r): {corr_r:.3f}")
    print(f"p-value: {p_value}")

    if p_value <= 0.05:
        print("결론: 나이와 요금 간에 유의미한 선형 관계가 있다. (H0 기각)")
    else:
        print("결론: 나이와 요금 간에 선형 관계가 있다고 말할 수 없다. (H0 기각 실패)")
    ```

    ## 📊 1. 분산분석 (ANOVA)이란 무엇인가?

**"t-검정의 3개 그룹 이상 확장판"**

**ANOVA** (Analysis of Variance)는 \*\*"분산"\*\*을 분석하지만, 그 목적은 \*\*"세 개 이상 집단의 평균이 같은지"\*\*를 검정하는 것입니다.

t-검정은 두 집단(예: 1반 vs 2반)의 평균만 비교할 수 있습니다. 3개 집단(1반, 2반, 3반)의 평균을 비교할 때 t-검정을 3번(1v2, 1v3, 2v3) 쓰면 안 되는지 궁금할 수 있습니다.

> **🚨 다중 비교 문제 (Multiple Comparisons Problem)**
>
> t-검정(유의수준 5%)을 여러 번 반복하면, "우연히 틀릴 확률(1종 오류)"이 5%보다 훨씬 더 커집니다. (예: 3번 실행 시 약 14.3%) 재판을 여러 번 해서 억지로 유죄를 만드는 셈입니다.
>
> ANOVA는 이 오류를 5%로 고정한 채, "단 한 번의 검정"으로 3개 이상 집단의 평균을 비교해 줍니다.

### 💡 ANOVA의 핵심 원리: F-통계량

ANOVA는 어떻게 "분산"을 이용해서 "평균"을 비교할까요?

"집단 간 분산"과 "집단 내 분산"이라는 두 가지 분산을 비교합니다.

1.  **집단 간 분산 (Between-group variance):**

      * 각 그룹의 "평균"이 전체 평균에서 얼마나 멀리 떨어져 있는지.
      * (A반 평균 50점, B반 평균 80점) ➡️ **집단 간 분산이 크다** = 그룹들이 서로 멀리 떨어져 있다.

2.  **집단 내 분산 (Within-group variance):**

      * 각 그룹 "내부"의 데이터가 얼마나 흩어져 있는지. (A반 학생들의 점수 분포)
      * ➡️ **집단 내 분산이 작다** = 그룹 구성원들이 자기 평균에 똘똘 뭉쳐있다.

**F-통계량 = (집단 간 분산) / (집단 내 분산)**

  * **F 값이 크다:** (집단끼리 멀리 떨어져 있음) / (집단 내부는 똘똘 뭉쳐있음)
      * **결론:** 이 그룹들은 명확히 다르다. **(H0 기각\!)**
  * **F 값이 작다:** (집단끼리 가깝게 붙어있음) / (집단 내부가 넓게 퍼져있음)
      * **결론:** 그룹 간 차이가 집단 내의 우연한 차이보다 작다. (H0 기각 실패)

> **⚖️ ANOVA의 가설**
>
>   * **$H_0$ (귀무가설):** 모든 집단의 평균은 같다. ($\mu_1 = \mu_2 = \mu_3$)
>   * **$H_1$ (대립가설):** 적어도 하나 이상의 집단 평균은 다르다.

-----

## 2\. Scipy vs Statsmodels: 언제 무엇을 쓸까?

두 라이브러리 모두 ANOVA를 수행하지만, 목적이 약간 다릅니다.

### 🔬 `scipy.stats.f_oneway`

  * **특징:** 빠르고, 간단하며, 코드 한 줄로 끝납니다.
  * **입력:** 각 그룹의 데이터를 **개별 인수**로 받습니다.
  * **출력:** F-통계량, p-value **두 개만** 줍니다.

<!-- end list -->

```python
from scipy import stats

# 1. 각 그룹의 'Fare' 데이터를 별도로 준비
group_S = df[df['Embarked'] == 'S']['Fare']
group_C = df[df['Embarked'] == 'C']['Fare']
group_Q = df[df['Embarked'] == 'Q']['Fare']

# 2. 그룹들을 그대로 인수로 전달
f_stat, p_value = stats.f_oneway(group_S, group_C, group_Q)
```

  * **👍 장점:** p-value만 빠르게 확인하고 싶을 때 최고입니다. (3유형 단답형 문제풀이에 적합)
  * **👎 단점:** 분산분석표(SS, MS 등)를 제공하지 않으며, 사후검정(Tukey)과 연동되지 않습니다.

### 🧬 `statsmodels` (`ols` + `anova_lm`)

  * **특징:** R 스타일의 \*\*"포뮬러(formula)"\*\*를 사용하며, 상세한 분석표를 제공합니다.
  * **입력:** `ols('종속변수 ~ C(독립변수)', data=df)` 형태의 모델을 먼저 만듭니다.
      * \*\*`C()`\*\*는 "이 변수가 범주형(Categorical)이다"라고 명시하는 필수 기호입니다.
  * **출력:** **완전한 분산분석표** (자유도(df), 제곱합(sum\_sq), 평균제곱(mean\_sq) 등)를 반환합니다.

<!-- end list -->

```python
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm

# 1. OLS(최소제곱법) 모델 생성
# 'Fare ~ C(Embarked)' -> Embarked 그룹에 따른 Fare 평균 분석
model = ols('Fare ~ C(Embarked)', data=df).fit()

# 2. 모델을 anova_lm에 전달
result_table = anova_lm(model, type=2) # type=2가 표준
# print(result_table)
```

  * **👍 장점:**
    1.  상세한 분석 결과를 제공합니다.
    2.  `statsmodels`의 **Tukey 사후검정**과 완벽하게 호환됩니다.
    3.  `'y ~ C(a) + C(b)'` 처럼 이원분산분석(Two-Way ANOVA) 등 복잡한 모델로 확장이 쉽습니다.
  * **👎 단점:** `scipy`보다 코드가 몇 줄 더 필요합니다.

> **결론:**
>
>   * 단순히 p-value만 묻는다면 ➡️ **`scipy`**
>   * F-통계량을 묻거나, 사후검정(Tukey)까지 이어지는 문제라면 ➡️ **`statsmodels`**

-----

## 3\. Tukey HSD 사후검정이란 무엇인가?

  * **"ANOVA가 유죄 판결을 내린 뒤, '진짜 범인'을 찾는 수사관"**

ANOVA는 $H_0$을 기각할 때, "적어도 하나는 다르다"라는 모호한 결론만 줍니다.
(1반, 2반, 3반의 평균이 다름)

하지만 **"누가"** 다른지는 알려주지 않습니다.

  * 1반 vs 2반? (차이 있음)
  * 1반 vs 3반? (차이 없음)
  * 2반 vs 3반? (차이 있음)

이것을 알아내기 위해 모든 그룹 쌍(pair)을 비교하는 것을 \*\*"사후검정 (Post-hoc test)"\*\*이라고 합니다.

### Tukey HSD (Honestly Significant Difference)

Tukey HSD(투키의 정직한 유의미한 차이)는 가장 널리 쓰이는 사후검정입니다.

앞서 언급한 \*\*"다중 비교 문제"\*\*를 해결하기 위해, 각 쌍(pair)을 비교할 때 p-value를 더 엄격하게 보정합니다. (그냥 t-검정을 여러 번 돌리는 것보다 신뢰할 수 있습니다.)

### 🐍 Python 코드 예시

Tukey 검정은 `statsmodels` 라이브러리를 사용하며, (모델이 아닌) **데이터**와 **그룹 라벨**을 직접 입력받습니다.

```python
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# (ANOVA에서 H0이 기각되었다고 가정)

# 1. Tukey HSD 수행
# (전체 'Fare' 데이터, 전체 'Embarked' 라벨)
tukey_result = pairwise_tukeyhsd(endog=df['Fare'], groups=df['Embarked'], alpha=0.05)

# 2. 결과 테이블 출력
# print(tukey_result)
```

### 📊 Tukey 결과 테이블 해석

`print(tukey_result)`는 다음과 같은 표를 보여줍니다.

| group1 | group2 | meandiff | **p-adj** | lower | upper | **reject** |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| C | Q | -1.135 | 0.999 | -27.6 | 25.3 | **False** |
| **C** | **S** | -32.89 | **0.000** | -42.8 | -22.9 | **True** |
| **Q** | **S** | -31.75 | **0.000** | -48.1 | -15.3 | **True** |

  * **`group1`, `group2`**: 비교하는 두 그룹 (예: 'C'와 'S')
  * **`meandiff`**: 두 그룹의 평균 차이 (예: C-S = -32.89)
  * **`p-adj` (Adjusted p-value)**: **가장 중요한 값.** 다중 비교가 보정된 p-value입니다.
  * **`reject` (기각 여부)**: **최종 결론.**
      * **`reject = True`:** "이 두 그룹은 유의미하게 다르다." (p-adj \<= 0.05)
      * **`reject = False`:** "이 두 그룹은 차이가 없다." (p-adj \> 0.05)

**최종 해석:** C와 S, Q와 S는 평균 요금에 유의미한 차이가 있지만, C와 Q는 차이가 없다고 말할 수 있습니다.