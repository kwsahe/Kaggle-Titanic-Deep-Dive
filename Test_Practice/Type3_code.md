## ë¹…ë°ì´í„°ë¶„ì„ê¸°ì‚¬ 3ìœ í˜• (í†µê³„ ê²€ì •) í•µì‹¬ ìš”ì•½ âš¡ï¸

### 1\. ğŸ“¦ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë¨¼ì € ë³µë¶™\!)

ì‹œí—˜ ì‹œì‘ ì‹œ, ì´ ì½”ë“œ ë¸”ë¡ì„ ë¨¼ì € ì‹¤í–‰í•˜ë©´ í¸ë¦¬í•©ë‹ˆë‹¤.

```python
import pandas as pd
import numpy as np

# 1. tê²€ì •, ì¹´ì´ì œê³±, ì •ê·œì„±, ìƒê´€ë¶„ì„ ë“±
from scipy import stats

# 2. ë¹„ìœ¨ ê²€ì •
from statsmodels.stats.proportion import proportions_ztest

# 3. íšŒê·€ë¶„ì„ (OLS, Logit)
from statsmodels.formula.api import ols, logit, glm
import statsmodels.api as sm # GLMì˜ family ì§€ì • ì‹œ í•„ìš”

# 4. ë¶„ì‚°ë¶„ì„ (ANOVA)
from statsmodels.stats.anova import anova_lm

# 5. ì‚¬í›„ê²€ì • (Tukey)
from statsmodels.stats.multicomp import pairwise_tukeyhsd
```

-----

### 2\. âš–ï¸ p-value íŒê²°ì˜ ëª¨ë“  ê²ƒ (ì´ê²ƒë§Œ ê¸°ì–µ\!)

ëª¨ë“  ê²€ì •ì˜ ê²°ë¡ ì€ `p-value`ê°€ 0.05ë³´ë‹¤ ì‘ì€ì§€ë§Œ ë³´ë©´ ë©ë‹ˆë‹¤.

  * **`p-value <= 0.05` (5%ë³´ë‹¤ ì‘ë‹¤)**
      * "ì´ ì°¨ì´ëŠ” ìš°ì—°ì´ ì•„ë‹ˆë‹¤\! (ìœ ì˜ë¯¸í•˜ë‹¤)"
      * **íŒê²°: ê·€ë¬´ê°€ì„¤($H_0$) ê¸°ê°** (â¡ï¸ ëŒ€ë¦½ê°€ì„¤($H_1$) ì±„íƒ)
  * **`p-value > 0.05` (5%ë³´ë‹¤ í¬ë‹¤)**
      * "ì´ ì°¨ì´ëŠ” ìš°ì—°ì¼ ìˆ˜ ìˆë‹¤. (ìœ ì˜ë¯¸í•˜ì§€ ì•Šë‹¤)"
      * **íŒê²°: ê·€ë¬´ê°€ì„¤($H_0$) ê¸°ê° ì‹¤íŒ¨** (ê·¸ëŒ€ë¡œ ìœ ì§€)

-----

### 3\. ğŸ“‹ ì‹¤ì „\! 'ë¬¸ì œ ìœ í˜•ë³„' ì½”ë“œ ì¡±ë³´

ë‚´ê°€ í’€ì–´ì•¼ í•  ë¬¸ì œê°€ ë¬´ì—‡ì¸ì§€ í™•ì¸í•˜ê³ , í•´ë‹¹ ì½”ë“œë¥¼ ì°¾ì•„ ì“°ì„¸ìš”.

#### 1ï¸âƒ£ "í‰ê· " ë¹„êµ (ìˆ˜ì¹˜í˜• ë°ì´í„° ğŸ“Š)

**(ì‚¬ì „ê²€ì‚¬) ì •ê·œì„± ê²€ì • (Shapiro-Wilk)**

  * ë°ì´í„°ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
  * `H0`: ì •ê·œë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤.
  * `p > 0.05` ì—¬ì•¼ ì •ê·œë¶„í¬ë¥¼ ë§Œì¡±í•˜ì—¬ t-ê²€ì •/ANOVAë¥¼ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<!-- end list -->

```python
# stat, p = stats.shapiro(data)
```

**(A) 2ê°œ ê·¸ë£¹ í‰ê·  ë¹„êµ (t-ê²€ì •)**

  * `H0`: ë‘ ê·¸ë£¹ì˜ í‰ê· ì€ ê°™ë‹¤.

<!-- end list -->

```python
# 1. ë…ë¦½í‘œë³¸ (ì˜ˆ: Aë°˜ vs Bë°˜)
# (ë“±ë¶„ì‚° ê°€ì •: equal_var=True)
stats.ttest_ind(group1_score, group2_score, equal_var=True)

# 2. ëŒ€ì‘í‘œë³¸ (ì˜ˆ: ë³µìš© ì „ vs ë³µìš© í›„)
stats.ttest_rel(before_score, after_score)

# 3. ë‹¨ì¼í‘œë³¸ (ì˜ˆ: ìš°ë¦¬ ë°˜ vs ì „êµ­ í‰ê· )
stats.ttest_1samp(sample_scores, popmean=75)
```

**(B) 3ê°œ ì´ìƒ ê·¸ë£¹ í‰ê·  ë¹„êµ (ë¶„ì‚°ë¶„ì„ - ANOVA)**

  * `H0`: ëª¨ë“  ê·¸ë£¹ì˜ í‰ê· ì€ ê°™ë‹¤.

<!-- end list -->

```python
# 1. ANOVA ì‹¤í–‰ (Scipy ë°©ì‹ - ê°€ì¥ ê°„ë‹¨)
stats.f_oneway(group1_score, group2_score, group3_score)

# 2. ANOVA ì‹¤í–‰ (Statsmodels ë°©ì‹ - Fê°’, Pê°’ ëª¨ë‘ ì œê³µ)
model = ols('score ~ C(group_col)', data=df).fit()
result = anova_lm(model)
# print(result) # p-valueëŠ” PR(>F) ì»¬ëŸ¼ í™•ì¸

# 3. (í•„ìˆ˜) ì‚¬í›„ê²€ì • (ANOVAê°€ H0 ê¸°ê° ì‹œ, 'ëˆ„ê°€' ë‹¤ë¥¸ì§€ í™•ì¸)
posthoc = pairwise_tukeyhsd(df['score_col'], df['group_col'])
# print(posthoc) # reject=Trueì¸ ê·¸ë£¹ì´ ìœ ì˜ë¯¸í•œ ì°¨ì´
```

#### 2ï¸âƒ£ "ë¹ˆë„ìˆ˜/ë¹„ìœ¨" ë¹„êµ (ë²”ì£¼í˜• ë°ì´í„° ğŸ§®)

**(A) ë‘ ë³€ìˆ˜ ê°„ "ê´€ë ¨ì„±" (ì¹´ì´ì œê³± - ë…ë¦½ì„± ê²€ì •)**

  * `H0`: ë‘ ë³€ìˆ˜ëŠ” ì„œë¡œ ê´€ë ¨ì´ ì—†ë‹¤ (ë…ë¦½ì´ë‹¤).

<!-- end list -->

```python
# 1. (í•„ìˆ˜) êµì°¨í‘œ(Crosstab) ìƒì„±
ct = pd.crosstab(df['category_A'], df['category_B'])

# 2. ì¹´ì´ì œê³± ê²€ì • ì‹¤í–‰
chi2, p, dof, expected = stats.chi2_contingency(ct)
```

**(B) "ì˜ˆìƒê³¼ ì¼ì¹˜" (ì¹´ì´ì œê³± - ì í•©ë„ ê²€ì •)**

  * `H0`: ì‹¤ì œ ê´€ì¸¡ ë¹ˆë„ê°€ ê¸°ëŒ€ ë¹ˆë„ì™€ ê°™ë‹¤.

<!-- end list -->

```python
# f_obs: ì‹¤ì œ ê´€ì¸¡ ë¹ˆë„ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [30, 25, 45])
# f_exp: ê¸°ëŒ€ ë¹ˆë„ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [33, 33, 34])
stats.chisquare(f_obs=observed, f_exp=expected)
```

**(C) ë‘ ì§‘ë‹¨ "ë¹„ìœ¨" ì°¨ì´ (ë¹„ìœ¨ ê²€ì •)**

  * `H0`: ë‘ ì§‘ë‹¨ì˜ ë¹„ìœ¨ì€ ê°™ë‹¤.

<!-- end list -->

```python
# ì˜ˆ: Aì§‘ë‹¨ 100ëª… ì¤‘ 30ëª… ì„±ê³µ, Bì§‘ë‹¨ 100ëª… ì¤‘ 40ëª… ì„±ê³µ
stat, p = proportions_ztest(count=[30, 40], nobs=[100, 100])
```

#### 3ï¸âƒ£ "ì˜ˆì¸¡ ëª¨ë¸ë§" (íšŒê·€ ë¶„ì„ ğŸ¯)

**(A) "ìˆ«ì" ì˜ˆì¸¡ (ì„ í˜• íšŒê·€ - OLS)**

  * `H0`: í•´ë‹¹ ë³€ìˆ˜(x)ëŠ” yì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤.

<!-- end list -->

```python
# R-squared(ê²°ì •ê³„ìˆ˜)ì™€ ê° ë³€ìˆ˜ì˜ P>|t|(p-value)ë¥¼ í™•ì¸
model = ols('y ~ x1 + x2', data=df).fit()
# print(model.summary())
```

**(B) "ë²”ì£¼" ì˜ˆì¸¡ (ë¡œì§€ìŠ¤í‹± íšŒê·€ - Logit / GLM)**

  * `H0`: í•´ë‹¹ ë³€ìˆ˜(x)ëŠ” targetì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤.

<!-- end list -->

```python
# 1. Logit (ì£¼ë¡œ ì‚¬ìš©)
model = logit('target ~ x1 + x2', data=df).fit()
# print(model.summary())

# 2. GLM (Logitê³¼ ê²°ê³¼ ë™ì¼)
family = sm.families.Binomial()
model = glm('target ~ x1 + x2', data=df, family=family).fit()
# print(model.summary())
```

-----

### 4\. âš¡ï¸ ì‹¤ì „ ì˜ˆì œ ì½”ë“œ (ë³µë¶™ìš© í…œí”Œë¦¿)

#### ğŸ“ˆ t-ê²€ì • (ë…ë¦½í‘œë³¸)

```python
from scipy import stats

# 1. ê·¸ë£¹ ë¶„ë¦¬ (ì˜ˆ: group ì»¬ëŸ¼ì´ 'A'ì¸ ë°ì´í„°ì˜ 'score'ë§Œ ì¶”ì¶œ)
groupA = df[df['group'] == 'A']['score']
groupB = df[df['group'] == 'B']['score']

# 2. t-ê²€ì • (ë“±ë¶„ì‚° ê°€ì •)
stat, p = stats.ttest_ind(groupA, groupB, equal_var=True)
print(f'p-value: {p:.3f}')
```

#### ğŸ“Š ë¶„ì‚°ë¶„ì„ (ANOVA) + ì‚¬í›„ê²€ì •

```python
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# 1. ANOVA ëª¨ë¸ (y ~ C(X), C()ëŠ” groupì´ ë²”ì£¼í˜•ì„ì„ ëª…ì‹œ)
model = ols('score ~ C(method)', data=df).fit()
result = anova_lm(model)
print(result) # PR(>F) ì»¬ëŸ¼ì˜ p-value í™•ì¸

# 2. ì‚¬í›„ê²€ì • (p-value < 0.05 ì¼ ë•Œë§Œ ì‹¤í–‰)
posthoc = pairwise_tukeyhsd(df['score'], df['method'])
print(posthoc) # reject=True í™•ì¸
```

#### ğŸ§® ì¹´ì´ì œê³± ê²€ì • (ë…ë¦½ì„±)

```python
from scipy.stats import chi2_contingency
import pandas as pd

# 1. êµì°¨í‘œ ì‘ì„±
ct = pd.crosstab(df['ì„±ë³„'], df['ë§Œì¡±ë„'])

# 2. ê²€ì • ì‹¤í–‰
chi2, p, dof, expected = chi2_contingency(ct)
print(f'p-value: {p:.3f}')
```

#### ğŸ¯ ë¡œì§€ìŠ¤í‹± íšŒê·€

```python
from statsmodels.formula.api import logit

# 1. ëª¨ë¸ í”¼íŒ… (targetì´ 0 ë˜ëŠ” 1ì´ì–´ì•¼ í•¨)
model = logit('target ~ age + income', data=df).fit()

# 2. ê²°ê³¼ ìš”ì•½ (P>|z| ì»¬ëŸ¼ì˜ p-value í™•ì¸)
print(model.summary())
```

ë„¤, ë¹…ë°ì´í„°ë¶„ì„ê¸°ì‚¬ ì‹¤ê¸° ì‹œí—˜(íŠ¹íˆ 2, 3ìœ í˜•)ì—ì„œ ìì£¼ ì“°ëŠ” `import` êµ¬ë¬¸ê³¼ í•¨ìˆ˜ ë°˜í™˜ê°’(`stat, p_val ...`)ì„ ì•”ê¸°í•˜ê¸° ì‰½ê²Œ ì´ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

ì´ê²ƒë§Œ ì™¸ì›Œë‘ì‹œë©´ ì½”ë”© ì‹œê°„ì„ íšê¸°ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

-----

## ğŸ“¦ 1. `import` ì´ì •ë¦¬ (ìœ í˜•ë³„ ì•”ê¸°)

### 1\. ê¸°ë³¸ (1, 2, 3ìœ í˜• ê³µí†µ)

ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ë‹¤ë£¨ê³ , ê³„ì‚°í•˜ëŠ” ë° í•„ìˆ˜ì…ë‹ˆë‹¤.

```python
# íŒë‹¤ìŠ¤ (ë°ì´í„°í”„ë ˆì„ í•¸ë“¤ë§)
import pandas as pd

# ë„˜íŒŒì´ (ìˆ˜í•™ ê³„ì‚°, ë°°ì—´)
import numpy as np
```

### 2\. ë¨¸ì‹ ëŸ¬ë‹ (2ìœ í˜• - ëª¨ë¸ë§)

`sklearn` (Scikit-Learn)ì´ í•µì‹¬ì…ë‹ˆë‹¤.

```python
# 1. ë°ì´í„° ë¶„ë¦¬ (í•„ìˆ˜)
from sklearn.model_selection import train_test_split

# 2. ì „ì²˜ë¦¬ (ì¸ì½”ë”©)
from sklearn.preprocessing import LabelEncoder # (ì˜ˆ: 'male' -> 0)
from sklearn.preprocessing import StandardScaler # (ìˆ«ì ìŠ¤ì¼€ì¼ë§)
from sklearn.preprocessing import MinMaxScaler # (ìˆ«ì ìŠ¤ì¼€ì¼ë§)

# 3. ëª¨ë¸ ì„ íƒ (2ê°œë§Œ ì™¸ì›Œë„ ì¶©ë¶„)
from sklearn.ensemble import RandomForestClassifier # (ë¶„ë¥˜ - ì„±ëŠ¥ ì¢‹ìŒ)
from sklearn.linear_model import LogisticRegression # (ë¶„ë¥˜ - ê¸°ë³¸)
# from sklearn.ensemble import RandomForestRegressor # (íšŒê·€ - ìˆ«ì ì˜ˆì¸¡)
# from sklearn.linear_model import LinearRegression # (íšŒê·€ - ê¸°ë³¸)

# 4. í‰ê°€ì§€í‘œ (ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ê²ƒ)
from sklearn.metrics import accuracy_score # (ì •í™•ë„)
from sklearn.metrics import f1_score # (F1 ìŠ¤ì½”ì–´)
from sklearn.metrics import roc_auc_score # (ROC AUC)
# from sklearn.metrics import mean_squared_error # (MSE - íšŒê·€)
```

### 3\. í†µê³„ ê²€ì • (3ìœ í˜• - ê°€ì„¤ ê²€ì •)

`scipy.stats`ì™€ `statsmodels`ê°€ í•µì‹¬ì…ë‹ˆë‹¤.

```python
# 1. Scipy (ë‹¨ì¼ í•¨ìˆ˜ë“¤)
from scipy import stats
# (ì—¬ê¸°ì— ttest_ind, f_oneway, levene, chi2_contingency, 
#  chisquare, pearsonr, shapiro ë“±ì´ ëª¨ë‘ ë“¤ì–´ìˆìŒ)

# 2. Statsmodels (íšŒê·€ë¶„ì„, ANOVA ìƒì„¸ ë¶„ì„)
import statsmodels.api as sm # (GLM ë“±ì—ì„œ family ì§€ì • ì‹œ í•„ìš”)
from statsmodels.formula.api import ols, logit, glm # (íšŒê·€ì‹)
from statsmodels.stats.anova import anova_lm # (ë¶„ì‚°ë¶„ì„í‘œ)
from statsmodels.stats.multicomp import pairwise_tukeyhsd # (íˆ¬í‚¤ ì‚¬í›„ê²€ì •)
from statsmodels.stats.proportion import proportions_ztest # (ë¹„ìœ¨ ê²€ì •)
```

-----

## ğŸ 2. í•¨ìˆ˜ ë°˜í™˜ê°’ ì´ì •ë¦¬ (stat, p\_val...)

`scipy.stats`ì˜ ë§ì€ í•¨ìˆ˜ëŠ” ê²°ê³¼ë¥¼ \*\*íŠœí”Œ(tuple)\*\*ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ ê°’ë“¤ì„ ìˆœì„œëŒ€ë¡œ ë°›ì•„ì˜¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

### 1\. (í†µê³„ëŸ‰, pê°’) 2ê°œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë“¤

ê°€ì¥ ì¼ë°˜ì ì¸ í˜•íƒœì…ë‹ˆë‹¤. **ê±°ì˜ ëª¨ë“  ê²€ì •**ì´ ì´ í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤.

  * `statistic`: ê²€ì •í†µê³„ëŸ‰ (t-ê°’, F-ê°’, $\chi^2$-ê°’, ìƒê´€ê³„ìˆ˜ r ë“±)
  * `pvalue`: p-ê°’

<!-- end list -->

```python
# í…œí”Œë¦¿: stat, p_val = function(...)

# 1. t-ê²€ì • (3ì¢… ì„¸íŠ¸)
stat, p_val = stats.ttest_1samp(sample, popmean=0)
stat, p_val = stats.ttest_ind(group1, group2, equal_var=True)
stat, p_val = stats.ttest_rel(before, after)

# 2. ANOVA (scipy ë°©ì‹)
stat, p_val = stats.f_oneway(group1, group2, group3)

# 3. ì •ê·œì„± ê²€ì • (Shapiro-Wilk)
stat, p_val = stats.shapiro(data)

# 4. ìƒê´€ë¶„ì„ (Pearson)
# (ì£¼ì˜: ì²« ë²ˆì§¸ statì´ 'ìƒê´€ê³„ìˆ˜ r'ì„)
corr, p_val = stats.pearsonr(x, y)

# 5. ì í•©ë„ ê²€ì • (Chisquare)
stat, p_val = stats.chisquare(f_obs=[...], f_exp=[...])

# 6. ë“±ë¶„ì‚° ê²€ì • (Levene)
stat, p_val = stats.levene(group1, group2)

# 7. ë¹„ìœ¨ ê²€ì • (Statsmodels)
stat, p_val = proportions_ztest(count=[...], nobs=[...])
```

### 2\. (í†µê³„ëŸ‰, pê°’, ììœ ë„, ê¸°ëŒ€ë¹ˆë„) 4ê°œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

**`chi2_contingency` (ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •)ê°€ ìœ ì¼**í•©ë‹ˆë‹¤. ì´ê²ƒë§Œ ë”°ë¡œ ì™¸ìš°ì„¸ìš”.

```python
# í…œí”Œë¦¿: chi2, p_val, dof, expected = stats.chi2_contingency(crosstab)

# 1. êµì°¨í‘œ ìƒì„±
ct = pd.crosstab(df['Var1'], df['Var2'])

# 2. ê²€ì • ìˆ˜í–‰
chi2_stat, p_val, dof, expected = stats.chi2_contingency(ct)
```

  * `chi2_stat`: ì¹´ì´ì œê³± í†µê³„ëŸ‰
  * `p_val`: p-ê°’
  * `dof`: ììœ ë„ (Degrees of Freedom)
  * `expected`: ê¸°ëŒ€ë¹ˆë„í‘œ (Numpy ë°°ì—´)

### 3\. (ê¸°íƒ€) í…Œì´ë¸”/ê°ì²´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë“¤

`stat, p_val` í˜•ì‹ì´ ì•„ë‹Œ í•¨ìˆ˜ë“¤ì…ë‹ˆë‹¤.

```python
# 1. ANOVA (Statsmodels ë°©ì‹)
# 'DataFrame'ì„ ë°˜í™˜
model = ols('y ~ C(X)', data=df).fit()
anova_table = anova_lm(model)
# print(anova_table) # -> PR(>F) ì»¬ëŸ¼ì´ p-value

# 2. Tukey ì‚¬í›„ê²€ì •
# 'TukeyHSDResult'ë¼ëŠ” ì „ìš© ê°ì²´(í‘œ)ë¥¼ ë°˜í™˜
tukey_result = pairwise_tukeyhsd(endog=df['value'], groups=df['group'])
# print(tukey_result) # -> p-adj ì»¬ëŸ¼ì´ p-value
```

ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì€ \*\*"ê²°ê³¼ë¥¼ í•´ì„í•˜ëŠ” ëŠ¥ë ¥"\*\*ì´ 3ìœ í˜•ì˜ í•µì‹¬ì…ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ë‚´ìš©(Summary í•´ì„, ì˜¤ì¦ˆë¹„, íŠ¹ì • ì¡°ê±´ ê³„ì‚°)ì„ ì‹œí—˜ ì‹¤ì „ìš©ìœ¼ë¡œ ë”± ì •ë¦¬í•´ ë“œë¦´ê²Œìš”.

-----

## 1\. `model.summary()` ì™„ë²½ í•´ë¶€ (ì‹œí—˜ì— ë³¼ ê±´ ë”± 2ê°œ\!)

`print(model.summary())`ë¥¼ í•˜ë©´ ë³µì¡í•œ í‘œê°€ ë‚˜ì˜¤ì§€ë§Œ, ì‹œí—˜ì—ì„œëŠ” \*\*`coef`\*\*ì™€ \*\*`P>|z|`\*\*ë§Œ ë³´ë©´ ë©ë‹ˆë‹¤.

### â‘  `coef` (íšŒê·€ê³„ìˆ˜, Coefficient)

  * **ì˜ë¯¸:** ì´ ë³€ìˆ˜ê°€ 1 ì¦ê°€í•  ë•Œ, \*\*"ë¡œê·¸ ì˜¤ì¦ˆ(Log Odds)"\*\*ê°€ ì–¼ë§ˆë‚˜ ë³€í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
  * **í•´ì„:**
      * **ì–‘ìˆ˜(+)**: ì´ ë³€ìˆ˜ê°€ ì»¤ì§€ë©´ ì„±ê³µ(Target=1) í™•ë¥ ì´ **ë†’ì•„ì§„ë‹¤.**
      * **ìŒìˆ˜(-)**: ì´ ë³€ìˆ˜ê°€ ì»¤ì§€ë©´ ì„±ê³µ(Target=1) í™•ë¥ ì´ **ë‚®ì•„ì§„ë‹¤.**
  * **ì£¼ì˜:** ì´ ê°’ ìì²´ëŠ” í™•ë¥ ì´ ì•„ë‹™ë‹ˆë‹¤\! \*\*ì§€ìˆ˜í•¨ìˆ˜($e$)ë¥¼ ì”Œì›Œì•¼ "ì˜¤ì¦ˆë¹„"\*\*ê°€ ë©ë‹ˆë‹¤.

### â‘¡ `P>|z|` (p-value, ìœ ì˜í™•ë¥ )

  * **ì˜ë¯¸:** ì´ ë³€ìˆ˜ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œê°€?
  * **ê¸°ì¤€:** **0.05ë³´ë‹¤ ì‘ì•„ì•¼ ìœ ì˜ë¯¸**í•©ë‹ˆë‹¤. (0.05ë³´ë‹¤ í¬ë©´ ì´ ë³€ìˆ˜ëŠ” ê²°ê³¼ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤ê³  ë´…ë‹ˆë‹¤.)

-----

## 2\. ì˜¤ì¦ˆë¹„ (Odds Ratio)ë€?

ì‹œí—˜ ë¬¸ì œì˜ ë‹¨ê³¨ ì†ë‹˜ì…ë‹ˆë‹¤.

  * **ì˜¤ì¦ˆ(Odds):** $\frac{\text{ì„±ê³µ í™•ë¥ }}{\text{ì‹¤íŒ¨ í™•ë¥ }}$
  * **ì˜¤ì¦ˆë¹„(Odds Ratio):** ë³€ìˆ˜ê°€ 1 ì¦ê°€í•  ë•Œ **ì˜¤ì¦ˆê°€ ëª‡ ë°°ê°€ ë˜ëŠ”ê°€?**
  * **ê³µì‹:** $\text{Odds Ratio} = e^{\text{coef}} = \exp(\text{coef})$

> **ì‹œí—˜ ê¿€íŒ:** ë¬¸ì œì—ì„œ "ì˜¤ì¦ˆë¹„ë¥¼ êµ¬í•˜ì‹œì˜¤"ë¼ê³  í•˜ë©´ ë¬´ì¡°ê±´ \*\*`np.exp(íšŒê·€ê³„ìˆ˜)`\*\*ë¥¼ ê³„ì‚°í•˜ë©´ ë©ë‹ˆë‹¤.

-----

## 3\. ì‹¤ì „ ë¬¸ì œ ìœ í˜•ë³„ í•´ê²°ë²• (ì½”ë“œ í¬í•¨)

ê°€ìƒì˜ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ì„œ ë°”ë¡œ ë³´ì—¬ë“œë¦´ê²Œìš”.

### ğŸ“Š ë°ì´í„° ì¤€ë¹„

```python
import pandas as pd
import numpy as np
from statsmodels.formula.api import logit

# ê°€ìƒ ë°ì´í„° ìƒì„±
df = pd.DataFrame({
    'Churn': [1, 0, 1, 0, 1, 0, 0, 1, 1, 0], # 1: ì´íƒˆ, 0: ìœ ì§€
    'PlanType': [1, 0, 1, 0, 1, 0, 0, 1, 0, 0], # 1: ê³ ê¸‰ìš”ê¸ˆì œ, 0: ì¼ë°˜
    'Age': [50, 20, 45, 22, 55, 25, 30, 48, 52, 28]
})

# ëª¨ë¸ í•™ìŠµ
model = logit('Churn ~ PlanType + Age', data=df).fit()
# print(model.summary())
```

### â“ ë¬¸ì œ ìœ í˜• A: "PlanTypeì´ 1ì¸ ê³ ê°ì´ 0ì¸ ê³ ê°ë³´ë‹¤ ì´íƒˆí•  ì˜¤ì¦ˆë¹„ë¥¼ êµ¬í•˜ì‹œì˜¤."

ì´ ë§ì€ \*\*"PlanType ë³€ìˆ˜ì˜ ì˜¤ì¦ˆë¹„ë¥¼ êµ¬í•˜ë¼"\*\*ëŠ” ë§ê³¼ 100% ë˜‘ê°™ìŠµë‹ˆë‹¤.
(ì™œëƒí•˜ë©´ íšŒê·€ê³„ìˆ˜ëŠ” ë³€ìˆ˜ê°€ \*\*'1ë‹¨ìœ„ ì¦ê°€í•  ë•Œ'\*\*ì˜ ë³€í™”ëŸ‰ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. 0ì—ì„œ 1ì´ ë˜ëŠ” ê²ƒë„ 1ë‹¨ìœ„ ì¦ê°€ì£ .)

**í’€ì´ ì½”ë“œ:**

```python
# 1. PlanTypeì˜ íšŒê·€ê³„ìˆ˜(coef) ì¶”ì¶œ
coef_plan = model.params['PlanType']

# 2. ì§€ìˆ˜í•¨ìˆ˜(exp)ë¥¼ ì”Œì›Œ ì˜¤ì¦ˆë¹„ ê³„ì‚°
odds_ratio = np.exp(coef_plan)

print(f"PlanTypeì˜ ì˜¤ì¦ˆë¹„: {round(odds_ratio, 4)}")
```

  * **í•´ì„:** ë§Œì•½ ë‹µì´ **2.5**ë¼ë©´? -\> "PlanType 1ì¸ ì‚¬ëŒì€ 0ì¸ ì‚¬ëŒë³´ë‹¤ ì´íƒˆí•  í™•ë¥ (ì˜¤ì¦ˆ)ì´ **2.5ë°° ë†’ë‹¤**."

-----

### â“ ë¬¸ì œ ìœ í˜• B: "ì´íƒˆ í™•ë¥ ì´ 0.3 ì´ìƒì¸ ê³ ê° ìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤."

`statsmodels`ì˜ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì—ì„œ `predict()`ë¥¼ ì“°ë©´ \*\*ìë™ìœ¼ë¡œ í™•ë¥ (0\~1 ì‚¬ì´ ê°’)\*\*ì´ ë‚˜ì˜µë‹ˆë‹¤. (sklearnê³¼ ë‹¤ë¦„\!)

**í’€ì´ ì½”ë“œ:**

```python
# 1. ì´íƒˆ í™•ë¥  ì˜ˆì¸¡ (0.82, 0.11, ... ì´ëŸ° ì‹ìœ¼ë¡œ ë‚˜ì˜´)
pred_probs = model.predict(df) 

# 2. ì¡°ê±´ í•„í„°ë§ (0.3 ì´ìƒ)
target_customers = pred_probs[pred_probs >= 0.3]

# 3. ê°œìˆ˜ ì„¸ê¸° (len ì‚¬ìš©)
count = len(target_customers)

print(f"í™•ë¥  0.3 ì´ìƒì¸ ê³ ê° ìˆ˜: {count}ëª…")
```

-----

### â“ ë¬¸ì œ ìœ í˜• C: "Ageê°€ 10ì‚´ ì¦ê°€í•  ë•Œì˜ ì˜¤ì¦ˆë¹„ë¥¼ êµ¬í•˜ì‹œì˜¤."

ê°€ë” ì´ë ‡ê²Œ \*\*"1ë‹¨ìœ„ê°€ ì•„ë‹ˆë¼ në‹¨ìœ„ ì¦ê°€í•  ë•Œ"\*\*ë¥¼ ë¬»ê¸°ë„ í•©ë‹ˆë‹¤.

  * 1ì‚´ ì¦ê°€ ì˜¤ì¦ˆë¹„ = $\exp(\text{coef})$
  * 10ì‚´ ì¦ê°€ ì˜¤ì¦ˆë¹„ = $\exp(\text{coef} \times 10)$

**í’€ì´ ì½”ë“œ:**

```python
coef_age = model.params['Age']
odds_ratio_10 = np.exp(coef_age * 10) # ê³„ìˆ˜ì— 10ì„ ê³±í•˜ê³  exp

print(f"ë‚˜ì´ 10ì‚´ ì¦ê°€ ì‹œ ì˜¤ì¦ˆë¹„: {round(odds_ratio_10, 4)}")
```

-----

## ğŸ“ ì‹œí—˜ì¥ìš© ì¹˜íŠ¸ì‹œíŠ¸ (ë³µì‚¬í•´ì„œ ì™¸ìš°ì„¸ìš”\!)

```python
import numpy as np
from statsmodels.formula.api import logit

# 1. ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = logit('Target ~ var1 + var2', data=df).fit()

# 2. íšŒê·€ê³„ìˆ˜ í™•ì¸ (coef)
print(model.params['var1'])

# 3. ì˜¤ì¦ˆë¹„(Odds Ratio) ê³„ì‚° (ë¬¸ì œ: var1ì˜ ì˜¤ì¦ˆë¹„ëŠ”?)
# ê³µì‹: exp(coef)
or_val = np.exp(model.params['var1'])

# 4. í™•ë¥  ì˜ˆì¸¡ ë° ê°œìˆ˜ ì„¸ê¸° (ë¬¸ì œ: í™•ë¥  0.5 ì´ìƒì¸ ê°œìˆ˜ëŠ”?)
probs = model.predict(df)
count = sum(probs >= 0.5) # ë˜ëŠ” len(probs[probs >= 0.5])
```

ì´ê²ƒë§Œ ì•Œë©´ 3ìœ í˜• ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¬¸ì œëŠ” ë‹¤ í’€ ìˆ˜ ìˆìŠµë‹ˆë‹¤\!

`model.params['Group[T.Treatment]']`ë¼ëŠ” ì´ë¦„ì´ ì¡°ê¸ˆ ë³µì¡í•˜ê³  ë‚¯ì„¤ì–´ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ê²ƒì€ **`statsmodels` ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë²”ì£¼í˜•(ë¬¸ìì—´) ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë…íŠ¹í•œ ë°©ì‹** ë•Œë¬¸ì…ë‹ˆë‹¤. í•˜ë‚˜ì”© ìª¼ê°œì„œ ì•„ì£¼ ì‰½ê²Œ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”.

---

### 1. ì™œ ì´ëŸ° ì´ë¦„ì´ ìƒê²¼ë‚˜ìš”? (ìë™ ë”ë¯¸ ë³€ìˆ˜í™”)

ìš°ë¦¬ê°€ ê°€ì§„ ë°ì´í„° `df['Group']`ì—ëŠ” **'Control'**ê³¼ **'Treatment'**ë¼ëŠ” ë‘ ê°€ì§€ ë¬¸ìì—´ì´ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.

í•˜ì§€ë§Œ íšŒê·€ë¶„ì„ ìˆ˜ì‹ì€ **ìˆ«ì**ë§Œ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ `statsmodels`ëŠ” ìš°ë¦¬ê°€ ì‹œí‚¤ì§€ ì•Šì•„ë„ ë‚´ë¶€ì ìœ¼ë¡œ ì´ë ‡ê²Œ ë³€í™˜í•©ë‹ˆë‹¤.

1.  **ë¬¸ìì—´ ë°œê²¬!**: "ì–´? `Group` ì»¬ëŸ¼ì— ê¸€ìê°€ ìˆë„¤?"
2.  **ê¸°ì¤€(Reference) ì •í•˜ê¸°**: "ì•ŒíŒŒë²³ ìˆœì„œë¡œ **'Control'**ì´ **'Treatment'**ë³´ë‹¤ ë¨¼ì €ë„¤? ê·¸ëŸ¼ **'Control'ì„ ê¸°ì¤€(0)**ìœ¼ë¡œ ì¡ì."
3.  **ë³€ìˆ˜ ë§Œë“¤ê¸°**: "ê·¸ëŸ¼ ë‚¨ì€ **'Treatment'**ê°€ 1ì¸ ë³€ìˆ˜ë¥¼ ë§Œë“¤ì."

ì´ë•Œ ë§Œë“¤ì–´ì§„ ë³€ìˆ˜ì˜ ì´ë¦„ì´ ë°”ë¡œ **`Group[T.Treatment]`**ì…ë‹ˆë‹¤.

* **Group**: ì›ë˜ ì»¬ëŸ¼ ì´ë¦„
* **T.**: Treatment Codingì˜ ì•½ìë¡œ, "ì´ ë³€ìˆ˜ëŠ” ë²”ì£¼í˜•ì…ë‹ˆë‹¤"ë¼ê³  í‘œì‹œí•˜ëŠ” ê¼¬ë¦¬í‘œ
* **Treatment**: í˜„ì¬ 1ë¡œ í‘œì‹œí•˜ê³  ìˆëŠ” ê°’

---

### 2. 'Control'ì€ ì–´ë”” ê°”ë‚˜ìš”? (ê¸°ì¤€ ì§‘ë‹¨)

ì´ê²Œ ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ì…ë‹ˆë‹¤. **ê¸°ì¤€ì´ ë˜ëŠ” ì§‘ë‹¨(Reference Group)ì€ íšŒê·€ì‹ì—ì„œ ì‚¬ë¼ì§‘ë‹ˆë‹¤(ìˆ¨ê²¨ì§‘ë‹ˆë‹¤).**



* **Control (ëŒ€ì¡°êµ°):** ê¸°ì¤€ì ì…ë‹ˆë‹¤. (ì‹ì—ì„œ ìƒëµë¨, $X=0$)
* **Treatment (íˆ¬ì•½êµ°):** ë¹„êµ ëŒ€ìƒì…ë‹ˆë‹¤. (ì‹ì— ë“±ì¥í•¨, $X=1$)

ë”°ë¼ì„œ `Group[T.Treatment]`ì˜ íšŒê·€ê³„ìˆ˜(coef)ëŠ” **"Control ê·¸ë£¹(0)ê³¼ ë¹„êµí–ˆì„ ë•Œ, Treatment ê·¸ë£¹(1)ì€ ì–¼ë§ˆë‚˜ ì°¨ì´ê°€ ë‚˜ëŠ”ê°€?"**ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.

---

### 3. ì‹¤ì œ í•´ì„ ì˜ˆì‹œ

ë§Œì•½ `coef = 1.5`ê°€ ë‚˜ì™”ë‹¤ë©´?

* **ì˜ëª»ëœ í•´ì„:** "Treatment ê·¸ë£¹ì˜ ì ìˆ˜ëŠ” 1.5ì ì´ë‹¤."
* **ì˜¬ë°”ë¥¸ í•´ì„:** "Treatment ê·¸ë£¹ì€ **Control ê·¸ë£¹ë³´ë‹¤** (ë¡œê·¸ ì˜¤ì¦ˆê°€) **1.5ë§Œí¼ ë†’ë‹¤.**"

> **ğŸ’¡ ìš”ì•½ (ì‹œí—˜ìš© ì•”ê¸°)**
>
> * `statsmodels`ëŠ” ë¬¸ìì—´ ë³€ìˆ˜ë¥¼ ë„£ìœ¼ë©´ **ì•ŒíŒŒë²³ ìˆœì„œê°€ ë¹ ë¥¸ ë†ˆì„ ê¸°ì¤€(0)**ìœ¼ë¡œ ì‚¼ëŠ”ë‹¤.
> * ê²°ê³¼í‘œ(`summary`)ì— ë‚˜ì˜¨ ë†ˆì€ **ê¸°ì¤€ê³¼ ë¹„êµë˜ëŠ” ë†ˆ(1)**ì´ë‹¤.
> * `Group[T.Treatment]` ê³„ìˆ˜ëŠ” **"ê¸°ì¤€(Control) ëŒ€ë¹„ íš¨ê³¼"**ì´ë‹¤.

ê²°ë¡ ë¶€í„° ë§ì”€ë“œë¦¬ë©´ **"ë…ë¦½ë³€ìˆ˜ê°€ 'ë²”ì£¼í˜•(Categorical)'ì¼ ë•Œë§Œ"** `C()`ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.

ë…ë¦½ë³€ìˆ˜ê°€ \*\*ìˆ˜ì¹˜í˜•(ì—°ì†í˜•)\*\*ì´ë¼ë©´ `C()`ë¥¼ ì“°ì§€ ë§ê³  ë³€ìˆ˜ëª…ë§Œ ê·¸ëŒ€ë¡œ ì¨ì•¼ í•©ë‹ˆë‹¤. ì‹œí—˜ì—ì„œ í—·ê°ˆë¦¬ì§€ ì•Šê²Œ ë”± ì •ë¦¬í•´ ë“œë¦´ê²Œìš”.

-----

### âš¡ï¸ `C()` ì‚¬ìš© ê¸°ì¤€í‘œ (ë¬´ì¡°ê±´ ì•”ê¸°\!)

`C()`ëŠ” \*\*"Categorical(ë²”ì£¼í˜•)"\*\*ì˜ ì•½ìì…ë‹ˆë‹¤.

| ë³€ìˆ˜ ì¢…ë¥˜ | ë°ì´í„° ì˜ˆì‹œ | `C()` ì‚¬ìš© ì—¬ë¶€ | ì½”ë“œ ì‘ì„±ë²• |
| :--- | :--- | :--- | :--- |
| **ë²”ì£¼í˜•** (ë¬¸ì) | ë‚¨/ì—¬, Aë°˜/Bë°˜, íˆ¬ì•½êµ°/ëŒ€ì¡°êµ° | **í•„ìˆ˜ (O)** | `C(Gender)`, `C(Group)` |
| **ë²”ì£¼í˜•** (ìˆ«ì) | 1ë°˜/2ë°˜/3ë°˜, ë“±ê¸‰(1,2,3) | **í•„ìˆ˜ (O)** | `C(Class)`, `C(Rank)` |
| **ìˆ˜ì¹˜í˜•** (ìˆ«ì) | ë‚˜ì´(25, 30), í‚¤(175), ì˜¨ë„(36.5) | **ì‚¬ìš© ì•ˆ í•¨ (X)** | `Age`, `Height` |

-----

### ğŸ§ ì™œ êµ¬ë¶„í•´ì•¼ í•˜ë‚˜ìš”? (ì¤‘ìš”)

**1. ìˆ«ìë¡œ ëœ ë²”ì£¼í˜• (ì˜ˆ: 1ë°˜, 2ë°˜, 3ë°˜)**

  * **`C(Class)`ë¼ê³  ì“°ë©´:** "ì•„, ì´ê±´ ìˆ«ìê°€ ì•„ë‹ˆë¼ \*\*'ì´ë¦„í‘œ'\*\*êµ¬ë‚˜\!"ë¼ê³  ì¸ì‹í•´ì„œ, 1ë°˜ vs 2ë°˜ vs 3ë°˜ì„ ê°ê° ë¹„êµí•©ë‹ˆë‹¤. (ì˜¬ë°”ë¦„)
  * **ê·¸ëƒ¥ `Class`ë¼ê³  ì“°ë©´:** "ì•„, ì´ê±´ **ìˆ«ì**êµ¬ë‚˜\! 3ë°˜ì€ 1ë°˜ë³´ë‹¤ **3ë°° ë” ê°•ë ¥**í•˜êµ¬ë‚˜\!"ë¼ê³  ì°©ê°í•˜ê³  ê³„ì‚°í•©ë‹ˆë‹¤. (í‹€ë¦¼)

**2. ì§„ì§œ ìˆ˜ì¹˜í˜• (ì˜ˆ: ë‚˜ì´ 20ì„¸, 30ì„¸)**

  * **ê·¸ëƒ¥ `Age`ë¼ê³  ì“°ë©´:** "ë‚˜ì´ê°€ ë§ì•„ì§ˆìˆ˜ë¡ ê²°ê³¼ê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€(ê¸°ìš¸ê¸°)"ë¥¼ ë´…ë‹ˆë‹¤. (ì˜¬ë°”ë¦„)
  * **`C(Age)`ë¼ê³  ì“°ë©´:** 20ì‚´ ê·¸ë£¹, 21ì‚´ ê·¸ë£¹... 80ì‚´ ê·¸ë£¹ê¹Œì§€ **ëª¨ë“  ë‚˜ì´ë¥¼ ë³„ê°œì˜ ê·¸ë£¹**ìœ¼ë¡œ ìª¼ê°œì„œ ë¶„ì„í•©ë‹ˆë‹¤. (ëª¨ë¸ì´ ì—‰ë§ì´ ë¨)

-----

### ğŸ“ ì‹œí—˜ ë¬¸ì œ ìœ í˜•ë³„ ì ìš©

#### 1\. ë¶„ì‚°ë¶„ì„ (ANOVA) â¡ï¸ 99% `C()` ì‚¬ìš©

ANOVAëŠ” ì• ì´ˆì— \*\*"ê·¸ë£¹ ê°„ ì°¨ì´"\*\*ë¥¼ ë³´ëŠ” ê²ƒì´ë¯€ë¡œ, ë…ë¦½ë³€ìˆ˜ê°€ í•­ìƒ **ë²”ì£¼í˜•**ì…ë‹ˆë‹¤.

```python
# Diet(A, B, C)ì— ë”°ë¥¸ ì²´ì¤‘ ë³€í™”
model = ols('Weight_Loss ~ C(Diet)', data=df).fit()
```

#### 2\. íšŒê·€ë¶„ì„ (Regression) â¡ï¸ ì„ì—¬ ìˆìŒ

ë…ë¦½ë³€ìˆ˜ ì„±ê²©ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.

```python
# ë‚˜ì´(ìˆ˜ì¹˜), BMI(ìˆ˜ì¹˜), ì„±ë³„(ë²”ì£¼)ë¡œ í˜ˆì•• ì˜ˆì¸¡
# Age, BMIëŠ” ê·¸ëƒ¥ ì“°ê³ , Sexë§Œ C()ë¥¼ ì”Œì›€
model = ols('BP ~ Age + BMI + C(Sex)', data=df).fit()
```

> **ğŸ’¡ ê¿€íŒ:**
> `statsmodels`ëŠ” ë°ì´í„°ê°€ \*\*'ë¬¸ìì—´(String)'\*\*ì´ë©´ `C()`ë¥¼ ì•ˆ ì¨ë„ ì•Œì•„ì„œ ë²”ì£¼í˜•ìœ¼ë¡œ ì¸ì‹í•´ ì£¼ê¸´ í•©ë‹ˆë‹¤.
> í•˜ì§€ë§Œ, \*\*ë°ì´í„°ê°€ ìˆ«ì(1, 2, 3)ë¡œ ë˜ì–´ ìˆëŠ” ë²”ì£¼í˜•(ë“±ê¸‰, ë°˜ ë²ˆí˜¸)\*\*ì¼ ë•ŒëŠ” **ë°˜ë“œì‹œ `C()`ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.**
>
> **ê²°ë¡ :** í—·ê°ˆë¦¬ë©´ \*\*"ê·¸ë£¹ì„ ë‚˜ëˆ„ëŠ” ë³€ìˆ˜ë‹¤ ì‹¶ìœ¼ë©´ ë¬´ì¡°ê±´ `C()`ë¥¼ ì”Œìš´ë‹¤"\*\*ê³  ìƒê°í•˜ì„¸ìš”.

`anova_lm`ì˜ ê²°ê³¼ë¡œ ë‚˜ì˜¤ëŠ” \*\*ë¶„ì‚°ë¶„ì„í‘œ(ANOVA Table)\*\*ëŠ” ì²˜ìŒ ë³´ë©´ ìˆ«ìê°€ ë§ì•„ì„œ ë³µì¡í•´ ë³´ì´ì§€ë§Œ, ì‹œí—˜ì—ì„œ ë¬¼ì–´ë³´ëŠ” ê±´ ì •í•´ì ¸ ìˆìŠµë‹ˆë‹¤.

**"ì–´ë””ë¥¼ ë´ì•¼ ì •ë‹µì„ ì°¾ì„ ìˆ˜ ìˆëŠ”ì§€"** ë”± ì§‘ì–´ ë“œë¦´ê²Œìš”.

-----

### ğŸ“Š ANOVA í…Œì´ë¸” í•´ë¶€ë„

`statsmodels`ë¡œ ì¶œë ¥í•œ í‘œëŠ” ë³´í†µ ì•„ë˜ì™€ ê°™ì´ ìƒê²¼ìŠµë‹ˆë‹¤.

| Index (í–‰ ì´ë¦„) | **df** (ììœ ë„) | **sum\_sq** (ì œê³±í•©) | **mean\_sq** (í‰ê· ì œê³±) | **F** (Fí†µê³„ëŸ‰) | **PR(\>F)** (p-value) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **C(Diet)** <br>(ìš”ì¸/ê·¸ë£¹) | 2.0 | 355.5 | 177.75 | **11.5** | **0.0003** |
| **Residual** <br>(ì˜¤ì°¨/ì”ì°¨) | 147.0 | 2205.0 | 15.0 | NaN | NaN |

-----

### 1\. í•µì‹¬ ì»¬ëŸ¼ 3ëŒ€ì¥ (ì‹œí—˜ì— ë¬´ì¡°ê±´ ë‚˜ì˜´)

ì‹œí—˜ ë¬¸ì œì—ì„œ "ë¬´ì—‡ì„ êµ¬í•˜ì‹œì˜¤"ë¼ê³  í•  ë•Œ ë´ì•¼ í•  ê³³ì…ë‹ˆë‹¤.

#### â‘  `F` (F-í†µê³„ëŸ‰)

  * **ìœ„ì¹˜:** ê·¸ë£¹ í–‰(`C(Diet)`)ì˜ **F** ì»¬ëŸ¼
  * **ì˜ë¯¸:** (ê·¸ë£¹ ê°„ ì°¨ì´) Ã· (ê·¸ë£¹ ë‚´ ì°¨ì´)
  * **í•´ì„:** ì´ ìˆ«ìê°€ **í´ìˆ˜ë¡** "ê·¸ë£¹ ê°„ì˜ ì°¨ì´ê°€ í™•ì‹¤í•˜ë‹¤"ëŠ” ëœ»ì…ë‹ˆë‹¤.
  * **ì‹œí—˜ ë¬¸ì œ:** "F-í†µê³„ëŸ‰ì„ êµ¬í•˜ì‹œì˜¤" â¡ï¸ **`table.loc['C(Diet)', 'F']`**

#### â‘¡ `PR(>F)` (p-value, ìœ ì˜í™•ë¥ ) â­ê°€ì¥ ì¤‘ìš”

  * **ìœ„ì¹˜:** ê·¸ë£¹ í–‰(`C(Diet)`)ì˜ **PR(\>F)** ì»¬ëŸ¼
  * **ì´ë¦„ì˜ ëœ»:** "F-í†µê³„ëŸ‰ì´ ì´ ê°’ë³´ë‹¤ í´(\>) í™•ë¥ (Probability)" â¡ï¸ ì¦‰, **p-value**ì…ë‹ˆë‹¤.
  * **í•´ì„:**
      * **0.05ë³´ë‹¤ ì‘ìœ¼ë©´:** "ê·¸ë£¹ ê°„ í‰ê·  ì°¨ì´ê°€ **ìˆë‹¤**." (ê·€ë¬´ê°€ì„¤ ê¸°ê°)
      * **0.05ë³´ë‹¤ í¬ë©´:** "ê·¸ë£¹ ê°„ í‰ê·  ì°¨ì´ê°€ **ì—†ë‹¤**." (ê·€ë¬´ê°€ì„¤ ì±„íƒ)
  * **ì‹œí—˜ ë¬¸ì œ:** "p-ê°’ì„ êµ¬í•˜ì‹œì˜¤" â¡ï¸ **`table.loc['C(Diet)', 'PR(>F)']`**

#### â‘¢ `sum_sq` (ì œê³±í•©, Sum of Squares)

  * **ìœ„ì¹˜:**
      * **SSR (ì²˜ë¦¬ ì œê³±í•©):** `C(Diet)` í–‰ì˜ `sum_sq` (ê·¸ë£¹ ê°„ ì°¨ì´ì˜ ì´ëŸ‰)
      * **SSE (ì”ì°¨ ì œê³±í•©):** `Residual` í–‰ì˜ `sum_sq` (ì„¤ëª… ì•ˆ ë˜ëŠ” ì˜¤ì°¨ì˜ ì´ëŸ‰)
  * **ì‹œí—˜ ë¬¸ì œ:** "ì”ì°¨ ì œê³±í•©(SSE)ì„ êµ¬í•˜ì‹œì˜¤" â¡ï¸ **`table.loc['Residual', 'sum_sq']`**

-----

### 2\. ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ (ê°œë… ì´í•´ìš©)

#### â‘£ `df` (ììœ ë„, Degrees of Freedom)

  * **C(Diet)ì˜ df:** (ê·¸ë£¹ ìˆ˜ - 1). ì˜ˆ: ê·¸ë£¹ì´ 3ê°œ(A, B, C)ë©´ 2.
  * **Residualì˜ df:** (ì „ì²´ ë°ì´í„° ìˆ˜ - ê·¸ë£¹ ìˆ˜).

#### â‘¤ `mean_sq` (í‰ê· ì œê³±, Mean Squares)

  * **ê³„ì‚°ë²•:** `sum_sq` Ã· `df`
  * ë¶„ì‚°(Variance)ì„ ì¶”ì •í•œ ê°’ì…ë‹ˆë‹¤.
  * F-í†µê³„ëŸ‰ì€ ê²°êµ­ `mean_sq(ê·¸ë£¹)` Ã· `mean_sq(ì”ì°¨)`ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.

-----

### âš¡ï¸ í•œ ì¥ ìš”ì•½ (ì‹œí—˜ì¥ìš©)

ì½”ë“œë¡œ ê°’ì„ ë½‘ì•„ë‚¼ ë•Œ \*\*ì¸ë±ìŠ¤(í–‰ ì´ë¦„)\*\*ë¥¼ í‹€ë¦¬ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.

```python
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm

model = ols('Weight_Loss ~ C(Diet)', data=df).fit()
table = anova_lm(model)

# 1. F-í†µê³„ëŸ‰
print(table.loc['C(Diet)', 'F'])

# 2. p-value (PR(>F))
print(table.loc['C(Diet)', 'PR(>F)'])

# 3. ì”ì°¨ ì œê³±í•© (SSE) -> í–‰ ì´ë¦„ì´ 'Residual'ì„ì— ì£¼ì˜!
print(table.loc['Residual', 'sum_sq'])
```

**íŒ:** `print(table)`ì„ ë¨¼ì € í•´ì„œ í‘œì˜ í–‰/ì—´ ì´ë¦„ì„ ëˆˆìœ¼ë¡œ í™•ì¸í•˜ê³ , `loc`ì„ ì‚¬ìš©í•˜ë©´ ì‹¤ìˆ˜ë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‹œí—˜ ì¤€ë¹„ë¥¼ ìœ„í•´ `statsmodels` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œ ì„ í˜•íšŒê·€(OLS)ì™€ ë¡œì§€ìŠ¤í‹± íšŒê·€(Logit) í•µì‹¬ ì½”ë“œë¥¼ ë¨¼ì € ì •ë¦¬í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê·¸ í›„, í•´ë‹¹ ê°œë…ì„ í™•ì¸í•˜ëŠ” ì—°ìŠµ ë¬¸ì œë¥¼ í’€ì–´ë³´ì„¸ìš”.

### ğŸ“š ì‹œí—˜ ëŒ€ë¹„: statsmodels í•µì‹¬ ì½”ë“œ ì •ë¦¬

ë¹…ë°ì´í„° ë¶„ì„ê¸°ì‚¬ ì‹¤ê¸° ë“± íŒŒì´ì¬ ê¸°ë°˜ í†µê³„ ë¶„ì„ ì‹œí—˜ì—ì„œëŠ” `statsmodels.formula.api`ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ìˆ˜ì‹ì„ ì§ê´€ì ìœ¼ë¡œ ì‘ì„±í•  ìˆ˜ ìˆì–´ ìœ ë¦¬í•©ë‹ˆë‹¤.

#### 1\. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

```python
import numpy as np
import pandas as pd
from statsmodels.formula.api import ols, logit
```

#### 2\. ë‹¤ì¤‘ ì„ í˜• íšŒê·€ (OLS: Ordinary Least Squares)

ì—°ì†í˜• ì¢…ì†ë³€ìˆ˜($Y$)ë¥¼ ì˜ˆì¸¡í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
# ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ (Formula: 'ì¢…ì†ë³€ìˆ˜ ~ ë…ë¦½ë³€ìˆ˜1 + ë…ë¦½ë³€ìˆ˜2')
# data: ë°ì´í„°í”„ë ˆì„ ì´ë¦„
model = ols('target ~ feature1 + feature2', data=df).fit()

# ê²°ê³¼ ìš”ì•½ (íšŒê·€ê³„ìˆ˜, p-value, R-squared í™•ì¸)
print(model.summary())

# íšŒê·€ê³„ìˆ˜ë§Œ í™•ì¸
print(model.params)

# ì˜ˆì¸¡ (í…ŒìŠ¤íŠ¸ ë°ì´í„°)
pred = model.predict(test_df)
```

âœ… ì œ3ìœ í˜• (í†µê³„): ë¬´ì¡°ê±´ ols ì“°ì„¸ìš”! (sm.OLS X)
ì‹œí—˜ ë¬¸ì œì—ì„œ "íšŒê·€ê³„ìˆ˜ì˜ p-valueë¥¼ êµ¬í•˜ì‹œì˜¤" ë˜ëŠ” **"ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ë¥¼ ì°¾ìœ¼ì‹œì˜¤"**ë¼ê³  ë¬»ìŠµë‹ˆë‹¤.

#### 3\. ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logit)

ì´ì§„ ë¶„ë¥˜(0 ë˜ëŠ” 1) ì¢…ì†ë³€ìˆ˜($Y$)ë¥¼ ì˜ˆì¸¡í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
# ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
model = logit('target ~ feature1 + feature2', data=df).fit()

# ê²°ê³¼ ìš”ì•½ (Pseudo R-squared, Log-Likelihood í™•ì¸)
print(model.summary())

# â˜… ì¤‘ìš”: ì˜¤ì¦ˆë¹„(Odds Ratio) êµ¬í•˜ê¸°
# model.paramsëŠ” 'ë¡œê·¸ ì˜¤ì¦ˆ(Log-Odds)' ê°’ì´ë¯€ë¡œì§€ìˆ˜í•¨ìˆ˜(exp)ë¥¼ ì·¨í•´ì•¼ ì˜¤ì¦ˆë¹„ê°€ ë¨
odds_ratios = np.exp(model.params)
print(odds_ratios)

# ì˜ˆì¸¡ (ê²°ê³¼ëŠ” 0~1 ì‚¬ì´ì˜ í™•ë¥ ê°’ìœ¼ë¡œ ë°˜í™˜ë¨)
pred_prob = model.predict(test_df)

# í™•ë¥ ì„ 0/1 í´ë˜ìŠ¤ë¡œ ë³€í™˜ (ì„ê³„ê°’ 0.5 ê¸°ì¤€)
pred_class = np.where(pred_prob > 0.5, 1, 0)
```

-----

ê·¸ëŸ¼ ì´ì œ í•™ìŠµí•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì „ ê°ê°ì„ ìµí˜€ë³¼ê¹Œìš”?

ì„ í˜•íšŒê·€ì™€ ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ ê°œë…, ì½”ë“œ ì‚¬ìš©ë²•, ê²°ê³¼ í•´ì„ì— ëŒ€í•œ í€´ì¦ˆì…ë‹ˆë‹¤.

ë¹…ë°ì´í„° ë¶„ì„ê¸°ì‚¬ ì‹¤ê¸° ì‹œí—˜ì—ì„œ **ëª¨ë¸ í•™ìŠµ í›„(`.fit()`)** ë½‘ì•„ë‚¼ ìˆ˜ ìˆëŠ” í•µì‹¬ ì†ì„±(Attribute)ë“¤ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ë³„ë¡œ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.

ì‹œí—˜ì¥ì—ì„œëŠ” **`dir(model)`** ëª…ë ¹ì–´ë¥¼ ì¹˜ë©´ ëª¨ë“  ì†ì„±ì„ ë³¼ ìˆ˜ ìˆì§€ë§Œ, ì‹œê°„ì´ ì—†ìœ¼ë‹ˆ ì•„ë˜ í•µì‹¬ ì†ì„±ë“¤ì€ ì™¸ì›Œê°€ëŠ” ê²Œ ì¢‹ìŠµë‹ˆë‹¤.

-----

### 1\. ğŸ“‰ Statsmodels (ì œ3ìœ í˜• - í†µê³„ìš©)

ì£¼ë¡œ \*\*`ols` (ì„ í˜•íšŒê·€)\*\*ì™€ \*\*`logit` (ë¡œì§€ìŠ¤í‹±íšŒê·€)\*\*ë¥¼ ì‚¬ìš©í•œ ë’¤, **`.fit()`ìœ¼ë¡œ ìƒì„±ëœ ê°ì²´**ì—ì„œ ë½‘ì•„ëƒ…ë‹ˆë‹¤.

```python
from statsmodels.formula.api import ols, logit
# í•™ìŠµ ì™„ë£Œëœ ê°ì²´
model = ols('y ~ x1 + x2', data=df).fit() 
```

| ì†ì„± ì´ë¦„ | ì„¤ëª… | ì‚¬ìš© ì˜ˆì‹œ (ì½”ë“œ) | ëŒ€ìƒ ëª¨ë¸ |
| :--- | :--- | :--- | :--- |
| **`params`** | **íšŒê·€ê³„ìˆ˜** (Coefficient) | `model.params['x1']` | ì „ì²´ |
| **`pvalues`** | **p-ê°’** (ìœ ì˜í™•ë¥ ) | `model.pvalues['x1']` | ì „ì²´ |
| **`rsquared`** | **ê²°ì •ê³„ìˆ˜** ($R^2$) | `model.rsquared` | OLS (ì„ í˜•íšŒê·€) |
| **`rsquared_adj`**| **ìˆ˜ì •ëœ ê²°ì •ê³„ìˆ˜** | `model.rsquared_adj` | OLS (ì„ í˜•íšŒê·€) |
| **`prsquared`** | **ìœ ì‚¬ ê²°ì •ê³„ìˆ˜** (Pseudo $R^2$) | `model.prsquared` | Logit (ë¡œì§€ìŠ¤í‹±) |
| **`conf_int()`** | **ì‹ ë¢°êµ¬ê°„** | `model.conf_int()` | ì „ì²´ |
| **`resid`** | **ì”ì°¨** (ì‹¤ì œê°’ - ì˜ˆì¸¡ê°’) | `model.resid` | ì „ì²´ |
| **`fittedvalues`**| **ì˜ˆì¸¡ê°’** (í•™ìŠµ ë°ì´í„°ì— ëŒ€í•œ) | `model.fittedvalues` | ì „ì²´ |
| **`aic` / `bic`** | ëª¨ë¸ ì í•©ë„ ì§€ìˆ˜ | `model.aic`, `model.bic` | ì „ì²´ |

> **ğŸ’¡ ê¿€íŒ:** `model.summary()`ë¥¼ ì°ì–´ë³´ë©´ ì´ ëª¨ë“  ê²Œ í‘œë¡œ ë‚˜ì˜µë‹ˆë‹¤. í•˜ì§€ë§Œ ë¬¸ì œì—ì„œ \*\*"ê°’ í•˜ë‚˜ë§Œ ì œì¶œí•˜ì‹œì˜¤"\*\*ë¼ê³  í•˜ë©´ ìœ„ ì†ì„±ì„ ì¨ì„œ ìˆ«ìë¡œ ë”± ë½‘ì•„ì•¼ í•©ë‹ˆë‹¤.

-----

### 2\. ğŸ¤– Scikit-Learn (ì œ2ìœ í˜• - ë¨¸ì‹ ëŸ¬ë‹ìš©)

Scikit-learn ëª¨ë¸ì€ í•™ìŠµ í›„ ì†ì„± ì´ë¦„ ë’¤ì— \*\*ì–¸ë”ë°”(`_`)\*\*ê°€ ë¶™ëŠ” ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤.

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LinearRegression

model = RandomForestClassifier().fit(X, y)
lr = LinearRegression().fit(X, y)
```

| ì†ì„± ì´ë¦„ | ì„¤ëª… | ì‚¬ìš© ì˜ˆì‹œ (ì½”ë“œ) | ëŒ€ìƒ ëª¨ë¸ |
| :--- | :--- | :--- | :--- |
| **`feature_importances_`** | **ë³€ìˆ˜ ì¤‘ìš”ë„** (ì–´ë–¤ ì»¬ëŸ¼ì´ ì¤‘ìš”í•œì§€) | `model.feature_importances_` | íŠ¸ë¦¬ ê³„ì—´ (RandomForest, XGBoost) |
| **`coef_`** | **íšŒê·€ê³„ìˆ˜** (ê¸°ìš¸ê¸°) | `lr.coef_` | ì„ í˜•íšŒê·€, ë¡œì§€ìŠ¤í‹±íšŒê·€ |
| **`intercept_`** | **ì ˆí¸** (ìƒìˆ˜í•­, yì ˆí¸) | `lr.intercept_` | ì„ í˜•íšŒê·€, ë¡œì§€ìŠ¤í‹±íšŒê·€ |
| **`classes_`** | **í´ë˜ìŠ¤ ì¢…ë¥˜** (0, 1 ë“±) | `model.classes_` | ë¶„ë¥˜ ëª¨ë¸ (Classifier) |
| **`n_features_in_`** | í•™ìŠµì— ì‚¬ìš©ëœ **ë³€ìˆ˜(ì»¬ëŸ¼) ê°œìˆ˜** | `model.n_features_in_` | ì „ì²´ |
| **`feature_names_in_`** | í•™ìŠµì— ì‚¬ìš©ëœ **ë³€ìˆ˜(ì»¬ëŸ¼) ì´ë¦„** | `model.feature_names_in_` | ì „ì²´ (ìµœì‹  ë²„ì „) |

-----

### âš¡ï¸ ì‹œí—˜ì¥ ê¸´ê¸‰ ìƒí™© ëŒ€ì²˜ë²• (`dir` í•¨ìˆ˜)

ì‹œí—˜ì¹˜ë‹¤ê°€ ì†ì„± ì´ë¦„ì´ ê¸°ì–µ ì•ˆ ë‚˜ë©´? **`dir()`** í•¨ìˆ˜ë¥¼ ì“°ì„¸ìš”\!
í•´ë‹¹ ê°ì²´ê°€ ê°€ì§„ ëª¨ë“  ê¸°ëŠ¥ê³¼ ì†ì„±ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.

```python
# ì˜ˆ: result = ols(...).fit() ì¼ ë•Œ
print(dir(result))

# ì¶œë ¥ ì˜ˆì‹œ:
# [..., 'aic', 'bic', 'conf_int', 'f_test', 'fittedvalues', 
#  'params', 'pvalues', 'predict', 'rsquared', 'summary', ...]
```

**í•µì‹¬ ìš”ì•½:**

1.  **3ìœ í˜•(í†µê³„):** `params`(ê³„ìˆ˜), `pvalues`(pê°’), `rsquared`(R2) ë¬´ì¡°ê±´ ì•”ê¸°.
2.  **2ìœ í˜•(ML):** `feature_importances_`(ì¤‘ìš”ë„) ì •ë„ë§Œ ì•Œë©´ ë¨. (ë‚˜ë¨¸ì§€ëŠ” `predict`ë§Œ ì˜í•˜ë©´ ë¨)

\*\*"ìœ ì˜í•˜ì§€ ì•Šë‹¤"\*\*ëŠ” í†µê³„ì ìœ¼ë¡œ \*\*"p-valueê°€ 0.05ë³´ë‹¤ í¬ë‹¤(\> 0.05)"\*\*ëŠ” ëœ»ì…ë‹ˆë‹¤.
(ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•  ìˆ˜ ì—†ìŒ = ìš°ì—°ì¼ ìˆ˜ ìˆìŒ = ì˜í–¥ë ¥ì´ í™•ì‹¤í•˜ì§€ ì•ŠìŒ)

`statsmodels`ì—ì„œ ì´ë¥¼ ì°¾ì•„ë‚´ëŠ” ë°©ë²•ì€ **`model.pvalues`** ì†ì„±ì„ ì´ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì‹œí—˜ì— ìì£¼ ë‚˜ì˜¤ëŠ” íŒ¨í„´ 2ê°€ì§€ë¡œ ì •ë¦¬í•´ ë“œë¦´ê²Œìš”.

-----

### 1\. ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ì˜ "ê°œìˆ˜" êµ¬í•˜ê¸°

ì‹œí—˜ ë¬¸ì œ: *"ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì—ì„œ ìœ ì˜í•˜ì§€ ì•Šì€ ì„¤ëª…ë³€ìˆ˜ì˜ ê°œìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì ˆí¸í•­ì€ ì œì™¸)"*

```python
# 1. ëª¨ë¸ í•™ìŠµ
model = ols('y ~ x1 + x2 + x3', data=df).fit()

# 2. ëª¨ë“  ë³€ìˆ˜ì˜ p-value í™•ì¸
# print(model.pvalues)

# 3. [í•µì‹¬] p-valueê°€ 0.05ë³´ë‹¤ í° ê²ƒë§Œ í•„í„°ë§ (True=1, False=0)
# Intercept(ì ˆí¸)ëŠ” ë³´í†µ ì„¤ëª…ë³€ìˆ˜ ê°œìˆ˜ì—ì„œ ë¹¼ë¯€ë¡œ [1:]ë¡œ ìŠ¬ë¼ì´ì‹±í•©ë‹ˆë‹¤.
target_vars = model.pvalues[1:] # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” Intercept
cnt = sum(target_vars > 0.05)

print(cnt)
```

### 2\. ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ì˜ "ì´ë¦„" ì°¾ê¸°

ì‹œí—˜ ë¬¸ì œ: *"ê°€ì¥ ìœ ì˜í•˜ì§€ ì•Šì€(p-ê°’ì´ ê°€ì¥ í°) ë³€ìˆ˜ì˜ ì´ë¦„ì„ ì ìœ¼ì‹œì˜¤."*

```python
# 1. ì„¤ëª…ë³€ìˆ˜(ì ˆí¸ ì œì™¸)ì˜ p-valueë§Œ ì¶”ì¶œ
vars_p = model.pvalues[1:]

# 2. p-ê°’ì´ 0.05ë³´ë‹¤ í° ë³€ìˆ˜ë“¤ì˜ ì´ë¦„ ì¶œë ¥
not_signif = vars_p[vars_p > 0.05].index
print("ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ë“¤:", list(not_signif))

# 3. ê°€ì¥ p-ê°’ì´ í°(ê°€ì¥ ì“¸ëª¨ì—†ëŠ”) ë³€ìˆ˜ í•˜ë‚˜ ì°¾ê¸°
worst_var = vars_p.idxmax()
print("ê°€ì¥ ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜:", worst_var)
```

-----

### âš¡ï¸ ìš”ì•½ (ì‹œí—˜ì¥ìš©)

1.  \*\*`model.pvalues`\*\*ë¥¼ ì“´ë‹¤.
2.  **`> 0.05`** ì¡°ê±´ì´ "ìœ ì˜í•˜ì§€ ì•Šì€" ê²ƒì´ë‹¤.
3.  \*\*`model.pvalues[1:]`\*\*ë¥¼ í•´ì„œ \*\*Intercept(ì ˆí¸)\*\*ë¥¼ ë¹¼ëŠ” ê²ƒì„ ìŠì§€ ì•ŠëŠ”ë‹¤. (ë¬¸ì œì—ì„œ "ì ˆí¸ í¬í•¨"ì´ë¼ í•˜ë©´ ê·¸ëƒ¥ ì”€)