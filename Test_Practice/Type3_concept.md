## 3유형의 핵심: '재판'으로 이해하는 가설 검정 ⚖️

모든 통계 검정은 "재판"입니다. 우리는 데이터라는 "증거"를 가지고 "용의자"를 재판대에 세웁니다.

  * **용의자:** 우리가 검증하고 싶은 가설 (예: "1등석과 3등석의 나이는 차이가 있다.")
  * **법정의 원칙 (무죄 추정):** **귀무가설 ($H_0$)**
      * "모든 것은 우연이며, 아무 차이도 없다." (예: "1등석과 3등석의 나이 평균은 같다.")
      * 이것이 우리가 \*\*기각(Rejection)\*\*시키고 싶은 대상입니다.
  * **검사의 주장 (우리의 주장):** **대립가설 ($H_1$)**
      * "우연이 아니다\! 여기엔 유의미한 차이가 있다\!" (예: "1등석과 3등석의 나이 평균은 다르다.")
  * **증거의 신뢰도:** **p-value (유의확률)**
      * 이것이 **가장 중요합니다.**
      * **p-value의 의미:** "귀무가설($H_0$)이 맞다(즉, 아무 차이가 없다)고 가정할 때, 지금 우리가 가진 이 데이터(증거)가 나올 확률"
      * **p-value가 낮다 (예: 0.01):** "아무 차이가 없는데 이런 데이터가 나올 확률이 1%라고? 말도 안 돼\! 이건 우연이 아니야\!"
      * **p-value가 높다 (예: 0.50):** "아무 차이가 없어도 이런 데이터는 50% 확률로 나올 수 있어. 충분히 우연일 수 있겠네."
  * **유죄 판결 기준:** **유의수준 ($\alpha$, alpha)**
      * "p-value가 이 기준보다 낮으면 유죄(대립가설 채택)로 판결하겠다\!"
      * 일반적으로 \*\*0.05 (5%)\*\*를 기준으로 씁니다.

### 📜 최종 판결 로직

> **`p-value <= 0.05` (5%보다 낮다)**
>
>   * "이 증거는 우연이라고 보기엔 너무 희귀하다\! (유의하다)"
>   * **판결:** **"귀무가설($H_0$)을 기각한다."**
>   * **결론:** 우리의 주장인 **대립가설($H_1$)을 채택**한다. (예: "두 집단의 나이 차이는 유의미하다\!")

> **`p-value > 0.05` (5%보다 높다)**
>
>   * "이 증거는 우연히 나올 수도 있다. (유의하지 않다)"
>   * **판결:** **"귀무가설($H_0$)을 기각하지 못한다."** (무죄 추정)
>   * **결론:** 대립가설을 채택할 근거가 부족하다. (예: "두 집단의 나이 차이가 있다고 말할 수 없다.")

-----

## 3유형 검정 '족보': 어떤 '재판'을 열어야 할까?

어떤 재판(검정)을 열지는 분석하려는 \*\*두 변수의 '타입'\*\*에 따라 결정됩니다.

| 변수 1 (X) | 변수 2 (Y) | 검정 방법 |
| :--- | :--- | :--- |
| **범주형 (2그룹)** | **수치형** | **t-검정 (t-test)** |
| **범주형 (3+그룹)**| **수치형** | **일원분산분석 (ANOVA)** |
| **범주형** | **범주형** | **카이제곱 검정 (Chi-squared)** |
| **수치형** | **수치형** | **피어슨 상관분석 (Pearson)** |

-----

## 1\. t-검정 (Independent t-test)

  * **🎯 언제 사용하나요?**
      * **"두 개의 그룹(범주형)"** 간의 \*\*"평균(수치형)"\*\*을 비교할 때.
  * **⚖️ 재판 비유:**
      * "타이타닉의 1등석 승객(`Pclass`=1)과 3등석 승객(`Pclass`=3)의 평균 나이(`Age`)는 다른가?"
      * $H_0$: "두 그룹의 평균 나이는 같다."
      * $H_1$: "두 그룹의 평균 나이는 다르다."
  * **❗ (필수) 사전 검토: 등분산 검정**
      * 본 재판(t-검정)을 열기 전, 두 그룹의 데이터가 얼마나 흩어져있는지(분산) 확인해야 합니다.
      * \*\*"두 그룹의 분산이 같은가?"\*\*를 먼저 검정합니다. (`scipy.stats.levene` 또는 F-검정)
      * 이 검정의 $H_0$: "두 그룹의 분산은 같다."
      * p-value \> 0.05 (분산이 같다) ➡️ `equal_var=True` 옵션
      * p-value \<= 0.05 (분산이 다르다) ➡️ `equal_var=False` 옵션
  * **🐍 Python 코드 예시:**
    ```python
    from scipy.stats import ttest_ind, levene

    # 1. 비교할 두 그룹의 'Age' 데이터 추출 (결측값 제거는 필수)
    group1 = df[df['Pclass'] == 1]['Age'].dropna()
    group3 = df[df['Pclass'] == 3]['Age'].dropna()

    # 2. (사전 검토) 레빈(Levene) 등분산 검정
    stat, p_levene = levene(group1, group3)
    print(f"등분산 검정 p-value: {p_levene}")

    is_equal_var = True # 기본값
    if p_levene <= 0.05:
        is_equal_var = False # 분산이 다르다고 판결

    # 3. (본 재판) t-검정 수행
    t_stat, p_value = ttest_ind(group1, group3, equal_var=is_equal_var)

    print(f"t-검정 p-value: {p_value}")
    if p_value <= 0.05:
        print("결론: 1등석과 3등석의 평균 나이는 유의미하게 다르다. (H0 기각)")
    else:
        print("결론: 평균 나이 차이가 유의미하다고 말할 수 없다. (H0 기각 실패)")
    ```

-----

## 2\. 일원분산분석 (ANOVA)

  * **🎯 언제 사용하나요?**
      * **"세 개 이상의 그룹(범주형)"** 간의 \*\*"평균(수치형)"\*\*을 비교할 때.
      * (t-검정의 '그룹 3개 이상' 버전)
  * **⚖️ 재판 비유:**
      * "1등석, 2등석, 3등석(`Pclass` 1, 2, 3) 간의 평균 나이(`Age`)는 다른가?"
      * $H_0$: "세 그룹의 평균 나이가 모두 같다."
      * $H_1$: "적어도 한 그룹의 평균 나이는 다르다."
      * **(주의\!)** ANOVA는 "누가" 다른지는 알려주지 않고, "다르다/안 다르다"만 알려줍니다.
  * **🐍 Python 코드 예시:**
    ```python
    from scipy.stats import f_oneway

    # 1. 비교할 세 그룹의 'Age' 데이터 추출 (결측값 제거 필수)
    group1 = df[df['Pclass'] == 1]['Age'].dropna()
    group2 = df[df['Pclass'] == 2]['Age'].dropna()
    group3 = df[df['Pclass'] == 3]['Age'].dropna()

    # 2. (본 재판) ANOVA 수행
    f_stat, p_value = f_oneway(group1, group2, group3)

    print(f"ANOVA p-value: {p_value}")
    if p_value <= 0.05:
        print("결론: 1, 2, 3등석 간 평균 나이는 유의미한 차이가 있다. (H0 기각)")
    else:
        print("결론: 등급 간 평균 나이 차이가 유의미하다고 말할 수 없다. (H0 기각 실패)")
    ```

-----

## 3\. 카이제곱 검정 (Chi-squared Test, $\chi^2$)

  * **🎯 언제 사용하나요?**
      * \*\*"범주형 변수"\*\*와 **"범주형 변수"** 간의 \*\*관련성(연관성)\*\*을 볼 때.
      * (평균이 아닌 '빈도수(count)'를 비교합니다.)
  * **⚖️ 재판 비유:**
      * "성별(`Sex`)과 생존 여부(`Survived`)는 서로 관련이 있는가?"
      * $H_0$: "성별과 생존 여부는 관련이 없다. (독립이다)"
      * $H_1$: "성별과 생존 여부는 관련이 있다. (독립이 아니다)"
  * **❗ (필수) 사전 작업: 교차표 (Crosstab)**
      * 카이제곱 검정은 "숫자"가 아닌 "표(table)"를 입력받습니다.
      * `pd.crosstab`을 사용해 두 변수의 빈도수를 표로 만듭니다.
  * **🐍 Python 코드 예시:**
    ```python
    import pandas as pd
    from scipy.stats import chi2_contingency

    # 1. (사전 작업) 교차표 생성
    crosstab = pd.crosstab(df['Sex'], df['Survived'])
    # print(crosstab)
    # Survived    0    1
    # Sex               
    # female     81  233
    # male      468  109

    # 2. (본 재판) 카이제곱 검정 수행
    # (통계량, p-value, 자유도, 기대빈도표)를 반환
    chi2_stat, p_value, dof, expected_freq = chi2_contingency(crosstab)

    print(f"카이제곱 p-value: {p_value}")
    if p_value <= 0.05:
        print("결론: 성별과 생존 여부는 유의미한 관련이 있다. (H0 기각)")
    else:
        print("결론: 성별과 생존 여부는 관련이 없다. (H0 기각 실패)")
    ```

-----

## 4\. 피어슨 상관분석 (Pearson Correlation)

  * **🎯 언제 사용하나요?**
      * \*\*"수치형 변수"\*\*와 **"수치형 변수"** 간의 \*\*"선형 관계"\*\*를 볼 때.
      * (한 변수가 증가할 때 다른 변수도 증가/감소하는가?)
  * **⚖️ 재판 비유:**
      * "승객의 나이(`Age`)와 지불한 요금(`Fare`)은 관계가 있는가?"
      * $H_0$: "두 변수는 선형 관계가 없다. (상관계수 = 0)"
      * $H_1$: "두 변수는 선형 관계가 있다. (상관계수 $\ne$ 0)"
  * **❗ (주의) p-value와 상관계수(r)는 다릅니다.**
      * **상관계수(r):** 관계의 **방향과 강도** (-1 \~ +1). 0.8이면 강한 양의 관계.
      * **p-value:** 이 관계가 **통계적으로 유의미한지(우연이 아닌지)**.
  * **🐍 Python 코드 예시:**
    ```python
    from scipy.stats import pearsonr

    # 1. 두 변수 추출 (결측값 제거 필수)
    # (두 변수에서 모두 결측값이 아닌 행만 사용해야 함)
    clean_df = df[['Age', 'Fare']].dropna()

    # 2. (본 재판) 피어슨 상관분석 수행
    # (상관계수, p-value)를 반환
    corr_r, p_value = pearsonr(clean_df['Age'], clean_df['Fare'])

    print(f"상관계수(r): {corr_r:.3f}")
    print(f"p-value: {p_value}")

    if p_value <= 0.05:
        print("결론: 나이와 요금 간에 유의미한 선형 관계가 있다. (H0 기각)")
    else:
        print("결론: 나이와 요금 간에 선형 관계가 있다고 말할 수 없다. (H0 기각 실패)")
    ```

    이 두 숫자는 상관분석의 핵심 결과입니다.

* `0.124` = **상관계수 (r)**
* `0.0002` = **p-value (유의확률)**

각각의 의미를 쉽게 설명해 드릴게요.

### 4.1. 상관계수 (r) = 0.124: "관계의 방향과 강도"

상관계수(r)는 -1에서 1 사이의 값을 가지며, 두 변수가 얼마나 가깝게 움직이는지 보여줍니다.

* **방향 (부호):** `+` 0.124는 **양수**입니다.
    * 이는 "양의 상관관계"를 의미합니다. (A 변수가 증가할 때 B 변수도 **증가하는 경향**이 있다.)
* **강도 (숫자 크기):** 0.124는 0에 매우 가깝습니다.
    * 1에 가까울수록 강한 관계이고, 0에 가까울수록 관계가 없습니다.
    * 0.1 ~ 0.3 사이는 보통 **"매우 약한(Very Weak)"** 또는 **"약한(Weak)"** 관계로 해석합니다.

> **➡️ 1번 결론:** "두 변수는 같은 방향으로 움직이는 **매우 약한** 관계가 있다."

---

### 4.2. p-value = 0.0002: "관계의 신뢰도"

p-value는 이 재판의 "판결문"입니다. 

* **의미:** "두 변수 간에 *아무 관계가 없다*(H0)고 가정할 때, 지금의 결과(r=0.124)가 우연히 나올 확률"
* **기준:** 유의수준 0.05 (5%)
* **판결:** `0.0002`는 `0.05`보다 **매우 작습니다.**

> **➡️ 2번 결론:** "이 관계가 우연일 확률(0.02%)은 매우 희박하다. 따라서 이 관계는 **통계적으로 유의미하다.**" (즉, 귀무가설 기각)

---

## 📜 그래서 최종 결론은?

이 두 가지를 조합하면 매우 흥미로운 결론이 나옵니다.

> "두 변수 간의 관계는 **매우 약하지만(r=0.124)**,
> 그 약한 관계가 **우연이 아니라 '실제로 존재한다'고 통계적으로 확신할 수 있다(p=0.0002).**"

저 멀리서 아주 희미한 불빛(매우 약한 관계)이 보이는데, 그게 신기루(우연)가 아니라 실제 불빛(통계적 유의미)이라고 확신하는 상황과 같습니다. (이런 결과는 데이터가 매우 많을 때 자주 나옵니다.)

    ## 📊 1. 분산분석 (ANOVA)이란 무엇인가?

**"t-검정의 3개 그룹 이상 확장판"**

**ANOVA** (Analysis of Variance)는 \*\*"분산"\*\*을 분석하지만, 그 목적은 \*\*"세 개 이상 집단의 평균이 같은지"\*\*를 검정하는 것입니다.

t-검정은 두 집단(예: 1반 vs 2반)의 평균만 비교할 수 있습니다. 3개 집단(1반, 2반, 3반)의 평균을 비교할 때 t-검정을 3번(1v2, 1v3, 2v3) 쓰면 안 되는지 궁금할 수 있습니다.

> **🚨 다중 비교 문제 (Multiple Comparisons Problem)**
>
> t-검정(유의수준 5%)을 여러 번 반복하면, "우연히 틀릴 확률(1종 오류)"이 5%보다 훨씬 더 커집니다. (예: 3번 실행 시 약 14.3%) 재판을 여러 번 해서 억지로 유죄를 만드는 셈입니다.
>
> ANOVA는 이 오류를 5%로 고정한 채, "단 한 번의 검정"으로 3개 이상 집단의 평균을 비교해 줍니다.

### 💡 ANOVA의 핵심 원리: F-통계량

ANOVA는 어떻게 "분산"을 이용해서 "평균"을 비교할까요?

"집단 간 분산"과 "집단 내 분산"이라는 두 가지 분산을 비교합니다.

1.  **집단 간 분산 (Between-group variance):**

      * 각 그룹의 "평균"이 전체 평균에서 얼마나 멀리 떨어져 있는지.
      * (A반 평균 50점, B반 평균 80점) ➡️ **집단 간 분산이 크다** = 그룹들이 서로 멀리 떨어져 있다.

2.  **집단 내 분산 (Within-group variance):**

      * 각 그룹 "내부"의 데이터가 얼마나 흩어져 있는지. (A반 학생들의 점수 분포)
      * ➡️ **집단 내 분산이 작다** = 그룹 구성원들이 자기 평균에 똘똘 뭉쳐있다.

**F-통계량 = (집단 간 분산) / (집단 내 분산)**

  * **F 값이 크다:** (집단끼리 멀리 떨어져 있음) / (집단 내부는 똘똘 뭉쳐있음)
      * **결론:** 이 그룹들은 명확히 다르다. **(H0 기각\!)**
  * **F 값이 작다:** (집단끼리 가깝게 붙어있음) / (집단 내부가 넓게 퍼져있음)
      * **결론:** 그룹 간 차이가 집단 내의 우연한 차이보다 작다. (H0 기각 실패)

> **⚖️ ANOVA의 가설**
>
>   * **$H_0$ (귀무가설):** 모든 집단의 평균은 같다. ($\mu_1 = \mu_2 = \mu_3$)
>   * **$H_1$ (대립가설):** 적어도 하나 이상의 집단 평균은 다르다.

-----

## 2\. Scipy vs Statsmodels: 언제 무엇을 쓸까?

두 라이브러리 모두 ANOVA를 수행하지만, 목적이 약간 다릅니다.

### 🔬 `scipy.stats.f_oneway`

  * **특징:** 빠르고, 간단하며, 코드 한 줄로 끝납니다.
  * **입력:** 각 그룹의 데이터를 **개별 인수**로 받습니다.
  * **출력:** F-통계량, p-value **두 개만** 줍니다.

<!-- end list -->

```python
from scipy import stats

# 1. 각 그룹의 'Fare' 데이터를 별도로 준비
group_S = df[df['Embarked'] == 'S']['Fare']
group_C = df[df['Embarked'] == 'C']['Fare']
group_Q = df[df['Embarked'] == 'Q']['Fare']

# 2. 그룹들을 그대로 인수로 전달
f_stat, p_value = stats.f_oneway(group_S, group_C, group_Q)
```

  * **👍 장점:** p-value만 빠르게 확인하고 싶을 때 최고입니다. (3유형 단답형 문제풀이에 적합)
  * **👎 단점:** 분산분석표(SS, MS 등)를 제공하지 않으며, 사후검정(Tukey)과 연동되지 않습니다.

### 🧬 `statsmodels` (`ols` + `anova_lm`)

  * **특징:** R 스타일의 \*\*"포뮬러(formula)"\*\*를 사용하며, 상세한 분석표를 제공합니다.
  * **입력:** `ols('종속변수 ~ C(독립변수)', data=df)` 형태의 모델을 먼저 만듭니다.
      * \*\*`C()`\*\*는 "이 변수가 범주형(Categorical)이다"라고 명시하는 필수 기호입니다.
  * **출력:** **완전한 분산분석표** (자유도(df), 제곱합(sum\_sq), 평균제곱(mean\_sq) 등)를 반환합니다.

<!-- end list -->

```python
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm

# 1. OLS(최소제곱법) 모델 생성
# 'Fare ~ C(Embarked)' -> Embarked 그룹에 따른 Fare 평균 분석
model = ols('Fare ~ C(Embarked)', data=df).fit()

# 2. 모델을 anova_lm에 전달
result_table = anova_lm(model, type=2) # type=2가 표준
# print(result_table)
```

  * **👍 장점:**
    1.  상세한 분석 결과를 제공합니다.
    2.  `statsmodels`의 **Tukey 사후검정**과 완벽하게 호환됩니다.
    3.  `'y ~ C(a) + C(b)'` 처럼 이원분산분석(Two-Way ANOVA) 등 복잡한 모델로 확장이 쉽습니다.
  * **👎 단점:** `scipy`보다 코드가 몇 줄 더 필요합니다.

> **결론:**
>
>   * 단순히 p-value만 묻는다면 ➡️ **`scipy`**
>   * F-통계량을 묻거나, 사후검정(Tukey)까지 이어지는 문제라면 ➡️ **`statsmodels`**

-----

## 3\. Tukey HSD 사후검정이란 무엇인가?

  * **"ANOVA가 유죄 판결을 내린 뒤, '진짜 범인'을 찾는 수사관"**

ANOVA는 $H_0$을 기각할 때, "적어도 하나는 다르다"라는 모호한 결론만 줍니다.
(1반, 2반, 3반의 평균이 다름)

하지만 **"누가"** 다른지는 알려주지 않습니다.

  * 1반 vs 2반? (차이 있음)
  * 1반 vs 3반? (차이 없음)
  * 2반 vs 3반? (차이 있음)

이것을 알아내기 위해 모든 그룹 쌍(pair)을 비교하는 것을 \*\*"사후검정 (Post-hoc test)"\*\*이라고 합니다.

### Tukey HSD (Honestly Significant Difference)

Tukey HSD(투키의 정직한 유의미한 차이)는 가장 널리 쓰이는 사후검정입니다.

앞서 언급한 \*\*"다중 비교 문제"\*\*를 해결하기 위해, 각 쌍(pair)을 비교할 때 p-value를 더 엄격하게 보정합니다. (그냥 t-검정을 여러 번 돌리는 것보다 신뢰할 수 있습니다.)

### 🐍 Python 코드 예시

Tukey 검정은 `statsmodels` 라이브러리를 사용하며, (모델이 아닌) **데이터**와 **그룹 라벨**을 직접 입력받습니다.

```python
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# (ANOVA에서 H0이 기각되었다고 가정)

# 1. Tukey HSD 수행
# (전체 'Fare' 데이터, 전체 'Embarked' 라벨)
tukey_result = pairwise_tukeyhsd(endog=df['Fare'], groups=df['Embarked'], alpha=0.05)

# 2. 결과 테이블 출력
# print(tukey_result)
```

### 📊 Tukey 결과 테이블 해석

`print(tukey_result)`는 다음과 같은 표를 보여줍니다.

| group1 | group2 | meandiff | **p-adj** | lower | upper | **reject** |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| C | Q | -1.135 | 0.999 | -27.6 | 25.3 | **False** |
| **C** | **S** | -32.89 | **0.000** | -42.8 | -22.9 | **True** |
| **Q** | **S** | -31.75 | **0.000** | -48.1 | -15.3 | **True** |

  * **`group1`, `group2`**: 비교하는 두 그룹 (예: 'C'와 'S')
  * **`meandiff`**: 두 그룹의 평균 차이 (예: C-S = -32.89)
  * **`p-adj` (Adjusted p-value)**: **가장 중요한 값.** 다중 비교가 보정된 p-value입니다.
  * **`reject` (기각 여부)**: **최종 결론.**
      * **`reject = True`:** "이 두 그룹은 유의미하게 다르다." (p-adj \<= 0.05)
      * **`reject = False`:** "이 두 그룹은 차이가 없다." (p-adj \> 0.05)

**최종 해석:** C와 S, Q와 S는 평균 요금에 유의미한 차이가 있지만, C와 Q는 차이가 없다고 말할 수 있습니다.

알겠습니다. t-검정에서 "등분산성(equal variance)"을 가정할 때 등장하는 핵심 개념이 바로 \*\*합동분산추정량 (Pooled Variance Estimator)\*\*입니다.

이전 마크다운 설명에서 **"1. 독립표본 t-검정"** 부분, 특히 **"(필수) 사전 검토: 등분산 검정"** 섹션에 이 설명을 추가하는 것이 가장 자연스럽습니다.

-----

### (수정) 1. 독립표본 t-검정 (Independent t-test)

  * **🎯 언제 사용하나요?**
      * **"두 개의 독립된 그룹(범주형)"** 간의 \*\*"평균(수치형)"\*\*을 비교할 때.
  * **⚖️ 예시:** "1등석 승객(`Pclass`=1)과 3등석 승객(`Pclass`=3)의 평균 나이(`Age`)는 다른가?"
  * **$H_0$ (귀무가설):** 두 그룹의 평균 나이는 같다.
  * **$H_1$ (대립가설):** 두 그룹의 평균 나이는 다르다.

-----

### (필수) 사전 검토: 등분산 검정

본 재판(t-검정)을 열기 전, 두 그룹의 데이터가 얼마나 흩어져있는지(분산) 확인해야 합니다.

  * **등분산 검정의 $H_0$:** 두 그룹의 분산은 같다.
  * `scipy.stats.levene`을 사용합니다.
      * `p > 0.05` ➡️ 등분산 가정 (`equal_var=True`) ➡️ **이때 "합동분산추정량"을 사용합니다.**
      * `p <= 0.05` ➡️ 이분산 가정 (`equal_var=False`) ➡️ (Welch's t-test를 사용하며, 합동분산을 쓰지 않습니다.)

-----

### (추가) 💡 합동분산추정량 (Pooled Variance Estimator)이란?

`levene` 검정 결과, p-value가 0.05보다 커서 \*\*"두 그룹의 분산이 같다"\*\*고 가정하기로 했습니다. (즉, `equal_var=True`)

이때, 두 그룹의 분산(s1², s2²)은 \*\*"표본"\*\*이라 약간의 차이가 있을 수 있습니다. (예: 1등석 분산 140, 3등석 분산 135)

우리의 가정은 "이 둘의 모(母)분산은 어차피 같다"는 것이므로, 140과 135라는 두 개의 다른 값을 쓰기보다, \*\*이 둘을 합쳐 "더 신뢰할 수 있는 하나의 공통 분산 추정치"\*\*를 만드는 것이 합리적입니다.

  * **정의:** 두 집단의 분산 추정치를 "하나로 합친(pooled)" 가중평균입니다.
  * **목적:** 두 집단의 모분산이 같다고 가정할 때, 이 공통의 모분산을 가장 잘 추정하는 \*\*"단일 값"\*\*을 얻기 위함입니다.
  * **특징:** 데이터가 더 많은 쪽(자유도가 큰 쪽)의 분산에 더 많은 가중치를 주어 계산합니다.
      * $s_p^2 = \frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}$
      * (n1: 그룹1 개수, s1²: 그룹1 분산)
  * **결론:** `stats.ttest_ind(..., equal_var=True)`를 실행하면, `scipy`는 내부적으로 이 합동분산추정량($s_p^2$)을 계산하여 t-통계량을 구합니다.

-----

### 🐍 Python 코드 예시 (t-검정)

```python
from scipy.stats import ttest_ind, levene

# 1. 비교할 두 그룹의 'Age' 데이터 추출
group1 = df[df['Pclass'] == 1]['Age'].dropna()
group3 = df[df['Pclass'] == 3]['Age'].dropna()

# 2. (사전 검토) 레빈(Levene) 등분산 검정
stat, p_levene = levene(group1, group3)
print(f"등분산 검정 p-value: {p_levene:.3f}")

is_equal_var = True # 기본값
if p_levene <= 0.05:
    is_equal_var = False # 분산이 다르다고 판결

# 3. (본 재판) t-검정 수행
# is_equal_var가 True이면, ttest_ind는 내부적으로 '합동분산추정량'을 사용함
t_stat, p_value = ttest_ind(group1, group3, equal_var=is_equal_var)

print(f"t-검정 p-value: {p_value:.3f}")
if p_value <= 0.05:
    print("결론: 1등석과 3등석의 평균 나이는 유의미하게 다르다. (H0 기각)")
else:
    print("결론: 평균 나이 차이가 유의미하다고 말할 수 없다. (H0 기각 실패)")
```

p-값(p-value), 정말 헷갈리죠. "낮으면 기각"이라고 외우긴 했는데, 그게 왜 그런지 헷갈립니다.

방금 전까지 우리가 했던 모든 3유형 문제(t-검정, 카이제곱, ANOVA 등)는 사실 **단 하나의 개념**, 이 p-값으로 귀결됩니다.

제가 법정 재판 비유로 확실하게 정리해 드릴게요.

## 1\. p-값이란 무엇인가? ⚖️ (재판 비유)

모든 통계 검정은 \*\*"재판"\*\*입니다.

  * **귀무가설 ($H_0$) (법정의 원칙):** "용의자는 무죄다\!"

      * 즉, "아무 차이도, 아무 관계도 없다. 모든 것은 **우연**이다."
      * (예: "1등석과 3등석의 평균 나이는 **같다**.")

  * **대립가설 ($H_1$) (검사의 주장):** "용의자는 유죄다\!"

      * 즉, "이건 우연이 아니다\! **유의미한 차이/관계가 있다\!**"
      * (예: "1등석과 3등석의 평균 나이는 **다르다**.")

-----

### ⭐️ p-value = "이게 우연일 확률"

> \*\*p-값은 "귀무가설이 맞다(즉, 아무 차이가 없다)고 가정할 때, 지금 내 눈앞의 이 데이터(증거)가 우연히 나올 확률"\*\*입니다.

  * **p-값이 낮다 (예: 0.0002)**

      * **의미:** "아무 차이가 없는데 이런 극단적인 데이터가 나올 확률이 0.02%라고? 말도 안 돼\!"
      * **판결:** "이건 우연이 아니다. **유죄(H1)다\!**"

  * **p-값이 높다 (예: 0.84)**

      * **의미:** "아무 차이가 없어도 이런 데이터는 84%의 확률로 흔하게 나올 수 있다."
      * **판결:** "우연일 가능성이 충분하다. **무죄(H0)다.**"

-----

## 2\. "판결 기준" = 0.05 (5%)

우리는 "우연히 일어날 확률이 5% 미만이면, 그건 우연이 아니다"라는 **국룰**을 사용합니다. 이게 바로 **유의수준(Alpha) 0.05**입니다.

### 📜 p-값을 해석하는 단 하나의 규칙

> **`p-value <= 0.05` (5%보다 낮다)**
>
>   * "이건 우연이 아니다\!"
>   * **판결:** **귀무가설($H_0$) 기각 (Reject)**
>   * **결론:** **대립가설($H_1$) 채택** ➡️ "차이가 있다", "관계가 있다"

> **`p-value > 0.05` (5%보다 높다)**
>
>   * "이건 우연일 수 있다."
>   * **판결:** **귀무가설($H_0$) 기각 실패 (Fail to Reject)**
>   * **결론:** **대립가설($H_1$) 채택 실패** ➡️ "차이가 있다고 말할 수 없다", "관계가 있다고 말할 수 없다"

-----

## 3\. 우리가 만난 p-값들 (총정리)

우리가 했던 모든 검정은 **$H_0$ (귀무가설)만 다를 뿐**, p-값을 해석하는 위 규칙은 100% 동일합니다.

| 검정 이름 | $H_0$ (무죄)는 "..." | `p <= 0.05`의 의미 (유죄 판결) |
| :--- | :--- | :--- |
| **t-검정 (독립표본)** | 두 그룹의 **평균은 같다.** | "두 그룹의 **평균은** 유의미하게 **다르다**." |
| **t-검정 (단일표본)** | 샘플 평균은 **기준값과 같다.** | "샘플 평균은 기준값과 유의미하게 **다르다**." |
| **ANOVA (분산분석)** | 모든 그룹(3개+)의 **평균은 같다.**| "적어도 한 그룹의 평균은 유의미하게 **다르다**." |
| **카이제곱 (독립성)** | 두 변수는 **관련이 없다.** (독립이다) | "두 변수는 유의미하게 **관련이 있다**." |
| **카이제곱 (적합도)** | 내 데이터는 **가설과 일치한다.** | "내 데이터는 가설과 유의미하게 **다르다**." (가설이 틀렸다) |
| **피어슨 상관분석** | 두 변수는 **선형 관계가 없다.** (r=0) | "두 변수는 유의미한 **선형 관계가 있다**." (r이 0이 아니다) |
| **(t-검정 사전검사)**<br>**Levene (등분산)** | 두 그룹의 **분산은 같다.** | "두 그룹의 분산은 유의미하게 **다르다**." (이분산이다) |

**Levene(등분산) 검정**만 p-값이 **커야(\> 0.05)** `equal_var=True`를 쓸 수 있어서 헷갈리지만, 원리는 "분산이 같다는 H0을 기각하지 못했다"로 동일합니다.

이제 p-값이 나오면, "이게 우연일 확률이 5%보다 낮은가, 높은가?" 이 한 가지만 생각하시면 됩니다.

[Image of normal distribution curve comparing t-distribution and z-distribution]

\*\*Z-검정(Z-test)\*\*은 T-검정과 거의 똑같지만, 딱 한 가지 조건이 다릅니다.

> **"모집단의 분산(표준편차)을 이미 알고 있거나, 데이터 개수(n)가 30개 이상으로 아주 많을 때 사용"**

빅데이터분석기사 실기 시험 관점에서 보면,

1.  **평균 검정:** `Z-test`보다는 \*\*`T-test`\*\*가 압도적으로 많이 나옵니다. (현실에서 모집단 분산을 아는 경우가 거의 없어서요.)
2.  **비율 검정:** \*\*`비율 검정(Proportions Z-test)`\*\*은 무조건 Z-검정을 씁니다. (이게 중요합니다\!)

-----

### 1\. 평균 비교 Z-검정 (Mean Z-test)

`scipy.stats`에는 Z-검정 함수가 없어서 `statsmodels`를 써야 합니다.

**상황:** "우리 반 학생 50명의 평균 키가 전국 평균 175cm와 다른가?" (n이 크므로 Z-검정 가능)

```python
import numpy as np
from statsmodels.stats.weightstats import ztest

# 1. 데이터 생성 (n=50)
np.random.seed(42)
data = np.random.normal(178, 5, 50) # 평균 178인 데이터 생성

# 2. 단일표본 Z-검정 (One-sample Z-test)
# value: 비교할 기준값 (귀무가설의 평균)
stat, p_val = ztest(data, value=175)

print(f"Z-통계량: {stat:.3f}")
print(f"p-value: {p_val:.4f}")

if p_val < 0.05:
    print("결론: 전국 평균(175)과 유의미하게 다르다.")
else:
    print("결론: 전국 평균과 다르다고 할 수 없다.")
```

-----

### 2\. 비율 검정 (Proportions Z-test) ⭐시험 빈출⭐

시험에서 Z-검정을 쓴다면 **99% 이 경우**입니다.
"A 그룹의 성공률과 B 그룹의 성공률이 다른가?"를 따질 때 씁니다.

**상황:**

  * **A반:** 100명 중 30명 합격
  * **B반:** 100명 중 45명 합격
  * 이 합격률 차이가 유의미한가?

<!-- end list -->

```python
from statsmodels.stats.proportion import proportions_ztest

# 1. 데이터 준비
count = [30, 45]  # 성공 횟수 (합격자 수)
nobs = [100, 100] # 전체 횟수 (응시자 수)

# 2. 비율 검정 수행
# alternative='two-sided' (양측검정: 다르다)
# alternative='larger' (단측검정: A가 더 크다)
stat, p_val = proportions_ztest(count, nobs, alternative='two-sided')

print(f"Z-통계량: {stat:.3f}")
print(f"p-value: {p_val:.4f}")

if p_val < 0.05:
    print("결론: 두 반의 합격률 차이는 유의미하다.")
else:
    print("결론: 차이가 유의미하지 않다.")
```

-----

### ⚡️ T-검정 vs Z-검정 (시험용 요약)

| 구분 | **T-검정 (T-test)** | **Z-검정 (Z-test)** |
| :--- | :--- | :--- |
| **언제 씀?** | **모분산 모름 (대부분의 경우)**<br>표본이 적을 때 (n \< 30) | **모분산 앎 (희귀함)**<br>표본이 클 때 (n \>= 30) |
| **코드 (평균)** | `scipy.stats.ttest_...` | `statsmodels.stats.weightstats.ztest` |
| **코드 (비율)** | 없음 | **`proportions_ztest`** (필수 암기) |
| **분포 모양** | 꼬리가 두꺼움 (불확실성 큼) | 꼬리가 얇음 (정규분포와 동일) |

**💡 결론:**
시험에서 "평균"을 비교하라고 하면 그냥 **T-검정** 쓰시고,
"비율(성공률, 불량률)"을 비교하라고 하면 \*\*`proportions_ztest`\*\*를 쓰시면 됩니다.

아니요\! **굳이 그렇게 어렵게(수동으로) 계산할 필요 없습니다.**

예전 버전의 `scipy`에서는 지원하지 않아서 수동으로 구해야 했지만, 지금은 **`alternative` 옵션** 하나만 넣어주면 함수가 알아서 다 계산해줍니다.

시험장 환경에서도 당연히 이 옵션을 사용할 수 있습니다.

-----

### 🚀 `alternative` 파라미터 사용법 (필수 암기)

`ttest_ind`, `ttest_1samp`, `ttest_rel` 모두 동일합니다.

| 가설 종류 | 대립가설 ($H_1$) | 옵션 설정 |
| :--- | :--- | :--- |
| **양측검정** (기본값) | $\mu_1 \neq \mu_2$ (차이가 있다) | `alternative='two-sided'` (생략 가능) |
| **단측검정** (크다) | $\mu_1 > \mu_2$ (A가 B보다 크다) | **`alternative='greater'`** |
| **단측검정** (작다) | $\mu_1 < \mu_2$ (A가 B보다 작다) | **`alternative='less'`** |

-----

### 💻 코드 예시 (독립표본 t-검정)

**상황:** A반 점수(`groupA`)가 B반 점수(`groupB`)보다 **높은지(크다)** 검정하고 싶다.

#### ❌ 예전 방식 (수동 계산 - 비추천)

```python
t_stat, p_val = stats.ttest_ind(groupA, groupB) # 기본은 양측
p_val_one_sided = p_val / 2  # 양측 p-value를 2로 나눔 (부호 확인 필요)

# t통계량이 양수면 p/2, 음수면 1-(p/2) 등 복잡함... 머리 아픔 🤯
```

#### ✅ 요즘 방식 (옵션 사용 - 추천)

```python
# A가 B보다 '큰지(greater)' 검정
# 순서 주의: (A, B) 순서로 넣었으면 "A > B"를 검정함
t_stat, p_val = stats.ttest_ind(groupA, groupB, alternative='greater')

print(p_val) # 바로 단측검정 p-value가 나옴!
```

-----

### ⚠️ 주의할 점: 변수 넣는 순서\!

단측검정(`greater`, `less`)을 할 때는 **변수를 넣는 순서**가 매우 중요합니다.

  * **`stats.ttest_ind(A, B, alternative='greater')`**
      * 검정 내용: **A의 평균 \> B의 평균** 인가?
  * **`stats.ttest_ind(A, B, alternative='less')`**
      * 검정 내용: **A의 평균 \< B의 평균** 인가?

**요약:**
복잡한 `cdf` 공식은 잊어버리시고, **`alternative='greater'`** 혹은 \*\*`'less'`\*\*만 기억하세요\!