{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2fa1656e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "        Date         Price  Sales\n",
      "0 2023-01-01  12142.529844   18.0\n",
      "1 2023-01-02   6434.896126   71.0\n",
      "2 2023-01-03  14121.359907   46.0\n",
      "3 2023-01-04  33886.945659   60.0\n",
      "4 2023-01-05   5846.520075   53.0\n",
      "  Product  2023-Q1  2023-Q2  2023-Q3  2023-Q4\n",
      "0       A      100      110      105      120\n",
      "1       B      150      160      155      170\n",
      "2       C      200      210      205      220\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. ì‹œê³„ì—´/í†µê³„ ë°ì´í„° (df_time)\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2023-01-01', periods=100, freq='D')\n",
    "prices = np.random.lognormal(mean=2, sigma=1, size=100) * 1000 # ì™œë„ê°€ ìˆëŠ” ë°ì´í„° ìƒì„±\n",
    "sales = np.random.randint(10, 100, size=100).astype(float)\n",
    "\n",
    "df_time = pd.DataFrame({'Date': dates, 'Price': prices, 'Sales': sales})\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ê°•ì œ ìƒì„± (ë³´ê°„ë²• ì—°ìŠµìš©)\n",
    "df_time.loc[10:20, 'Sales'] = np.nan \n",
    "df_time.loc[50:55, 'Sales'] = np.nan\n",
    "\n",
    "# 2. ë„“ì€ í˜•íƒœ ë°ì´í„° (df_wide) - Melt ì—°ìŠµìš©\n",
    "data_wide = {\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    '2023-Q1': [100, 150, 200],\n",
    "    '2023-Q2': [110, 160, 210],\n",
    "    '2023-Q3': [105, 155, 205],\n",
    "    '2023-Q4': [120, 170, 220]\n",
    "}\n",
    "df = pd.DataFrame(data_wide)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df_time.head())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "88f81e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.07\n"
     ]
    }
   ],
   "source": [
    "skew_orig = df_time['Price'].skew()\n",
    "#print(skew_orig)\n",
    "\n",
    "df_time['Price_Log'] = np.log1p(df_time['Price'])\n",
    "skew_log = df_time['Price_Log'].skew()\n",
    "result1 = abs(skew_orig - skew_log)\n",
    "print(round(result1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4ed4de67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "        Date         Price  Sales  Price_Log  Sales_fill  Prev_Sales\n",
      "0 2023-01-01  12142.529844   18.0   9.404552        18.0         NaN\n",
      "1 2023-01-02   6434.896126   71.0   8.769646        71.0        18.0\n",
      "2 2023-01-03  14121.359907   46.0   9.555515        46.0        71.0\n",
      "3 2023-01-04  33886.945659   60.0  10.430815        60.0        46.0\n",
      "4 2023-01-05   5846.520075   53.0   8.673773        53.0        60.0\n"
     ]
    }
   ],
   "source": [
    "df_time['Sales_fill'] = df_time['Sales'].interpolate(method='linear')\n",
    "df_time['Prev_Sales'] = df_time['Sales_fill'].shift(1)\n",
    "result2 = df_time['Sales_fill'].corr(df_time['Prev_Sales'])\n",
    "print(round(result2, 2))\n",
    "print(df_time.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b77e17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n"
     ]
    }
   ],
   "source": [
    "#print(df.head())\n",
    "df_melt = pd.melt(df, id_vars=['Product'], var_name='Quarter', value_name='Revenue')\n",
    "#print(df_melt)\n",
    "\n",
    "result3 = df_melt[df_melt['Quarter']=='2023-Q4']['Revenue'].sum()\n",
    "print(round(result3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "aa070290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "min_val = df_time['Price'].min()\n",
    "max_val = df_time['Price'].max()\n",
    "df_time['Price_Scaled'] = (df_time['Price'] - min_val) / (max_val - min_val)\n",
    "result4 = sum(df_time['Price_Scaled'] > 0.5)\n",
    "print(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53649f5f",
   "metadata": {},
   "source": [
    "ğŸ“ ì‹¤ì „ ì—°ìŠµ ë¬¸ì œ\n",
    "ë¬¸ì œ 1. (ì¡°ê±´ í•„í„°ë§ & ì¤‘ì•™ê°’ ëŒ€ì¹˜) Price ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜(NaN)ë¥¼ **Cityë³„ Priceì˜ ì¤‘ì•™ê°’(median)**ìœ¼ë¡œ ì±„ìš°ì‹œì˜¤. ê·¸ í›„, Paymentê°€ 'Card'ì¸ ë°ì´í„°ë“¤ì˜ Price í‰ê· ê°’ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ì‹œê³„ì—´ & Groupby) Date ì»¬ëŸ¼ì—ì„œ 'ìš”ì¼'(Monday=0, ... Sunday=6) ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ Weekday ì»¬ëŸ¼ì„ ë§Œë“œì‹œì˜¤. **'ì£¼ë§' (í† ìš”ì¼, ì¼ìš”ì¼)**ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§í•œ í›„, ì´ ë°ì´í„°ë“¤ì˜ Cityë³„ Price **í•©ê³„(sum)**ë¥¼ êµ¬í–ˆì„ ë•Œ ê°€ì¥ í° ê°’ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ë°ì´í„° êµ¬ê°„í™” & ë¹ˆë„ìˆ˜) Price ì»¬ëŸ¼ ê°’(ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œëœ ìƒíƒœ ê°€ì •)ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ 3ê°œì˜ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
    "\n",
    "0 ì´ìƒ 4000 ë¯¸ë§Œ: 'Low'\n",
    "\n",
    "4000 ì´ìƒ 7000 ë¯¸ë§Œ: 'Mid'\n",
    "\n",
    "7000 ì´ìƒ: 'High'\n",
    "\n",
    "'Mid' ê·¸ë£¹ì— ì†í•˜ë©´ì„œ Productê°€ 'A'ì¸ ë°ì´í„°ì˜ **ê°œìˆ˜(í–‰ì˜ ìˆ˜)**ë¥¼ êµ¬í•˜ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a8437069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Date     City Product   Price Payment\n",
      "0 2023-01-01 00:00:00    Seoul       A  2725.0    Cash\n",
      "1 2023-01-01 01:00:00    Daegu       B  9929.0    Card\n",
      "2 2023-01-01 02:00:00    Seoul       C  3118.0    Card\n",
      "3 2023-01-01 03:00:00    Seoul       C  2901.0    Card\n",
      "4 2023-01-01 04:00:00  Incheon       A  2739.0    Cash\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2024)\n",
    "\n",
    "# ë°ì´í„° ìƒì„±\n",
    "dates = pd.date_range('2023-01-01', periods=500, freq='h')\n",
    "cities = np.random.choice(['Seoul', 'Busan', 'Daegu', 'Incheon'], 500)\n",
    "products = np.random.choice(['A', 'B', 'C'], 500)\n",
    "prices = np.random.randint(1000, 10000, 500)\n",
    "payments = np.random.choice(['Card', 'Cash', 'Pay'], 500)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'City': cities,\n",
    "    'Product': products,\n",
    "    'Price': prices,\n",
    "    'Payment': payments\n",
    "})\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì„ì˜ ìƒì„± (Price ì»¬ëŸ¼)\n",
    "df.loc[10:20, 'Price'] = np.nan\n",
    "\n",
    "# ë°ì´í„° í™•ì¸\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "106e157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426.29\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1\n",
    "fill_nan = df.groupby('City')['Price'].transform('median')\n",
    "\n",
    "df['Price'] = df['Price'].fillna(fill_nan)\n",
    "#print(df.info())\n",
    "result = df[df['Payment']=='Card']['Price'].mean()\n",
    "print(round(result, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ce0c4c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City\n",
      "Incheon    815941.0\n",
      "Busan      647059.5\n",
      "Daegu      641636.0\n",
      "Seoul      599213.0\n",
      "Name: Price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2\n",
    "df['Weekday'] = df['Date'].dt.weekday\n",
    "q1 = df['Weekday'].isin([5, 6])\n",
    "result = df.groupby('City')['Price'].sum().sort_values(ascending=False)\n",
    "print(result)\n",
    "# loc, iloc, isin ì“°ëŠ”ë²•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2e06b990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "def get_category(price):\n",
    "    if price < 4000: return 'Low'\n",
    "    elif price < 7000: return 'Mid'\n",
    "    else: return 'High'\n",
    "\n",
    "df['Category'] = df['Price'].apply(get_category)\n",
    "result = len(df[(df['Category']=='Mid') & (df['Product']=='A')])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116db132",
   "metadata": {},
   "source": [
    "ğŸ“ ì‹¤ì „ ì—°ìŠµ ë¬¸ì œ (Large Data)\n",
    "ë¬¸ì œ 1. (ì‹œê³„ì—´ ë¶„í•´ & ì§‘ê³„) Date ì»¬ëŸ¼ì„ ì´ìš©í•˜ì—¬ **2023ë…„ì˜ 'ì›”ë³„(Month)' ì´ ë²”ì£„ ê±´ìˆ˜(Violent + Theft + Traffic)**ë¥¼ ì§‘ê³„í•˜ì‹œì˜¤. ê·¸ì¤‘ ì´ ë²”ì£„ ê±´ìˆ˜ê°€ **ê°€ì¥ ë§ì•˜ë˜ ì›”(Month)**ì˜ ë²”ì£„ ê±´ìˆ˜ í•©ê³„ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ë³µí•© ì—°ì‚° & Groupby ì£¼ì˜ì ) ì „ì²´ ê¸°ê°„ ë™ì•ˆ ê° êµ¬(District)ë³„ë¡œ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. **'Zone_A'**ì˜ ì—°ê°„ 10ë§Œ ëª…ë‹¹ í‰ê·  ê°•ë ¥ ë²”ì£„(Violent) ë°œìƒ ê±´ìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤.\n",
    "\n",
    "ê³„ì‚° ë¡œì§: (Zone_Aì˜ ì „ì²´ Violent í•©ê³„ / ë°ì´í„° ìˆ˜ì§‘ ë…„ìˆ˜) / Zone_Aì˜ ì¸êµ¬ìˆ˜ * 100,000\n",
    "\n",
    "ë°ì´í„° ìˆ˜ì§‘ ë…„ìˆ˜(Years)ëŠ” 5ë…„(2020~2024)ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ê°’ì€ ì†Œìˆ˜ì  ì´í•˜ëŠ” ë²„ë¦¬ê³  **ì •ìˆ˜(int)**ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.\n",
    "\n",
    "ë¬¸ì œ 3. (ì´ìƒì¹˜ íƒìƒ‰ & ì¡°ê±´ë¶€ í‰ê· ) ì „ì²´ ë°ì´í„° ì¤‘ Traffic ë²”ì£„ ê±´ìˆ˜ê°€ ìƒìœ„ 1%(quantile(0.99)) ì´ìƒì¸ ë‚ ë“¤ì„ **'Traffic_High'**ë¡œ ì •ì˜í•©ë‹ˆë‹¤. ì´ 'Traffic_High' ê·¸ë£¹ì— ì†í•˜ëŠ” ë°ì´í„°ë“¤ì˜ Violent ë²”ì£„ ë°œìƒ ê±´ìˆ˜ì˜ í‰ê· ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b4ed9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ! í¬ê¸°: (50000, 6)\n",
      "        Date District  Violent  Theft  Traffic  Population\n",
      "0 2020-01-01   Zone_N        6     21       21      662347\n",
      "1 2020-01-01   Zone_A       10      3       44      732104\n",
      "2 2020-01-01   Zone_N        4      8       38      662347\n",
      "3 2020-01-01   Zone_E       12      0       47      654593\n",
      "4 2020-01-01   Zone_K       13      5       35      474799\n",
      "5 2020-01-01   Zone_H        9      5       37      721696\n",
      "6 2020-01-01   Zone_D        0      7       20      661246\n",
      "7 2020-01-01   Zone_G       14      5       41      486794\n",
      "8 2020-01-01   Zone_O       11     28       41      466331\n",
      "9 2020-01-01   Zone_S        1     10        9      253094\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ëœë¤ ì‹œë“œ ê³ ì • (ì •ë‹µ í†µì¼ì„ ìœ„í•´)\n",
    "np.random.seed(2024)\n",
    "\n",
    "# 1. ê¸°ë³¸ ì„¤ì •\n",
    "n_rows = 50000\n",
    "districts = [f'Zone_{chr(i)}' for i in range(65, 85)] # Zone_A ~ Zone_T (20ê°œ)\n",
    "\n",
    "# 2. êµ¬ë³„ ì¸êµ¬ìˆ˜ ë§¤í•‘ (Zone_AëŠ” 30ë§Œ, Zone_BëŠ” 35ë§Œ... ëœë¤ ë°°ì •)\n",
    "pop_map = {d: np.random.randint(200000, 800000) for d in districts}\n",
    "\n",
    "# 3. ë°ì´í„° ìƒì„±\n",
    "df = pd.DataFrame({\n",
    "    'Date': np.random.choice(pd.date_range('2020-01-01', '2024-12-31'), n_rows),\n",
    "    'District': np.random.choice(districts, n_rows),\n",
    "    'Violent': np.random.randint(0, 15, n_rows),  # ì¼ì¼ ë°œìƒ ê±´ìˆ˜ë¼ ì ê²Œ ì„¤ì •\n",
    "    'Theft': np.random.randint(0, 30, n_rows),\n",
    "    'Traffic': np.random.randint(0, 50, n_rows)\n",
    "})\n",
    "\n",
    "# 4. ì¸êµ¬ìˆ˜ ë§¤í•‘ ë° ì •ë ¬\n",
    "df['Population'] = df['District'].map(pop_map)\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "print(f\"ë°ì´í„° ìƒì„± ì™„ë£Œ! í¬ê¸°: {df.shape}\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cf932e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41536\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "\n",
    "df['Total'] = df['Violent'] + df['Theft'] + df['Traffic']\n",
    "q1 = df[df['year']==2023]\n",
    "result = q1.groupby('month')['Total'].sum().sort_values(ascending=False)\n",
    "print(result.iloc[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ba7f3002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2\n",
    "q2 = df[df['District']=='Zone_A']\n",
    "year_ratio = (q2['Violent'].sum() / 5) / q2['Population'].iloc[0] * 100000\n",
    "print(int(year_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1ef011f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.94\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3\n",
    "var = df['Traffic'].quantile(0.99)\n",
    "def cond(traffic):\n",
    "    if traffic >= var: return 'Traffic_High'\n",
    "    else: return 'NoNan'\n",
    "\n",
    "df['Traffic_check'] = df['Traffic'].apply(cond)\n",
    "\n",
    "result = df[df['Traffic_check']=='Traffic_High']['Violent'].mean()\n",
    "print(round(result, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a71b8eb",
   "metadata": {},
   "source": [
    "ğŸ“ ì‹¤ì „ ì—°ìŠµ ë¬¸ì œ (ì•½ì  ë³´ì™„ & ë¬¸ìì—´)\n",
    "ë¬¸ì œ 1. (ë¬¸ìì—´ ì¶”ì¶œ & ë¹ˆë„ ë¶„ì„) Product ì»¬ëŸ¼ì—ëŠ” ëŒ€ê´„í˜¸ [ ... ] ì•ˆì— ì œí’ˆì˜ ì˜µì…˜ ì •ë³´ê°€ ë“¤ì–´ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: [Black]) ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì´ ì˜µì…˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ(ê´„í˜¸ ì œì™¸)í•˜ì—¬ Optionì´ë¼ëŠ” ìƒˆ ì»¬ëŸ¼ì„ ë§Œë“œì„¸ìš”. ê°€ì¥ ë§ì´ íŒë§¤ëœ(í–‰ ê°œìˆ˜ ê¸°ì¤€) Optionì˜ ì´ë¦„ì„ ì¶œë ¥í•˜ì‹œì˜¤.\n",
    "\n",
    "ë¬¸ì œ 2. (ê·¸ë£¹ë³„ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ & í‰ê·  ê³„ì‚°) Price ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ë¥¼ **Categoryë³„ Priceì˜ í‰ê· ê°’(mean)**ìœ¼ë¡œ ì±„ìš°ì„¸ìš”. (ì£¼ì˜: ì „ì²´ í‰ê· ì´ ì•„ë‹ˆë¼, ElectronicsëŠ” Electronicsë¼ë¦¬, AccessoriesëŠ” Accessoriesë¼ë¦¬ í‰ê· ì„ êµ¬í•´ì„œ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤.) ê²°ì¸¡ì¹˜ ì²˜ë¦¬ê°€ ì™„ë£Œëœ í›„, Priceì˜ **í‘œì¤€í¸ì°¨(std)**ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ì´í•˜ëŠ” ë²„ë¦¬ê³  **ì •ìˆ˜(int)**ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ì‹œê³„ì—´ ì§‘ê³„ & ì´ìƒì¹˜ ë²”ìœ„ - ì§€ë‚œë²ˆ ì‹¤ìˆ˜ ë³µìŠµ) ì¼ë³„ ë§¤ì¶œì•¡(Daily_Sales)ì„ ê³„ì‚°í•˜ë ¤ê³  í•©ë‹ˆë‹¤. (ë§¤ì¶œì•¡ = Price * Quantity, ê²°ì¸¡ì¹˜ ì²˜ë¦¬ëœ Price ì‚¬ìš©) ë‚ ì§œ(Date)ë³„ë¡œ ì´ ë§¤ì¶œì•¡ì„ ì§‘ê³„í•œ ë’¤, ì´ ë§¤ì¶œì•¡ì´ **ìƒìœ„ 10% ì´ìƒ(>= 0.9 quantile)**ì¸ ë‚ ì§œë“¤ì„ **'High_Sales_Day'**ë¡œ ì •ì˜í•©ë‹ˆë‹¤. ì´ 'High_Sales_Day'ì— í•´ë‹¹í•˜ëŠ” ë‚ ë“¤ì˜ ì¼í‰ê·  ë§¤ì¶œì•¡ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ì´í•˜ëŠ” ë²„ë¦¬ê³  **ì •ìˆ˜(int)**ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8cefe8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ! (í–‰: 5000)\n",
      "        Date             Product     Category      Price  Quantity\n",
      "0 2023-08-11  Monitor [Wireless]  Electronics  1030000.0         2\n",
      "1 2023-12-26       Laptop [16GB]  Electronics        NaN         1\n",
      "2 2023-10-19    Mouse [Wireless]  Accessories   410000.0         4\n",
      "3 2023-07-24      Laptop [Black]  Electronics   930000.0         1\n",
      "4 2023-03-09     Monitor [White]  Electronics  1437000.0         4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 5000\n",
    "\n",
    "# 1. ìƒí’ˆëª… ìƒì„± (ëŒ€ê´„í˜¸ ì•ˆì— ì˜µì…˜ í¬í•¨)\n",
    "products_base = ['Laptop', 'Phone', 'Monitor', 'Mouse', 'Keyboard']\n",
    "options = ['[Black]', '[White]', '[Silver]', '[16GB]', '[Wireless]']\n",
    "categories = ['Electronics', 'Electronics', 'Electronics', 'Accessories', 'Accessories']\n",
    "\n",
    "prod_list = []\n",
    "cat_list = []\n",
    "for _ in range(n_rows):\n",
    "    idx = np.random.randint(0, 5)\n",
    "    opt_idx = np.random.randint(0, 5)\n",
    "    # ìƒí’ˆëª… ì˜ˆ: \"Laptop [Black]\"\n",
    "    prod_name = f\"{products_base[idx]} {options[opt_idx]}\"\n",
    "    prod_list.append(prod_name)\n",
    "    cat_list.append(categories[idx])\n",
    "\n",
    "# 2. ë°ì´í„° ìƒì„±\n",
    "df = pd.DataFrame({\n",
    "    'Date': np.random.choice(pd.date_range('2023-01-01', '2023-12-31'), n_rows),\n",
    "    'Product': prod_list,\n",
    "    'Category': cat_list,\n",
    "    'Price': np.random.randint(50, 2000, n_rows) * 1000, # 50,000 ~ 2,000,000\n",
    "    'Quantity': np.random.randint(1, 5, n_rows)\n",
    "})\n",
    "\n",
    "# 3. ê²°ì¸¡ì¹˜ ìƒì„± (Price)\n",
    "df.loc[np.random.choice(df.index, 500), 'Price'] = np.nan\n",
    "\n",
    "print(f\"ë°ì´í„° ìƒì„± ì™„ë£Œ! (í–‰: {df.shape[0]})\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ca8321de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1\n",
    "df['Option'] = df['Product'].str.extract(r'\\[(.*?)\\]')\n",
    "result = df['Option'].value_counts().sort_values(ascending=False)\n",
    "print(result.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "62786703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533145\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2\n",
    "fill_val = df.groupby('Category')['Price'].transform('mean')\n",
    "\n",
    "df['Price'] = df['Price'].fillna(fill_val)\n",
    "result = df['Price'].std()\n",
    "print(int(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b3fe2a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55587015\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3\n",
    "df['Revenue'] = df['Price'] * df['Quantity']\n",
    "daily_sales = df.groupby('Date')['Revenue'].sum()\n",
    "#print(daily_sales)\n",
    "\n",
    "var = daily_sales.quantile(0.9)\n",
    "high_sales_days = daily_sales[daily_sales >= var]\n",
    "result = high_sales_days.mean()\n",
    "print(int(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c318badb",
   "metadata": {},
   "source": [
    "ğŸ“ ì‹¤ì „ ì—°ìŠµ ë¬¸ì œ (ë°ì´í„°ì…‹: Ecommerce_Sales)\n",
    "ë¬¸ì œ 1. (ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€ ê²€ìƒ‰) Product ì´ë¦„ì— **'Wireless'**ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ìƒí’ˆë“¤ë§Œ ë³„ë„ë¡œ ë¶„ì„í•˜ë ¤ê³  í•©ë‹ˆë‹¤. 'Wireless'ê°€ í¬í•¨ëœ ìƒí’ˆë“¤ì˜ **Price ì¤‘ì•™ê°’(median)**ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, Price ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ëŠ” ì œê±°(dropna)í•œ í›„ ê³„ì‚°í•˜ê³ , ê²°ê³¼ëŠ” **ì •ìˆ˜(int)**ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ì‹œê³„ì—´ ì§‘ê³„ & ì •ë ¬) Date ì»¬ëŸ¼ì—ì„œ 'ì›”(Month)' ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. 'Electronics' ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§í•œ í›„, **ì›”ë³„ ì´ ë§¤ì¶œì•¡(Price * Quantity)**ì„ ì§‘ê³„í–ˆì„ ë•Œ, ë§¤ì¶œì•¡ì´ ê°€ì¥ ë†’ì€ **ì›”(Month)**ì€ ëª‡ ì›”ì…ë‹ˆê¹Œ? (ë‹¨, ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ì€ ë§¤ì¶œì•¡ ê³„ì‚° ì „ ì œê±°í•˜ê³ , ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ìˆœìœ„ êµ¬í•˜ê¸° & ì¸ë±ì‹±) ì „ì²´ ë°ì´í„°(ê²°ì¸¡ì¹˜ ì œê±° í›„)ë¥¼ Price(ê°€ê²©)ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•©ë‹ˆë‹¤. ì´ë•Œ, ê°€ê²©ì´ 5ë²ˆì§¸ë¡œ ë†’ì€ ì£¼ë¬¸ì˜ **Order_ID**ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ? (ì£¼ì˜: 0ë¶€í„° ì‹œì‘í•˜ëŠ” ì¸ë±ìŠ¤ ê¸°ì¤€ì´ ì•„ë‹ˆë¼, ì‹¤ì œ ìˆœìœ„ ê¸°ì¤€ 5ë“±ì…ë‹ˆë‹¤. ë™ì ìëŠ” ë¬´ì‹œí•˜ê³  í–‰ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f0050a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date             Product     Category         Price  Quantity  \\\n",
      "0 2023-08-11  Monitor [Wireless]  Electronics  1.030000e+06         2   \n",
      "1 2023-12-26       Laptop [16GB]  Electronics  1.022305e+06         1   \n",
      "2 2023-10-19    Mouse [Wireless]  Accessories  4.100000e+05         4   \n",
      "3 2023-07-24      Laptop [Black]  Electronics  9.300000e+05         1   \n",
      "4 2023-03-09     Monitor [White]  Electronics  1.437000e+06         4   \n",
      "\n",
      "     Option       Revenue  \n",
      "0  Wireless  2.060000e+06  \n",
      "1      16GB  1.022305e+06  \n",
      "2  Wireless  1.640000e+06  \n",
      "3     Black  9.300000e+05  \n",
      "4     White  5.748000e+06  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c49c47b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022305\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1\n",
    "q1 = df.dropna(subset=['Price'])\n",
    "result = q1[q1['Product'].str.contains('Wireless')]['Price'].median()\n",
    "print(int(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "087ea252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangh\\AppData\\Local\\Temp\\ipykernel_15296\\3975182502.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q1['Revenue'] = q1['Price'] * q1['Quantity']\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "q1 = df[df['Category']=='Electronics']\n",
    "q1['Revenue'] = q1['Price'] * q1['Quantity']\n",
    "result = q1.groupby('Month')['Revenue'].sum().sort_values(ascending=False)\n",
    "print(result.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "19a63283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        2023-11-20 00:00:00\n",
      "Product      Monitor [Wireless]\n",
      "Category            Electronics\n",
      "Price                 1998000.0\n",
      "Quantity                      3\n",
      "Option                 Wireless\n",
      "Revenue               5994000.0\n",
      "Month                        11\n",
      "Name: 2770, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3\n",
    "df = df.dropna(subset=['Price'])\n",
    "df = df.sort_values(by='Price', ascending=False)\n",
    "print(df.iloc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431efbfd",
   "metadata": {},
   "source": [
    "ğŸ“ ì‹¤ì „ ì—°ìŠµ ë¬¸ì œ (Subway Traffic)\n",
    "\n",
    "ë¬¸ì œ 1. (ì‹œê³„ì—´ ì§‘ê³„ & ìµœëŒ“ê°’)Line_2 í˜¸ì„ ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.Date ì»¬ëŸ¼ì„ í™œìš©í•˜ì—¬ 'ì›”(Month)'ë³„ ìŠ¹ì°¨ ì¸ì›(Get_On)ì˜ ì´í•©ì„ êµ¬í–ˆì„ ë•Œ, ìŠ¹ì°¨ ì¸ì›ì´ ê°€ì¥ ë§ì•˜ë˜ **ì›”(Month)**ì„ êµ¬í•˜ì‹œì˜¤.(ë‹¨, Get_Onì˜ ê²°ì¸¡ì¹˜ëŠ” ì œê±°í•˜ê³  ê³„ì‚°í•˜ë©°, ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (íŒŒìƒë³€ìˆ˜ & ì ˆëŒ“ê°’ ì •ë ¬)ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ 'ìŠ¹í•˜ì°¨ ì°¨ì´' (Diff) ì»¬ëŸ¼ì„ ìƒì„±í•©ë‹ˆë‹¤. ê³„ì‚° ì‹ì€ Get_On - Get_Offì…ë‹ˆë‹¤. (ê²°ì¸¡ì¹˜ê°€ í¬í•¨ëœ í–‰ì€ ì œê±°)ì´ Diff ê°’ì˜ **ì ˆëŒ“ê°’(Absolute Value)**ì´ ê°€ì¥ í° ìƒìœ„ 3ê°œ ì—­(Station)ì„ ì°¾ê³ , ê·¸ ì¤‘ ì²« ë²ˆì§¸ ì—­ì˜ ì´ë¦„ì„ ì¶œë ¥í•˜ì‹œì˜¤.(ë™ì ìê°€ ìˆì„ ê²½ìš° í–‰ì˜ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬)\n",
    "\n",
    "ë¬¸ì œ 3. (IQR ì´ìƒì¹˜ íƒìƒ‰)Line_1 í˜¸ì„ ì˜ Get_Off (í•˜ì°¨ ì¸ì›) ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì´ìƒì¹˜ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.IQR ë°©ì‹ì„ ì´ìš©í•˜ì—¬ ì´ìƒì¹˜(Outlier)ë¡œ íŒë‹¨ë˜ëŠ” ë°ì´í„°ì˜ ê°œìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤.$Q1$: í•˜ìœ„ 25%, $Q3$: ìƒìœ„ 75%$IQR = Q3 - Q1$ì´ìƒì¹˜ ê¸°ì¤€: $(Q1 - 1.5 \\times IQR)$ ë¯¸ë§Œ ì´ê±°ë‚˜ $(Q3 + 1.5 \\times IQR)$ ì´ˆê³¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8e2b5fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "                 Date    Line    Station  Get_On  Get_Off\n",
      "0 2023-01-01 02:00:00  Line_2  Station_O   292.0      298\n",
      "1 2023-01-01 05:00:00  Line_4  Station_A   882.0      370\n",
      "2 2023-01-01 09:00:00  Line_3  Station_S   871.0      813\n",
      "3 2023-01-01 10:00:00  Line_5  Station_P   636.0      336\n",
      "4 2023-01-01 11:00:00  Line_2  Station_J   548.0      545\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 5000\n",
    "\n",
    "# ë°ì´í„° ìƒì„±\n",
    "dates = pd.date_range('2023-01-01', '2023-12-31', freq='h') # ì‹œê°„ ë‹¨ìœ„ì§€ë§Œ 5000ê°œë§Œ ìƒ˜í”Œë§\n",
    "dates = np.random.choice(dates, n_rows)\n",
    "\n",
    "lines = ['Line_1', 'Line_2', 'Line_3', 'Line_4', 'Line_5']\n",
    "stations = [f'Station_{chr(i)}' for i in range(65, 85)] # A ~ T\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Line': np.random.choice(lines, n_rows),\n",
    "    'Station': np.random.choice(stations, n_rows),\n",
    "    'Get_On': np.random.randint(10, 1000, n_rows),\n",
    "    'Get_Off': np.random.randint(10, 1000, n_rows)\n",
    "})\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì£¼ì… (Get_On)\n",
    "df.loc[np.random.choice(df.index, 100), 'Get_On'] = np.nan\n",
    "\n",
    "# ë°ì´í„° ì •ë ¬\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9f8ca62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1ë²ˆ\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "df_line2 = df[df['Line']=='Line_2']\n",
    "q1 = df_line2.groupby('Month')['Get_On'].sum()\n",
    "print(q1.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c102974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station\n",
      "Station_H    11493.0\n",
      "Station_R     8754.0\n",
      "Station_D     8118.0\n",
      "Name: Diff, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2ë²ˆ\n",
    "df['Diff'] = df['Get_On'] - df['Get_Off']\n",
    "q2 = df.groupby('Station')['Diff'].sum().sort_values(ascending=False)\n",
    "print(np.abs(q2).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0cece8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3ë²ˆ\n",
    "df_1 = df[df['Line']=='Line_1'][['Line', 'Get_Off']]\n",
    "Q1 = df_1['Get_Off'].quantile(0.25)\n",
    "Q3 = df_1['Get_Off'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = (Q1 - 1.5 * IQR)\n",
    "high_bound = (Q3 + 1.5 * IQR)\n",
    "\n",
    "df_outer = df_1[(df_1['Get_Off'] > high_bound) | (df_1['Get_Off'] < lower_bound)]\n",
    "result = len(df_outer)\n",
    "print(result)\n",
    "\n",
    "#df_2 = df[df['Line']=='Line_1']['Get_Off']\n",
    "#print(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c875b90",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ1ìœ í˜•] ëŒ€ê¸°ì˜¤ì—¼ ë°ì´í„° ë¶„ì„\n",
    "ë¬¸ì œ 1. (ì´ìƒì¹˜ ì²˜ë¦¬ & ì¡°ê±´ë¶€ í‰ê· ) PM10 ì»¬ëŸ¼ì—ëŠ” ì„¼ì„œ ì˜¤ë¥˜ë¡œ ì¸í•´ **0ë³´ë‹¤ ì‘ì€ ê°’(ìŒìˆ˜)**ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ **ìŒìˆ˜ ê°’ì„ ì´ìƒì¹˜ë¡œ ê°„ì£¼í•˜ì—¬ ì œê±°(í•„í„°ë§)**í•œ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ, **'City_A'**ì˜ PM10 í‰ê· ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ì´í•˜ëŠ” ë²„ë¦¬ê³  **ì •ìˆ˜(int)**ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ì‹œê³„ì—´ ì¶”ì¶œ & Groupby) Date ì»¬ëŸ¼ì—ì„œ 'ì‹œê°„(Hour)' ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì „ì²´ ë„ì‹œë¥¼ í†µí‹€ì–´, ì˜¤ì „ 10ì‹œ(10)ë¶€í„° ì˜¤í›„ 3ì‹œ(15) ì‚¬ì´(10ì‹œ, 15ì‹œ í¬í•¨) ì‹œê°„ëŒ€ì˜ PM2.5 í‰ê·  ë†ë„ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, PM2.5ì˜ ê²°ì¸¡ì¹˜ëŠ” ì œê±°í•˜ê³  ê³„ì‚°í•˜ë©°, ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ê²°ì¸¡ì¹˜ ë³´ê°„ & ë³µí•© ì¡°ê±´) PM2.5 ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ë¥¼ **ì „ì²´ ë°ì´í„°ì˜ ì¤‘ì•™ê°’(median)**ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤. ê·¸ í›„, 'ë‚˜ì¨' ìƒíƒœì¸ ë°ì´í„°ë¥¼ ì°¾ìœ¼ë ¤ê³  í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì¡°ê±´ 1: PM10ì´ 80 ì´ìƒ\n",
    "\n",
    "ì¡°ê±´ 2: PM2.5ê°€ 35 ì´ìƒ ìœ„ **ë‘ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¼ë„ ë§Œì¡±(OR)**í•˜ëŠ” ë°ì´í„°ì˜ **í–‰ ê°œìˆ˜(row count)**ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë¬¸ì œ 1ë²ˆì—ì„œ ì–¸ê¸‰í•œ PM10ì˜ ìŒìˆ˜ ì´ìƒì¹˜ëŠ” ë¯¸ë¦¬ ì œê±°ëœ ìƒíƒœì—ì„œ ì§„í–‰í•˜ì‹œì˜¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "44a0069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "                 Date    City       PM10      PM2.5       Temp\n",
      "0 2023-01-01 00:00:00  City_C  41.395782  25.009453  28.385131\n",
      "1 2023-01-01 01:00:00  City_C  49.862120  25.841500  -3.906242\n",
      "2 2023-01-01 02:00:00  City_C  36.678939  18.679058  35.055428\n",
      "3 2023-01-01 03:00:00  City_C  66.587579  40.386310  10.693343\n",
      "4 2023-01-01 04:00:00  City_A  45.675755  25.241757   6.889414\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 2000\n",
    "\n",
    "# 1. ë°ì´í„° ìƒì„±\n",
    "dates = pd.date_range('2023-01-01', periods=n_rows, freq='h')\n",
    "cities = np.random.choice(['City_A', 'City_B', 'City_C', 'City_D'], n_rows)\n",
    "\n",
    "# PM10: í‰ê·  50, í‘œì¤€í¸ì°¨ 20 (ê°€ë” ì„¼ì„œ ì˜¤ë¥˜ë¡œ -999 ê°’ ë°œìƒ)\n",
    "pm10 = np.random.normal(50, 20, n_rows)\n",
    "error_indices = np.random.choice(range(n_rows), 20, replace=False)\n",
    "pm10[error_indices] = -999 # ì„¼ì„œ ì˜¤ë¥˜ ê°’\n",
    "\n",
    "# PM2.5: PM10ì˜ ì•½ 60% ìˆ˜ì¤€ (ê²°ì¸¡ì¹˜ ë°œìƒ)\n",
    "pm25 = pm10 * 0.6 + np.random.normal(0, 5, n_rows)\n",
    "nan_indices = np.random.choice(range(n_rows), 50, replace=False)\n",
    "pm25[nan_indices] = np.nan # ê²°ì¸¡ì¹˜\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'City': cities,\n",
    "    'PM10': pm10,\n",
    "    'PM2.5': pm25,\n",
    "    'Temp': np.random.normal(15, 10, n_rows)\n",
    "})\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "99804810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1ë²ˆ\n",
    "#df.loc[df['PM10'] < 0, 'PM10'] = 0\n",
    "q1 = df[df['PM10'] >= 0]\n",
    "q2 = q1.groupby('City')['PM10'].mean()\n",
    "print(int(q2.loc['City_A']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "605c8b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.78\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2ë²ˆ\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Hour'] = df['Date'].dt.hour\n",
    "df_t = df[(df['Hour'] >= 10) & (df['Hour'] <= 15)]\n",
    "result = df_t['PM2.5'].mean()\n",
    "print(round(result, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f116fc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3ë²ˆ\n",
    "df = df[df['PM10'] >= 0]\n",
    "\n",
    "#print(df['PM2.5'].isna().sum())\n",
    "med = df['PM2.5'].median()\n",
    "df['PM2.5'] = df['PM2.5'].fillna(med)\n",
    "\n",
    "df_filter = df[(df['PM10'] >= 80) | (df['PM2.5'] >= 35)]\n",
    "print(len(df_filter))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81a038",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ1ìœ í˜•] ì‡¼í•‘ëª° ë°°ì†¡/íŒë§¤ ë¶„ì„\n",
    "ë¬¸ì œ 1. (ìˆœìœ„ êµ¬í•˜ê¸° - Rank) 'Tech' ì¹´í…Œê³ ë¦¬ì˜ ë°ì´í„°ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤. ë§¤ì¶œì•¡(Sales)ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ **ìˆœìœ„(Rank)**ë¥¼ ë§¤ê¸¸ ë•Œ, **ìƒìœ„ 10ìœ„ (1ë“±~10ë“±)**ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë“¤ì˜ Sales í‰ê· ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë™ì ìê°€ ìˆì„ ê²½ìš° 'min' ë°©ì‹(ì˜ˆ: 1ë“±ì´ 2ëª…ì´ë©´ ë‘˜ ë‹¤ 1ë“±, ë‹¤ìŒì€ 3ë“±)ìœ¼ë¡œ ìˆœìœ„ë¥¼ ë§¤ê¸°ë©°, ê²°ê³¼ëŠ” ì •ìˆ˜(int)ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ë‚ ì§œ ì°¨ì´ ê³„ì‚° - Timedelta) ì£¼ë¬¸ì¼(Order_Date)ë¡œë¶€í„° ë°°ì†¡ì¼(Ship_Date)ê¹Œì§€ ê±¸ë¦° ê¸°ê°„ì„ **'Delivery_Days'**ë¼ê³  í•©ë‹ˆë‹¤. (Ship_Date - Order_Date) ì „ì²´ ë°ì´í„° ì¤‘ Delivery_Daysê°€ **3ì¼ ì´ë‚´(<= 3ì¼)**ì¸ ë°ì´í„°ì˜ ë¹„ìœ¨(%)ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ê²°ê³¼ëŠ” ë°±ë¶„ìœ¨ë¡œ ë³€í™˜í•˜ì§€ ë§ê³  0~1 ì‚¬ì´ ë¹„ìœ¨ ê·¸ëŒ€ë¡œ ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ê·¸ë£¹ë³„ ë³€ë™í­ - Diff) ê° ìƒí’ˆ(Product)ë³„ë¡œ ì£¼ë¬¸ ë‚ ì§œ(Order_Date) ìˆœì„œëŒ€ë¡œ ì •ë ¬í–ˆì„ ë•Œ, ì´ì „ íŒë§¤ëŸ‰(Quantity) ëŒ€ë¹„ í˜„ì¬ íŒë§¤ëŸ‰ì˜ **ì°¨ì´(ì ˆëŒ“ê°’)**ê°€ ê°€ì¥ ì»¸ë˜ ê°’ì„ ì°¾ìœ¼ì‹œì˜¤. ì¦‰, ëª¨ë“  ìƒí’ˆì„ í†µí‹€ì–´ **\"ì „ë²ˆ ì£¼ë¬¸ ëŒ€ë¹„ íŒë§¤ëŸ‰ ë³€ë™í­\"**ì˜ ìµœëŒ“ê°’ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ê° ìƒí’ˆì˜ ì²« ë²ˆì§¸ ì£¼ë¬¸ì€ ì´ì „ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ë¬´ì‹œí•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f98b1f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "  Order_Date  Ship_Date   Category Product  Sales  Quantity\n",
      "0 2023-01-01 2023-01-03       Tech  Prod_8  41930         4\n",
      "1 2023-01-01 2023-01-06       Tech  Prod_5  31530         2\n",
      "2 2023-01-01 2023-01-07  Furniture  Prod_8  65670         5\n",
      "3 2023-01-03 2023-01-07     Office  Prod_1  88220         8\n",
      "4 2023-01-03 2023-01-05     Office  Prod_5  94630         8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 1000\n",
    "\n",
    "# 1. ë°ì´í„° ìƒì„±\n",
    "order_dates = pd.date_range('2023-01-01', '2023-12-31', freq='D')\n",
    "order_dates = np.random.choice(order_dates, n_rows)\n",
    "\n",
    "# ë°°ì†¡ì¼ì€ ì£¼ë¬¸ì¼ë¡œë¶€í„° 1~7ì¼ í›„\n",
    "ship_days = np.random.randint(1, 8, n_rows)\n",
    "ship_dates = [pd.to_datetime(d) + pd.Timedelta(days=i) for d, i in zip(order_dates, ship_days)]\n",
    "\n",
    "products = [f'Prod_{i}' for i in range(1, 11)] # ìƒí’ˆ 10ê°œ\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Order_Date': order_dates,\n",
    "    'Ship_Date': ship_dates,\n",
    "    'Category': np.random.choice(['Furniture', 'Office', 'Tech'], n_rows),\n",
    "    'Product': np.random.choice(products, n_rows),\n",
    "    'Sales': np.random.randint(100, 10000, n_rows) * 10,\n",
    "    'Quantity': np.random.randint(1, 10, n_rows)\n",
    "})\n",
    "\n",
    "# ë‚ ì§œ ì •ë ¬\n",
    "df = df.sort_values('Order_Date').reset_index(drop=True)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9bdadf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97513\n",
      "97513\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1ë²ˆ\n",
    "df_tech = df[df['Category']=='Tech'].sort_values(by='Sales', ascending=False)\n",
    "print(int(df_tech['Sales'].head(10).mean()))\n",
    "\n",
    "# ì •ì„ í’€ì´\n",
    "df_tech = df[df['Category']=='Tech'].copy()\n",
    "df_tech['Rank'] = df_tech['Sales'].rank(method='min', ascending=False)\n",
    "result = df_tech[df_tech['Rank'] <= 10]['Sales'].mean()\n",
    "print(int(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "fa78597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2ë²ˆ\n",
    "df['Order_Date'] = pd.to_datetime(df['Order_Date'])\n",
    "df['Ship_Date'] = pd.to_datetime(df['Ship_Date'])\n",
    "df['Delivery_Days'] = (df['Ship_Date'] - df['Order_Date']).dt.days\n",
    "\n",
    "inner_len = len(df[df['Delivery_Days'] <= 3])\n",
    "df_len = len(df)\n",
    "result = inner_len / df_len\n",
    "print(round(result, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "7f83e558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3ë²ˆ\n",
    "df = df.sort_values(by=['Product', 'Order_Date'])\n",
    "df['Vol_Diff'] = df.groupby('Product')['Quantity'].diff()\n",
    "df['Vol_Diff_Abs'] = df['Vol_Diff'].abs()\n",
    "print(int(df['Vol_Diff_Abs'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287f64d",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ2ìœ í˜•] ì€í–‰ ê³ ê° ì´íƒˆ ì˜ˆì¸¡\n",
    "ë¬¸ì œ: ì€í–‰ ê³ ê° ë°ì´í„°(train)ë¥¼ ì´ìš©í•˜ì—¬ ê³ ê°ì˜ ì´íƒˆ ì—¬ë¶€(Exited)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³ , ì œê³µëœ í‰ê°€ìš© ë°ì´í„°(test)ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ csv íŒŒì¼ë¡œ ì œì¶œí•˜ì‹œì˜¤.\n",
    "\n",
    "1. ë°ì´í„° ì„¤ëª…\n",
    "\n",
    "Target: Exited (1: ì´íƒˆ, 0: ìœ ì§€)\n",
    "\n",
    "Features:\n",
    "\n",
    "CustomerId: ê³ ê° ID (ì‹ë³„ì)\n",
    "\n",
    "Surname: ì„± (String)\n",
    "\n",
    "CreditScore: ì‹ ìš© ì ìˆ˜\n",
    "\n",
    "Geography: êµ­ê°€ (France, Germany, Spain)\n",
    "\n",
    "Gender: ì„±ë³„\n",
    "\n",
    "Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary\n",
    "\n",
    "2. ì œì¶œ í˜•ì‹\n",
    "\n",
    "result.csv íŒŒì¼ë¡œ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë°˜ë“œì‹œ **CustomerId**ì™€ Exited ë‘ ê°œì˜ ì»¬ëŸ¼ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "Exited ì»¬ëŸ¼ì—ëŠ” **ì´íƒˆí•  í™•ë¥ (Probability)**ì„ ì œì¶œí•˜ì‹œì˜¤. (0ê³¼ 1 ì‚¬ì´ì˜ ì†Œìˆ˜)\n",
    "\n",
    "3. í‰ê°€ ì§€í‘œ\n",
    "\n",
    "ROC-AUC (ê°’ì´ í´ìˆ˜ë¡ ì¢‹ìŒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c2a02fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "train shape: (2100, 13)\n",
      "test shape: (900, 12)\n",
      "   CustomerId   Surname  CreditScore Geography  Gender   Age  Tenure  \\\n",
      "0       10001  Williams          423    France    Male  43.0       5   \n",
      "1       10002     Jones          532   Germany  Female  54.0       9   \n",
      "2       10003     Smith          470     Spain    Male  75.0       8   \n",
      "3       10004     Brown          627   Germany  Female  81.0       0   \n",
      "4       10005     Brown          520     Spain    Male  67.0       5   \n",
      "\n",
      "         Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
      "0  156207.782854              3          0               0     61837.658280   \n",
      "1  149914.101471              2          1               1     54490.748664   \n",
      "2  132768.028528              3          0               1    126846.371424   \n",
      "3   44238.586796              1          0               0    172944.034041   \n",
      "4  105158.756047              2          1               1     58251.970535   \n",
      "\n",
      "   Exited  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 3000\n",
    "\n",
    "# 1. ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'CustomerId': np.arange(10001, 10001 + n_rows),\n",
    "    'Surname': np.random.choice(['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], n_rows),\n",
    "    'CreditScore': np.random.randint(350, 850, n_rows),\n",
    "    'Geography': np.random.choice(['France', 'Germany', 'Spain'], n_rows),\n",
    "    'Gender': np.random.choice(['Male', 'Female'], n_rows),\n",
    "    'Age': np.random.randint(18, 92, n_rows),\n",
    "    'Tenure': np.random.randint(0, 10, n_rows),\n",
    "    'Balance': np.random.uniform(0, 250000, n_rows),\n",
    "    'NumOfProducts': np.random.randint(1, 4, n_rows),\n",
    "    'HasCrCard': np.random.randint(0, 2, n_rows),\n",
    "    'IsActiveMember': np.random.randint(0, 2, n_rows),\n",
    "    'EstimatedSalary': np.random.uniform(11, 200000, n_rows),\n",
    "    'Exited': np.random.randint(0, 2, n_rows) # Target\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ ê°•ì œ ì£¼ì… (ì „ì²˜ë¦¬ ì—°ìŠµìš©)\n",
    "# Age ê²°ì¸¡ì¹˜\n",
    "df.loc[np.random.choice(df.index, 50), 'Age'] = np.nan\n",
    "# Balance ê²°ì¸¡ì¹˜\n",
    "df.loc[np.random.choice(df.index, 30), 'Balance'] = np.nan\n",
    "\n",
    "# 3. Train / Test ë¶„ë¦¬ (ì‹œí—˜ í™˜ê²½ í‰ë‚´)\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']\n",
    "\n",
    "# ì‹¤ì œ ì‹œí—˜ì—ì„œëŠ” X_testì— ì •ë‹µ(y)ì´ ì—†ìŠµë‹ˆë‹¤.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ í•©ì¹˜ê¸° (ì‹œí—˜ì—ì„œ ì œê³µë˜ëŠ” í˜•íƒœ)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = X_test # y_testëŠ” ìˆ¨ê²¨ì ¸ ìˆìŒ (ì±„ì ìš©)\n",
    "\n",
    "# CSV íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆë‹¤ê³  ê°€ì •í•˜ê³  ë³€ìˆ˜ëª…ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "print(f\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"test shape: {test.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "fdd15584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532\n",
      "      Id  pred\n",
      "0  11802     1\n",
      "1  11191     1\n",
      "2  11818     1\n",
      "3  10252     1\n",
      "4  12506     1\n"
     ]
    }
   ],
   "source": [
    "#print(train.info())\n",
    "# ê²°ì¸¡ì¹˜: Age, Balance\n",
    "# object: Geography, Gender\n",
    "\n",
    "#print(test.info())\n",
    "# ê²°ì¸¡ì¹˜: Age, Balance\n",
    "\n",
    "train['Age'] = train['Age'].fillna(train['Age'].mean())\n",
    "test['Age'] = test['Age'].fillna(train['Age'].mean())\n",
    "\n",
    "train['Balance'] = train['Balance'].fillna(train['Balance'].mean())\n",
    "test['Balance'] = test['Balance'].fillna(train['Balance'].mean())\n",
    "\n",
    "#print(test.info())\n",
    "\n",
    "X = train.drop(['CustomerId', 'Surname', 'Exited'], axis=1)\n",
    "y = train['Exited']\n",
    "X_submit = test.drop(['CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "cols = ['Geography', 'Gender']\n",
    "\n",
    "X = pd.get_dummies(X, columns=cols)\n",
    "X_submit = pd.get_dummies(X_submit, columns=cols)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc = roc_auc_score(y_val, pred_proba)\n",
    "print(round(roc, 3))\n",
    "\n",
    "model.fit(X, y)\n",
    "final_pred = model.predict(X_submit)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'Id': test['CustomerId'],\n",
    "    'pred': final_pred\n",
    "})\n",
    "result.to_csv('result.csv', index=False)\n",
    "print(pd.read_csv('result.csv').head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b8524",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ2ìœ í˜•] ìì „ê±° ëŒ€ì—¬ëŸ‰ ì˜ˆì¸¡ (íšŒê·€)\n",
    "ë¬¸ì œ: ì œê³µëœ ìì „ê±° ëŒ€ì—¬ ë°ì´í„°(train)ë¥¼ ì´ìš©í•˜ì—¬ ëŒ€ì—¬ íšŸìˆ˜(count)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³ , í‰ê°€ìš© ë°ì´í„°(test)ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ csv íŒŒì¼ë¡œ ì œì¶œí•˜ì‹œì˜¤.\n",
    "\n",
    "1. ë°ì´í„° ì„¤ëª…\n",
    "\n",
    "Target: count (ëŒ€ì—¬ íšŸìˆ˜, ìˆ˜ì¹˜í˜•)\n",
    "\n",
    "Features:\n",
    "\n",
    "ID: ê³ ìœ  ì‹ë³„ì\n",
    "\n",
    "Date: ë‚ ì§œ (datetime)\n",
    "\n",
    "Temperature, Humidity, Windspeed, Visibility: ë‚ ì”¨ ì •ë³´\n",
    "\n",
    "Holiday: ê³µíœ´ì¼ ì—¬ë¶€ (Yes/No)\n",
    "\n",
    "Hour: ì‹œê°„ (0~23)\n",
    "\n",
    "2. ì œì¶œ í˜•ì‹\n",
    "\n",
    "result.csv íŒŒì¼ë¡œ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ID**ì™€ pred ë‘ ê°œì˜ ì»¬ëŸ¼ë§Œ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "pred ì»¬ëŸ¼ì—ëŠ” ì˜ˆì¸¡í•œ ëŒ€ì—¬ íšŸìˆ˜(ì‹¤ìˆ˜ ë˜ëŠ” ì •ìˆ˜)ë¥¼ ì…ë ¥í•˜ì‹œì˜¤.\n",
    "\n",
    "3. í‰ê°€ ì§€í‘œ\n",
    "\n",
    "MAE (Mean Absolute Error)\n",
    "\n",
    "(ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¢‹ì€ ì„±ëŠ¥ì…ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9bcb496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "train shape: (1400, 9)\n",
      "test shape: (600, 8)\n",
      "        ID                Date  Temperature  Humidity  Windspeed  Visibility  \\\n",
      "836   1836 2023-02-04 20:00:00    27.741598        39   4.947782         836   \n",
      "575   1575 2023-01-24 23:00:00    20.760819        80        NaN        1787   \n",
      "557   1557 2023-01-24 05:00:00    15.534825        61   2.401177        1261   \n",
      "1235  2235 2023-02-21 11:00:00    26.003205        64   7.495187         971   \n",
      "1360  2360 2023-02-26 16:00:00    18.989828        52   0.973485         958   \n",
      "\n",
      "     Holiday  Hour  count  \n",
      "836       No    14    205  \n",
      "575       No     5    153  \n",
      "557       No    10    204  \n",
      "1235      No     7    152  \n",
      "1360      No     8    138  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 2000\n",
    "\n",
    "# 1. ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'ID': np.arange(1000, 1000 + n_rows),\n",
    "    'Date': pd.date_range('2023-01-01', periods=n_rows, freq='h'),\n",
    "    'Temperature': np.random.normal(20, 5, n_rows), # ê¸°ì˜¨\n",
    "    'Humidity': np.random.randint(30, 90, n_rows),  # ìŠµë„\n",
    "    'Windspeed': np.random.uniform(0, 10, n_rows),  # í’ì†\n",
    "    'Visibility': np.random.randint(500, 2000, n_rows), # ê°€ì‹œê±°ë¦¬\n",
    "    'Holiday': np.random.choice(['No', 'Yes'], n_rows, p=[0.95, 0.05]), # ê³µíœ´ì¼\n",
    "    'Hour': np.random.randint(0, 24, n_rows), # ì‹œê°„\n",
    "    'count': 0 # Target ì´ˆê¸°í™”\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Target ìƒì„± (ëŒ€ì—¬ëŸ‰ì€ ê¸°ì˜¨ì´ ë†’ê³ , í‡´ê·¼ì‹œê°„ì— ë§ë‹¤ëŠ” ê°€ì •)\n",
    "df['count'] = 100 + (df['Temperature'] * 3) + (df['Hour'] * 5) - (df['Humidity'] * 0.5)\n",
    "df['count'] = df['count'] + np.random.normal(0, 20, n_rows) # ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "df['count'] = df['count'].apply(lambda x: max(0, int(x))) # ìŒìˆ˜ ë°©ì§€ ë° ì •ìˆ˜í™”\n",
    "\n",
    "# 2. ê²°ì¸¡ì¹˜ ì£¼ì… (ì „ì²˜ë¦¬ ì—°ìŠµìš©)\n",
    "df.loc[np.random.choice(df.index, 50), 'Windspeed'] = np.nan\n",
    "\n",
    "# 3. Train / Test ë¶„ë¦¬\n",
    "X = df.drop('count', axis=1)\n",
    "y = df['count']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = X_test\n",
    "\n",
    "print(f\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"test shape: {test.shape}\")\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "13724801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.27\n",
      "     ID    pred\n",
      "0  2860  127.66\n",
      "1  1353  118.44\n",
      "2  2333  182.31\n",
      "3  1905  221.30\n",
      "4  2289  205.26\n"
     ]
    }
   ],
   "source": [
    "#print(test.info())\n",
    "# ê²°ì¸¡ì¹˜: windspeed\n",
    "# ì¸ì½”ë”©: Holiday\n",
    "# ì‚­ì œ: ID, Date\n",
    "\n",
    "train['Windspeed'] = train['Windspeed'].fillna(train['Windspeed'].mean())\n",
    "test['Windspeed'] = test['Windspeed'].fillna(train['Windspeed'].mean())\n",
    "\n",
    "X = train.drop(['ID', 'Date', 'count'], axis=1)\n",
    "y = train['count']\n",
    "X_submit = test.drop(['ID', 'Date'], axis=1)\n",
    "\n",
    "X = pd.get_dummies(X, columns=['Holiday'])\n",
    "X_submit = pd.get_dummies(X_submit, columns=['Holiday'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pred_val = mean_absolute_error(y_val, pred)\n",
    "print(round(pred_val, 3))\n",
    "\n",
    "model.fit(X, y)\n",
    "final_pred = model.predict(X_submit)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'pred': final_pred\n",
    "})\n",
    "result.to_csv('result1.csv', index=False)\n",
    "print(pd.read_csv('result1.csv').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b73708",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ2ìœ í˜•] ì „ììƒê±°ë˜ êµ¬ë§¤ ì˜ˆì¸¡\n",
    "ë¬¸ì œ: ì œê³µëœ ê³ ê° ë°ì´í„°(train)ë¥¼ ì´ìš©í•˜ì—¬ ê³ ê°ì´ ìƒí’ˆì„ êµ¬ë§¤í• ì§€(Purchase) ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³ , í‰ê°€ìš© ë°ì´í„°(test)ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ result.csv íŒŒì¼ë¡œ ì œì¶œí•˜ì‹œì˜¤.\n",
    "\n",
    "1. ë°ì´í„° ì„¤ëª…\n",
    "\n",
    "Target: Purchase (1: êµ¬ë§¤, 0: ë¹„êµ¬ë§¤)\n",
    "\n",
    "Features:\n",
    "\n",
    "UserID: ê³ ê° ID (ë¶ˆí•„ìš”í•œ ì‹ë³„ì)\n",
    "\n",
    "Age, AnnualIncome, BrowsingTime, PagesViewed: ìˆ˜ì¹˜í˜• ì •ë³´\n",
    "\n",
    "MembershipTier: íšŒì› ë“±ê¸‰ (Bronze, Silver, Gold)\n",
    "\n",
    "DeviceType: ì ‘ì† ê¸°ê¸° (Mobile, Desktop, Tablet)\n",
    "\n",
    "2. ì œì¶œ í˜•ì‹\n",
    "\n",
    "result.csv íŒŒì¼ë¡œ ì €ì¥.\n",
    "\n",
    "**UserID**ì™€ pred ë‘ ê°œì˜ ì»¬ëŸ¼ë§Œ í¬í•¨.\n",
    "\n",
    "pred ì»¬ëŸ¼ì—ëŠ” **êµ¬ë§¤í•  í™•ë¥ (Probability)**ì„ ì œì¶œí•˜ì‹œì˜¤. (0~1 ì‚¬ì´ ê°’)\n",
    "\n",
    "3. í‰ê°€ ì§€í‘œ\n",
    "\n",
    "ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "18d8d25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ! (ê²°ì¸¡ì¹˜ ì—†ìŒ)\n",
      "train shape: (2800, 8)\n",
      "test shape: (1200, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 4000\n",
    "\n",
    "# 1. ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'UserID': np.arange(10001, 10001 + n_rows),\n",
    "    'Age': np.random.randint(18, 70, n_rows),\n",
    "    'AnnualIncome': np.random.randint(20000, 150000, n_rows),\n",
    "    'BrowsingTime': np.random.normal(30, 10, n_rows), # ë¶„ ë‹¨ìœ„\n",
    "    'PagesViewed': np.random.randint(1, 20, n_rows),\n",
    "    'MembershipTier': np.random.choice(['Bronze', 'Silver', 'Gold'], n_rows, p=[0.5, 0.3, 0.2]),\n",
    "    'DeviceType': np.random.choice(['Mobile', 'Desktop', 'Tablet'], n_rows),\n",
    "    'Purchase': 0 # Target ì´ˆê¸°í™”\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Target ìƒì„± (êµ¬ë§¤ í™•ë¥ : ê³¨ë“œ íšŒì›ì¼ìˆ˜ë¡, ìˆ˜ì…ì´ ë§ì„ìˆ˜ë¡, ë§ì´ ë³¼ìˆ˜ë¡ ë†’ìŒ)\n",
    "logits = -5 + (df['AnnualIncome'] / 50000) + (df['BrowsingTime'] / 20) + (df['PagesViewed'] / 5)\n",
    "logits += np.where(df['MembershipTier'] == 'Gold', 2, 0)\n",
    "logits += np.where(df['MembershipTier'] == 'Silver', 1, 0)\n",
    "probs = 1 / (1 + np.exp(-logits))\n",
    "df['Purchase'] = np.random.binomial(1, probs)\n",
    "\n",
    "# 3. ë°ì´í„° ë¶„ë¦¬\n",
    "X = df.drop('Purchase', axis=1)\n",
    "y = df['Purchase']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ì‹œí—˜ ì œê³µ í˜•íƒœ\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = X_test\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ! (ê²°ì¸¡ì¹˜ ì—†ìŒ)\")\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "00ab57ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806\n",
      "      UserID  pred\n",
      "0      10556  0.51\n",
      "1      13492  0.71\n",
      "2      10528  0.99\n",
      "3      13926  0.62\n",
      "4      12990  0.95\n",
      "...      ...   ...\n",
      "1195   13857  0.73\n",
      "1196   10227  0.50\n",
      "1197   11613  0.91\n",
      "1198   10536  0.64\n",
      "1199   13849  0.66\n",
      "\n",
      "[1200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(test.info())\n",
    "# ì œê±°: UserID\n",
    "# ì¸ì½”ë”©: MembershipTier, DeviceType\n",
    "# í™•ë¥  -> classfier\n",
    "\n",
    "X = train.drop(['UserID', 'Purchase'], axis=1)\n",
    "y = train['Purchase']\n",
    "X_submit = test.drop('UserID', axis=1)\n",
    "\n",
    "cols = ['MembershipTier', 'DeviceType']\n",
    "\n",
    "X = pd.get_dummies(X, columns=cols)\n",
    "X_submit = pd.get_dummies(X_submit, columns=cols)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred_proba = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "score = roc_auc_score(y_val, pred_proba)\n",
    "print(round(score, 3))\n",
    "\n",
    "model.fit(X, y)\n",
    "pred_proba_final = model.predict_proba(X_submit)[:,1]\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'UserID': test['UserID'],\n",
    "    'pred': pred_proba_final\n",
    "})\n",
    "\n",
    "result.to_csv('result2.csv', index=False)\n",
    "print(pd.read_csv('result2.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45360579",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ3ìœ í˜•] í†µê³„ì  ê°€ì„¤ ê²€ì •\n",
    "ë¬¸ì œ 1. (ëŒ€ì‘í‘œë³¸ t-ê²€ì •) 'Treatment'(íˆ¬ì•½êµ°) ê·¸ë£¹ì— ì†í•œ í™˜ìë“¤ì˜ **íˆ¬ì•½ ì „(BP_Pre)**ê³¼ íˆ¬ì•½ í›„(BP_Post) í˜ˆì•• ì°¨ì´ê°€ ìœ ì˜ë¯¸í•œì§€ ê²€ì •í•˜ë ¤ê³  í•©ë‹ˆë‹¤. (ê°€ì„¤: íˆ¬ì•½ í›„ í˜ˆì••ì´ íˆ¬ì•½ ì „ê³¼ ë‹¤ë¥´ë‹¤.) **ëŒ€ì‘í‘œë³¸ t-ê²€ì •(Paired t-test)**ì„ ìˆ˜í–‰í•˜ê³ , **ê²€ì •í†µê³„ëŸ‰(t-value)**ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •) íˆ¬ì—¬ ê·¸ë£¹(Group)ê³¼ ë¶€ì‘ìš© ë°œìƒ ì—¬ë¶€(Side_Effects)ê°€ ì„œë¡œ ê´€ë ¨ì´ ìˆëŠ”ì§€(ë…ë¦½ì´ ì•„ë‹Œì§€) ê²€ì •í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ , **p-ê°’(p-value)**ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ë„·ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ & ì˜¤ì¦ˆë¹„) ì¹˜ë£Œ ì„±ê³µ ì—¬ë¶€(Success)ë¥¼ ì¢…ì†ë³€ìˆ˜ë¡œ í•˜ê³ , Ageì™€ BMIë¥¼ ë…ë¦½ë³€ìˆ˜ë¡œ í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì„ ìˆ˜í–‰í•˜ì‹œì˜¤. ì´ë•Œ **BMI ë³€ìˆ˜ì˜ ì˜¤ì¦ˆë¹„(Odds Ratio)**ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, statsmodelsë¥¼ ì‚¬ìš©í•˜ê³ , ê²°ê³¼ê°’ì€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "75ccdee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "   ID      Group  Age        BMI      BP_Pre Side_Effects     BP_Post  Success\n",
      "0   1  Treatment   49  25.536214  115.545523          Yes  107.602568        0\n",
      "1   2  Treatment   75  25.708310  118.339493           No  114.446628        0\n",
      "2   3  Treatment   45  25.510836  115.130393           No  114.998380        0\n",
      "3   4  Treatment   29  27.439367  128.171946           No  125.530657        0\n",
      "4   5  Treatment   32  19.326160  129.338332           No  119.815970        0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n = 300\n",
    "\n",
    "data = {\n",
    "    'ID': range(1, n + 1),\n",
    "    'Group': np.random.choice(['Treatment', 'Control'], n),\n",
    "    'Age': np.random.randint(25, 80, n),\n",
    "    'BMI': np.random.normal(25, 4, n),\n",
    "    'BP_Pre': np.random.normal(130, 10, n),\n",
    "    'Side_Effects': np.random.choice(['Yes', 'No'], n, p=[0.15, 0.85])\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# íˆ¬ì•½ í›„ í˜ˆì•• ìƒì„± (Treatment ê·¸ë£¹ë§Œ í˜ˆì••ì´ ë–¨ì–´ì§€ëŠ” íš¨ê³¼ ë¶€ì—¬)\n",
    "def get_bp_post(row):\n",
    "    change = np.random.normal(-5, 5) if row['Group'] == 'Treatment' else np.random.normal(0, 3)\n",
    "    return row['BP_Pre'] + change\n",
    "\n",
    "df['BP_Post'] = df.apply(get_bp_post, axis=1)\n",
    "\n",
    "# ì¹˜ë£Œ ì„±ê³µ ì—¬ë¶€ (BMIê°€ ë‚®ì„ìˆ˜ë¡, ë‚˜ì´ê°€ ì ì„ìˆ˜ë¡ ì„±ê³µ í™•ë¥  ë†’ìŒ)\n",
    "logits = 2 - 0.1 * df['BMI'] - 0.02 * df['Age'] + np.random.normal(0, 1, n)\n",
    "probs = 1 / (1 + np.exp(-logits))\n",
    "df['Success'] = np.random.binomial(1, probs)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9674ec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.205\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1\n",
    "target_df = df[df['Group']=='Treatment']\n",
    "before = target_df['BP_Pre']\n",
    "after = target_df['BP_Post']\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "t_stat, p_val = ttest_rel(before, after)\n",
    "print(round(t_stat, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "87fb4fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.283\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2\n",
    "from scipy.stats import chi2_contingency\n",
    "group = df['Group']\n",
    "side_effects = df['Side_Effects']\n",
    "\n",
    "ct = pd.crosstab(group, side_effects)\n",
    "\n",
    "chi2, p_val, ddof, expected = chi2_contingency(ct)\n",
    "print(round(p_val, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5184f4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.465692\n",
      "         Iterations 6\n",
      "0.939\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3\n",
    "from statsmodels.formula.api import logit\n",
    "model = logit('Success ~ Age + BMI', data=df).fit()\n",
    "#print(model.summary())\n",
    "\n",
    "import numpy as np\n",
    "odds_ratio = np.exp(model.params['BMI'])\n",
    "print(round(odds_ratio, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed132f2",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ3ìœ í˜•] íšŒê·€ë¶„ì„ ì¢…í•© ë¬¸ì œ\n",
    "ë¬¸ì œ 1. (ë‹¤ì¤‘íšŒê·€ë¶„ì„ - OLS) íˆ¬ì•½ í›„ í˜ˆì••(BP_Post)ì„ ì¢…ì†ë³€ìˆ˜ë¡œ í•˜ê³ , íˆ¬ì•½ ì „ í˜ˆì••(BP_Pre), ë‚˜ì´(Age), ì²´ì§ˆëŸ‰ì§€ìˆ˜(BMI)ë¥¼ ë…ë¦½ë³€ìˆ˜ë¡œ í•˜ëŠ” ë‹¤ì¤‘ì„ í˜•íšŒê·€ ëª¨ë¸ì„ ìƒì„±í•˜ì‹œì˜¤. ì´ë•Œ, **BP_Pre (íˆ¬ì•½ ì „ í˜ˆì••)ì˜ íšŒê·€ê³„ìˆ˜(Coefficient)**ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ë„·ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ë¡œì§€ìŠ¤í‹± íšŒê·€ - ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ì˜¤ì¦ˆë¹„) ì¹˜ë£Œ ì„±ê³µ ì—¬ë¶€(Success)ë¥¼ ì¢…ì†ë³€ìˆ˜ë¡œ í•˜ê³ , Age, BMI, Groupì„ ë…ë¦½ë³€ìˆ˜ë¡œ í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ ìƒì„±í•˜ì‹œì˜¤. ì´ë•Œ, 'Treatment'(íˆ¬ì•½êµ°) ê·¸ë£¹ì˜ í™˜ìëŠ” 'Control'(ëŒ€ì¡°êµ°) ê·¸ë£¹ì˜ í™˜ìë³´ë‹¤ ì¹˜ë£Œ ì„±ê³µ ì˜¤ì¦ˆ(Odds)ê°€ ëª‡ ë°°ì¸ì§€(ì˜¤ì¦ˆë¹„) êµ¬í•˜ì‹œì˜¤. (ë‹¨, Controlì„ ê¸°ì¤€(0), Treatmentë¥¼ ë¹„êµ(1)ë¡œ ì²˜ë¦¬í•˜ë©°, ì˜¤ì¦ˆë¹„ëŠ” ì†Œìˆ˜ì  ë„·ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ë¡œì§€ìŠ¤í‹± íšŒê·€ - í™•ë¥  ì˜ˆì¸¡) 2ë²ˆ ë¬¸ì œì—ì„œ ë§Œë“  ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬, ì „ì²´ ë°ì´í„°(df) í™˜ìë“¤ì˜ **ì¹˜ë£Œ ì„±ê³µ í™•ë¥ (Probability)**ì„ ì˜ˆì¸¡í•˜ì‹œì˜¤. ì˜ˆì¸¡ëœ ì¹˜ë£Œ ì„±ê³µ í™•ë¥ ì´ **0.6 ì´ìƒ(>= 0.6)**ì¸ í™˜ìì˜ **ì¸ì›ìˆ˜(ëª…)**ë¥¼ êµ¬í•˜ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7edf1e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "   ID      Group  Age        BMI      BP_Pre     BP_Post  Treatment_Code  \\\n",
      "0   1  Treatment   39  30.087421  128.659704  135.787762               1   \n",
      "1   2  Treatment   75  27.065314  128.106733  136.317723               1   \n",
      "2   3  Treatment   73  25.347528  138.199694  144.206251               1   \n",
      "\n",
      "   Success  \n",
      "0        0  \n",
      "1        1  \n",
      "2        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n = 500\n",
    "\n",
    "# ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'ID': range(1, n + 1),\n",
    "    'Group': np.random.choice(['Treatment', 'Control'], n), # íˆ¬ì•½êµ°, ëŒ€ì¡°êµ°\n",
    "    'Age': np.random.randint(25, 80, n),\n",
    "    'BMI': np.random.normal(25, 4, n),\n",
    "    'BP_Pre': np.random.normal(130, 10, n), # íˆ¬ì•½ ì „ í˜ˆì••\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ì¢…ì†ë³€ìˆ˜ ìƒì„± (ì„ í˜• ê´€ê³„)\n",
    "# íˆ¬ì•½ í›„ í˜ˆì•• = íˆ¬ì•½ ì „ * 0.9 + ë‚˜ì´ * 0.1 + BMI * 0.5 - (Treatmentì¸ ê²½ìš° 10)\n",
    "def get_bp_post(row):\n",
    "    effect = -10 if row['Group'] == 'Treatment' else 0\n",
    "    base = row['BP_Pre'] * 0.9 + row['Age'] * 0.1 + row['BMI'] * 0.5 + 10\n",
    "    return base + effect + np.random.normal(0, 2, 1)[0]\n",
    "\n",
    "df['BP_Post'] = df.apply(get_bp_post, axis=1)\n",
    "\n",
    "# ì¢…ì†ë³€ìˆ˜ ìƒì„± (ë¡œì§€ìŠ¤í‹± ê´€ê³„)\n",
    "# Treatmentì¼ ë•Œ ì„±ê³µ í™•ë¥  ì¦ê°€, BMI ë‚®ì„ìˆ˜ë¡ ì„±ê³µ\n",
    "df['Treatment_Code'] = df['Group'].map({'Treatment': 1, 'Control': 0})\n",
    "logits = -2 + 1.5 * df['Treatment_Code'] - 0.1 * df['BMI'] + 0.02 * df['Age']\n",
    "probs = 1 / (1 + np.exp(-logits))\n",
    "df['Success'] = np.random.binomial(1, probs)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ab9697e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.895\n"
     ]
    }
   ],
   "source": [
    "# 1ë²ˆ ë¬¸ì œ\n",
    "from statsmodels.formula.api import ols\n",
    "model = ols('BP_Post ~ BP_Pre + Age + BMI', data=df).fit()\n",
    "coef = model.params['BP_Pre']\n",
    "print(round(coef, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8557132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.208368\n",
      "         Iterations 9\n",
      "19.577\n"
     ]
    }
   ],
   "source": [
    "# 2ë²ˆ ë¬¸ì œ\n",
    "from statsmodels.formula.api import logit\n",
    "model = logit('Success ~ Age + BMI + Group', data=df).fit()\n",
    "coef = model.params['Group[T.Treatment]']\n",
    "# ì„¤ëª… (ìë™ ë”ë¯¸ ë³€ìˆ˜í™” - ë¬¸ìì—´)\n",
    "odds_ratio = np.exp(coef)\n",
    "print(round(odds_ratio, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4341ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 3ë²ˆ ë¬¸ì œ - ì™¸ìš°ê¸°\n",
    "pred_proba = model.predict(df)\n",
    "target = pred_proba[pred_proba >= 0.6]\n",
    "result = len(target)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3eda20",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ3ìœ í˜•] ë¶„ì‚°ë¶„ì„í‘œ (ANOVA Table) í•´ì„\n",
    "ë¬¸ì œ 1. (ANOVA ëª¨ë¸ ì í•©) ì‹ì´ìš”ë²• ìœ í˜•(Diet)ì— ë”°ë¥¸ ì²´ì¤‘ ê°ëŸ‰(Weight_Loss)ì˜ ì°¨ì´ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•´, ols í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ ìƒì„±í•˜ê³  ì í•©(fit)ì‹œí‚¤ì‹œì˜¤. ìƒì„±ëœ ëª¨ë¸ ê°ì²´ë¥¼ ì´ìš©í•˜ì—¬ anova_lm í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ í…Œì´ë¸”ì—ì„œ **Diet ë³€ìˆ˜ì˜ F-í†µê³„ëŸ‰(F-value)**ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ì”ì°¨ ì œê³±í•© - SSE) 1ë²ˆì—ì„œ êµ¬í•œ ë¶„ì‚°ë¶„ì„í‘œ(ANOVA Table)ë¥¼ í™•ì¸í•˜ì—¬, ì„¤ëª…ë˜ì§€ ì•ŠëŠ” ë³€ë™ì¸ **ì”ì°¨(Residual)ì˜ ì œê³±í•©(Sum of Squares)**ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (p-value í•´ì„) ë¶„ì‚°ë¶„ì„ ê²°ê³¼ì˜ **p-ê°’(PR(>F))**ì„ êµ¬í•˜ê³ , ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì—ì„œ ê·€ë¬´ê°€ì„¤(ì„¸ ê·¸ë£¹ì˜ í‰ê· ì€ ê°™ë‹¤)ì„ ê¸°ê°í•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨í•˜ì‹œì˜¤. (p-ê°’ì€ ì†Œìˆ˜ ë„·ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì¶œë ¥í•˜ê³ , ê¸°ê° ì—¬ë¶€ëŠ” \"ê¸°ê°\" ë˜ëŠ” \"ì±„íƒ\"ìœ¼ë¡œ ì¶œë ¥í•˜ì‹œì˜¤. ì •ë‹µ ì˜ˆì‹œ: 0.0123 ê¸°ê°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6f7434c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "   ID    Diet  Weight_Loss\n",
      "0   1  Type_C     6.616633\n",
      "1   2  Type_C     5.644096\n",
      "2   3  Type_C     6.007296\n",
      "3   4  Type_C     3.862329\n",
      "4   5  Type_A     2.226040\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n = 150\n",
    "\n",
    "# ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'ID': range(1, n + 1),\n",
    "    'Diet': np.random.choice(['Type_A', 'Type_B', 'Type_C'], n),\n",
    "    'Weight_Loss': np.zeros(n)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ê·¸ë£¹ë³„ íš¨ê³¼ ë¶€ì—¬ (C > B > A ìˆœìœ¼ë¡œ ê°ëŸ‰ íš¨ê³¼ í¼)\n",
    "def get_weight_loss(diet):\n",
    "    base = np.random.normal(2, 1) # ê¸°ë³¸ ê°ëŸ‰\n",
    "    if diet == 'Type_B': return base + 2  # BëŠ” +2kg ë” ê°ëŸ‰\n",
    "    elif diet == 'Type_C': return base + 4 # CëŠ” +4kg ë” ê°ëŸ‰\n",
    "    else: return base # AëŠ” ê¸°ë³¸\n",
    "\n",
    "df['Weight_Loss'] = df['Diet'].apply(get_weight_loss)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2cc46efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             df      sum_sq     mean_sq          F        PR(>F)\n",
      "C(Diet)     2.0  433.580080  216.790040  238.35233  7.359841e-47\n",
      "Residual  147.0  133.701801    0.909536        NaN           NaN\n",
      "238.352\n",
      "133.702\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "model = ols('Weight_Loss ~C(Diet)', data=df).fit()\n",
    "anova_table = anova_lm(model)\n",
    "print(anova_table)\n",
    "\n",
    "f_stat = anova_table.loc['C(Diet)', 'F']\n",
    "print(round(f_stat, 3))\n",
    "\n",
    "sse = anova_table.loc['Residual', 'sum_sq']\n",
    "print(round(sse, 3))\n",
    "\n",
    "p_val = anova_table.loc['C(Diet)', 'PR(>F)']\n",
    "print(round(p_val, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20094737",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ3ìœ í˜•] ë¹„ëª¨ìˆ˜ & ë¹„ìœ¨ & íšŒê·€ í‰ê°€\n",
    "\n",
    "ë¬¸ì œ 1. (ë¹„ëª¨ìˆ˜ ëŒ€ì‘í‘œë³¸ ê²€ì • - ìœŒì½•ìŠ¨ ë¶€í˜¸ìˆœìœ„)ë™ì¼í•œ ê³ ê°ì˜ ìº í˜ì¸ ì „(Satis_Pre)ê³¼ í›„(Satis_Post)ì˜ ë§Œì¡±ë„ ì°¨ì´ë¥¼ ë¹„êµí•˜ë ¤ê³  í•©ë‹ˆë‹¤.ë°ì´í„°ê°€ ì •ê·œì„±ì„ ë§Œì¡±í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  ê°€ì •í•˜ê³ , **ìœŒì½•ìŠ¨ ë¶€í˜¸ìˆœìœ„ ê²€ì •(Wilcoxon Signed-Rank Test)**ì„ ìˆ˜í–‰í•˜ì‹œì˜¤.ì´ë•Œì˜ **ê²€ì •í†µê³„ëŸ‰(statistic)**ì„ êµ¬í•˜ì‹œì˜¤.(ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ì„ í˜• íšŒê·€ë¶„ì„ - ê²°ì •ê³„ìˆ˜ $R^2$)êµ¬ë§¤ ê¸ˆì•¡(Purchase)ì„ ì¢…ì†ë³€ìˆ˜ë¡œ í•˜ê³ , ìº í˜ì¸ ì „ ë§Œì¡±ë„(Satis_Pre)ì™€ í›„ ë§Œì¡±ë„(Satis_Post)ë¥¼ ë…ë¦½ë³€ìˆ˜ë¡œ í•˜ëŠ” ë‹¤ì¤‘ì„ í˜•íšŒê·€ ëª¨ë¸ì„ ìƒì„±í•˜ì‹œì˜¤. (ols ì‚¬ìš©)ì´ ëª¨ë¸ì˜ ê²°ì •ê³„ìˆ˜(R-squared) ê°’ì„ êµ¬í•˜ì‹œì˜¤.(ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "       \n",
    "ë¬¸ì œ 3. (ë¹„ìœ¨ ê²€ì • - 1í‘œë³¸)ì „ì²´ ê³ ê° ì¤‘ ì´ë²¤íŠ¸ ë°°ë„ˆë¥¼ í´ë¦­(Clicked=1)í•œ ë¹„ìœ¨ì´ **35%**ì™€ ë‹¤ë¥¸ì§€ ê²€ì •í•˜ë ¤ê³  í•©ë‹ˆë‹¤.**1í‘œë³¸ ë¹„ìœ¨ ê²€ì •(One-Proportion Z-test)**ì„ ìˆ˜í–‰í•˜ê³  p-ê°’ì„ êµ¬í•˜ì‹œì˜¤.(ë‹¨, proportions_ztestë¥¼ ì‚¬ìš©í•˜ë˜, alternative='two-sided'(ì–‘ì¸¡ê²€ì •)ë¡œ ì„¤ì •í•˜ë©°, p-ê°’ì€ ì†Œìˆ˜ ë„·ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bbd2aef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "   ID    Store  Satis_Pre      Purchase  Clicked  Satis_Post\n",
      "0   1   Jamsil          4  50280.810091        1           6\n",
      "1   2   Jamsil          5  46781.064946        1           5\n",
      "2   3   Jamsil          7  37092.167520        1           9\n",
      "3   4   Jamsil          6  65087.481495        1           8\n",
      "4   5  Gangnam          7  58943.399478        1           9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n = 200\n",
    "\n",
    "data = {\n",
    "    'ID': range(1, n + 1),\n",
    "    'Store': np.random.choice(['Gangnam', 'Hongdae', 'Jamsil'], n),\n",
    "    'Satis_Pre': np.random.randint(3, 8, n),\n",
    "    'Purchase': np.random.normal(50000, 10000, n),\n",
    "    'Clicked': np.random.binomial(1, 0.4, n) # 40% í™•ë¥ ë¡œ í´ë¦­\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ë§Œì¡±ë„ í›„: ì „ë³´ë‹¤ í‰ê·  1.5ì  ìƒìŠ¹, ì •ê·œë¶„í¬ ì•„ë‹˜(ìˆœìœ„í˜•)\n",
    "df['Satis_Post'] = df['Satis_Pre'] + np.random.choice([0, 1, 2, 3], n, p=[0.1, 0.3, 0.4, 0.2])\n",
    "df['Satis_Post'] = df['Satis_Post'].clip(upper=10) # 10ì  ë§Œì  ì œí•œ\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7d4f428b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1ë²ˆ\n",
    "group_before = df['Satis_Pre']\n",
    "group_after = df['Satis_Post']\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "stat, p_val = wilcoxon(group_before, group_after)\n",
    "print(round(stat, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e2664382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2ë²ˆ\n",
    "from statsmodels.formula.api import ols\n",
    "model = ols('Purchase ~ Satis_Pre + Satis_Post', data=df).fit()\n",
    "print(round(model.rsquared, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d713e54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8825\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3ë²ˆ\n",
    "count = df['Clicked'].sum()\n",
    "nobs = len(df)\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "stat, p_val = proportions_ztest(count, nobs, value=0.35, alternative='two-sided')\n",
    "print(round(p_val, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47917312",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ3ìœ í˜•] í†µì‹ ì‚¬ ê³ ê° ì´íƒˆ ë¶„ì„\n",
    "í•œ í†µì‹  íšŒì‚¬ì—ì„œëŠ” ê³ ê° ì´íƒˆì„ ì¤„ì´ê³ ì ì£¼ìš” ìš”ì¸ë“¤ì„ ë¶„ì„í•˜ê¸°ë¡œ ê²°ì •í•˜ì˜€ë‹¤. ì´ë¥¼ ìœ„í•´ 500ëª…ì˜ ê³ ê° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í–ˆìœ¼ë©° ê³ ê°ì˜ ì„œë¹„ìŠ¤ ì´ìš© ë° ê°€ì…ì •ë³´, ê·¸ë¦¬ê³  ì¼ë¶€ ê°œì¸ì ì¸ ì†ì„±ì„ ì¡°ì‚¬í•˜ì˜€ë‹¤.\n",
    "\n",
    "1. ëª¨ë“  ì»¬ëŸ¼(ID ì œì™¸)ì„ í™œìš©í•˜ì—¬ Churn(ì´íƒˆ ì—¬ë¶€)ì„ ì˜ˆì¸¡í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¶„ì„ì„ ì‹œí–‰í•œ í›„, col1 ì¹¼ëŸ¼ì˜ p-valueë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, Contract ë³€ìˆ˜ëŠ” ë²”ì£¼í˜•ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©°, ê²°ê³¼ê°’ì€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "2. ìœ„ ëª¨ë¸ì—ì„œ PhoneServiceë¥¼ ë°›ì§€ ì•Šì€ ê³ ê°(0) ëŒ€ë¹„ ë°›ì€ ê³ ê°(1)ì˜ ì´íƒˆ í™•ë¥  ì˜¤ì¦ˆë¹„(Odds Ratio)ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "3. ìœ„ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì „ì²´ ê³ ê°ì˜ ì´íƒˆ í™•ë¥ (Probability)ì„ ì˜ˆì¸¡í•˜ê³ , ì´íƒˆí•  í™•ë¥ ì´ 0.3 ì´ìƒì¸ ê³ ê° ìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "12636bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "   ID       col1  Tenure  PhoneService        Contract  Churn\n",
      "0   1  67.228295      32             1  Month-to-month      0\n",
      "1   2  92.028567      17             1  Month-to-month      1\n",
      "2   3  26.833539      71             1        One year      0\n",
      "3   4  50.097339      20             1  Month-to-month      0\n",
      "4   5  66.978157       6             0        Two year      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n = 500\n",
    "\n",
    "# 1. ë…ë¦½ë³€ìˆ˜ ìƒì„±\n",
    "data = {\n",
    "    'ID': range(1, n + 1),\n",
    "    'col1': np.random.normal(70, 30, n), # ì›” ìš”ê¸ˆ (ìˆ˜ì¹˜í˜•)\n",
    "    'Tenure': np.random.randint(1, 72, n), # ê°€ì… ê¸°ê°„ (ìˆ˜ì¹˜í˜•)\n",
    "    'PhoneService': np.random.choice([0, 1], n, p=[0.1, 0.9]), # 0: ë¯¸ê°€ì…, 1: ê°€ì…\n",
    "    'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], n)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. ì¢…ì†ë³€ìˆ˜(Churn) ìƒì„± (ë¡œì§€ìŠ¤í‹± ê´€ê³„)\n",
    "# col1(ìš”ê¸ˆ)ì´ ë†’ì„ìˆ˜ë¡, Tenure(ê¸°ê°„)ê°€ ì§§ì„ìˆ˜ë¡, PhoneServiceê°€ ì—†ì„ìˆ˜ë¡ ì´íƒˆ í™•ë¥  ë†’ìŒ\n",
    "# Contract: Month-to-monthê°€ ì´íƒˆ í™•ë¥  ë†’ìŒ\n",
    "contract_map = {'Month-to-month': 2, 'One year': 1, 'Two year': 0}\n",
    "contract_score = df['Contract'].map(contract_map)\n",
    "\n",
    "logits = -3 + (0.05 * df['col1']) - (0.05 * df['Tenure']) + (0.5 * contract_score) - (1.2 * df['PhoneService'])\n",
    "probs = 1 / (1 + np.exp(-logits))\n",
    "df['Churn'] = np.random.binomial(1, probs)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9bb42917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.387853\n",
      "         Iterations 7\n",
      "0.0\n",
      "0.332\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1ë²ˆ\n",
    "df_d = df.drop('ID', axis=1)\n",
    "from statsmodels.formula.api import logit\n",
    "model = logit('Churn ~ col1 + Tenure + PhoneService + C(Contract)', data=df_d).fit()\n",
    "print(round(model.pvalues['col1'], 3))\n",
    "\n",
    "# ë¬¸ì œ 2ë²ˆ\n",
    "odds_ratio = np.exp(model.params['PhoneService'])\n",
    "print(round(odds_ratio, 3))\n",
    "\n",
    "# ë¬¸ì œ 3ë²ˆ\n",
    "pred = model.predict(df_d)\n",
    "result3 = sum(pred >= 0.3)\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b823c",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ3ìœ í˜•] ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ íƒìƒ‰ (ë‹¤ì¤‘íšŒê·€)\n",
    "ë¬¸ì œ 1. (ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ ê°œìˆ˜) Priceë¥¼ ì¢…ì†ë³€ìˆ˜ë¡œ í•˜ê³ , ë‚˜ë¨¸ì§€ ëª¨ë“  ë³€ìˆ˜(Size, Rooms, Year, Distance, Lucky_Num)ë¥¼ ë…ë¦½ë³€ìˆ˜ë¡œ í•˜ëŠ” **ë‹¤ì¤‘ì„ í˜•íšŒê·€ ëª¨ë¸(OLS)**ì„ ì í•©í•˜ì‹œì˜¤. ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•Šì€(p-value > 0.05) ì„¤ëª…ë³€ìˆ˜ì˜ ê°œìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì ˆí¸í•­(Intercept)ì€ ê°œìˆ˜ì—ì„œ ì œì™¸í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ê°€ì¥ ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜) ìœ„ ëª¨ë¸ì—ì„œ p-valueê°€ ê°€ì¥ í°(ê°€ì¥ ìœ ì˜í•˜ì§€ ì•Šì€) ë³€ìˆ˜ì˜ ì´ë¦„ì„ ì ìœ¼ì‹œì˜¤.\n",
    "\n",
    "ë¬¸ì œ 3. (ìˆ˜ì •ëœ ê²°ì •ê³„ìˆ˜) ìœ„ ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ìˆ˜ì •ëœ ê²°ì •ê³„ìˆ˜(Adjusted R-squared) ê°’ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "55e77ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "        Size  Rooms  Year  Distance  Lucky_Num       Price\n",
      "0  29.076098      1  2014  3.753131          6  155.242173\n",
      "1  37.342856      3  1992  8.255590          2  187.675429\n",
      "2  15.611180      4  2017  3.419036          6  109.319247\n",
      "3  23.365780      1  2020  8.985747          2  132.536119\n",
      "4  28.992719      3  2015  3.060076          4  162.630936\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n = 300\n",
    "\n",
    "# ë…ë¦½ë³€ìˆ˜ ìƒì„±\n",
    "data = {\n",
    "    'Size': np.random.normal(30, 10, n),      # í‰ìˆ˜\n",
    "    'Rooms': np.random.randint(1, 6, n),      # ë°© ê°œìˆ˜\n",
    "    'Year': np.random.randint(1990, 2023, n), # ê±´ì¶• ì—°ë„\n",
    "    'Distance': np.random.normal(5, 2, n),    # ì—­ê¹Œì§€ ê±°ë¦¬ (ê°€ì§œ ë³€ìˆ˜)\n",
    "    'Lucky_Num': np.random.randint(1, 10, n)  # í–‰ìš´ì˜ ìˆ«ì (ê°€ì§œ ë³€ìˆ˜)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ì¢…ì†ë³€ìˆ˜(Price) ìƒì„±\n",
    "# ê°€ê²© = í‰ìˆ˜*5 + ë°©*2 + (ì—°ë„-1990)*0.5 + ì˜¤ì°¨\n",
    "# (Distanceì™€ Lucky_Numì€ ê°€ê²© ê²°ì • ì‹ì— í¬í•¨ë˜ì§€ ì•ŠìŒ -> ìœ ì˜í•˜ì§€ ì•Šì•„ì•¼ í•¨)\n",
    "df['Price'] = (5 * df['Size']) + (2 * df['Rooms']) + (0.5 * (df['Year'] - 1990))\n",
    "df['Price'] += np.random.normal(0, 5, n) # ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "891dd5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Distance\n",
      "0.9901308799657466\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1ë²ˆ\n",
    "from statsmodels.formula.api import ols\n",
    "model = ols('Price ~ Size + Rooms + Year + Distance + Lucky_Num', data=df).fit()\n",
    "p_val = model.pvalues[1:]\n",
    "#print(p_val)\n",
    "count = sum(p_val > 0.05)\n",
    "print(count)\n",
    "\n",
    "# ë¬¸ì œ 2ë²ˆ\n",
    "worst_val = p_val.idxmax()\n",
    "print(worst_val)\n",
    "\n",
    "# ë¬¸ì œ 3ë²ˆ\n",
    "adj = model.rsquared_adj\n",
    "print(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6049b37",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ3ìœ í˜•] F-ê²€ì • & í•©ë™ë¶„ì‚°ì¶”ì •ëŸ‰\n",
    "\n",
    "ë¬¸ì œ 1. (F-ê²€ì • í†µê³„ëŸ‰)ë‘ ê¸°ê³„(A, B)ì˜ ì œí’ˆ ë¬´ê²Œ(Weight) ë¶„ì‚°ì´ ê°™ì€ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ F-ê²€ì •ì„ ìˆ˜í–‰í•˜ë ¤ê³  í•©ë‹ˆë‹¤.**A ê¸°ê³„ì˜ ë¶„ì‚°($s_A^2$)**ê³¼ **B ê¸°ê³„ì˜ ë¶„ì‚°($s_B^2$)**ì„ ê°ê° êµ¬í•œ í›„, F-ê²€ì • í†µê³„ëŸ‰ì„ êµ¬í•˜ì‹œì˜¤.(ë‹¨, F-í†µê³„ëŸ‰ì€ í° ë¶„ì‚°ì„ ì‘ì€ ë¶„ì‚°ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ìœ¼ë¡œ ì •ì˜í•˜ë©°, ë¶„ì‚° ê³„ì‚° ì‹œ ddof=1(ë¶ˆí¸ë¶„ì‚°)ì„ ì‚¬ìš©í•˜ì‹œì˜¤. ê²°ê³¼ëŠ” ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (í•©ë™ë¶„ì‚°ì¶”ì •ëŸ‰)ìœ„ 1ë²ˆì˜ ê²°ê³¼ì™€ ê´€ê³„ì—†ì´, ë‘ ê¸°ê³„ì˜ ëª¨ë¶„ì‚°ì´ ê°™ë‹¤ê³  ê°€ì •(equal_var=True)í•©ë‹ˆë‹¤.ì´ë•Œ ë‘ ì§‘ë‹¨ì˜ ë¶„ì‚°ì„ í•˜ë‚˜ë¡œ í•©ì¹œ **í•©ë™ë¶„ì‚°ì¶”ì •ëŸ‰(Pooled Variance, $s_p^2$)**ì„ êµ¬í•˜ì‹œì˜¤.(ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (t-ê²€ì •)í•©ë™ë¶„ì‚°ì¶”ì •ëŸ‰ì„ ì‚¬ìš©í•˜ì—¬(ì¦‰, ë“±ë¶„ì‚°ì„ ê°€ì •í•˜ê³ ) ë‘ ê¸°ê³„ A, Bì˜ í‰ê·  ë¬´ê²Œì— ì°¨ì´ê°€ ìˆëŠ”ì§€ ë…ë¦½í‘œë³¸ t-ê²€ì •ì„ ìˆ˜í–‰í•˜ì‹œì˜¤.ì´ë•Œì˜ **p-ê°’(p-value)**ì„ êµ¬í•˜ì‹œì˜¤.(ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ë„·ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9174c0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "  Machine      Weight\n",
      "0       A  199.538049\n",
      "1       A  203.671428\n",
      "2       A  192.805590\n",
      "3       A  196.682890\n",
      "4       A  199.496360\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n = 30 # í‘œë³¸ í¬ê¸° 30ê°œ\n",
    "\n",
    "# ë°ì´í„° ìƒì„± (ë¶„ì‚°ì´ ë¹„ìŠ·í•˜ê²Œ ì„¤ì •ë¨)\n",
    "group_a = np.random.normal(200, 5, n)       # í‰ê·  200, í‘œì¤€í¸ì°¨ 5\n",
    "group_b = np.random.normal(202, 5.5, n)     # í‰ê·  202, í‘œì¤€í¸ì°¨ 5.5\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Machine': ['A']*n + ['B']*n,\n",
    "    'Weight': np.concatenate([group_a, group_b])\n",
    "})\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "#print(df.groupby('Machine')['Weight'].describe())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3c23aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.471\n",
      "24.078\n",
      "0.3538\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1ë²ˆ\n",
    "group_A = df[df['Machine']=='A']['Weight']\n",
    "group_B = df[df['Machine']=='B']['Weight']\n",
    "\n",
    "import numpy as np\n",
    "A_var = np.var(group_A, ddof = 1)\n",
    "B_var = np.var(group_B, ddof = 1)\n",
    "\n",
    "if A_var > B_var:\n",
    "    f_stat = A_var / B_var\n",
    "else:\n",
    "    f_stat = B_var / A_var\n",
    "\n",
    "print(round(f_stat, 3))\n",
    "\n",
    "# ë¬¸ì œ 2ë²ˆ\n",
    "A_n = len(group_A)\n",
    "B_n = len(group_B)\n",
    "\n",
    "pool_var = ((A_n - 1)*A_var + (B_n - 1)*B_var) / ((A_n - 1) + (B_n - 1))\n",
    "print(round(pool_var, 3))\n",
    "\n",
    "# ë¬¸ì œ 3ë²ˆ\n",
    "from scipy.stats import ttest_ind\n",
    "t_stat, p_val = ttest_ind(group_A, group_B, equal_var=True)\n",
    "print(round(p_val, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
