{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa1656e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "        Date         Price  Sales\n",
      "0 2023-01-01  12142.529844   18.0\n",
      "1 2023-01-02   6434.896126   71.0\n",
      "2 2023-01-03  14121.359907   46.0\n",
      "3 2023-01-04  33886.945659   60.0\n",
      "4 2023-01-05   5846.520075   53.0\n",
      "  Product  2023-Q1  2023-Q2  2023-Q3  2023-Q4\n",
      "0       A      100      110      105      120\n",
      "1       B      150      160      155      170\n",
      "2       C      200      210      205      220\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. ì‹œê³„ì—´/í†µê³„ ë°ì´í„° (df_time)\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2023-01-01', periods=100, freq='D')\n",
    "prices = np.random.lognormal(mean=2, sigma=1, size=100) * 1000 # ì™œë„ê°€ ìˆëŠ” ë°ì´í„° ìƒì„±\n",
    "sales = np.random.randint(10, 100, size=100).astype(float)\n",
    "\n",
    "df_time = pd.DataFrame({'Date': dates, 'Price': prices, 'Sales': sales})\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ê°•ì œ ìƒì„± (ë³´ê°„ë²• ì—°ìŠµìš©)\n",
    "df_time.loc[10:20, 'Sales'] = np.nan \n",
    "df_time.loc[50:55, 'Sales'] = np.nan\n",
    "\n",
    "# 2. ë„“ì€ í˜•íƒœ ë°ì´í„° (df_wide) - Melt ì—°ìŠµìš©\n",
    "data_wide = {\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    '2023-Q1': [100, 150, 200],\n",
    "    '2023-Q2': [110, 160, 210],\n",
    "    '2023-Q3': [105, 155, 205],\n",
    "    '2023-Q4': [120, 170, 220]\n",
    "}\n",
    "df = pd.DataFrame(data_wide)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df_time.head())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f81e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.07\n"
     ]
    }
   ],
   "source": [
    "skew_orig = df_time['Price'].skew()\n",
    "#print(skew_orig)\n",
    "\n",
    "df_time['Price_Log'] = np.log1p(df_time['Price'])\n",
    "skew_log = df_time['Price_Log'].skew()\n",
    "result1 = abs(skew_orig - skew_log)\n",
    "print(round(result1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed4de67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "        Date         Price  Sales  Price_Log  Sales_fill  Prev_Sales\n",
      "0 2023-01-01  12142.529844   18.0   9.404552        18.0         NaN\n",
      "1 2023-01-02   6434.896126   71.0   8.769646        71.0        18.0\n",
      "2 2023-01-03  14121.359907   46.0   9.555515        46.0        71.0\n",
      "3 2023-01-04  33886.945659   60.0  10.430815        60.0        46.0\n",
      "4 2023-01-05   5846.520075   53.0   8.673773        53.0        60.0\n"
     ]
    }
   ],
   "source": [
    "df_time['Sales_fill'] = df_time['Sales'].interpolate(method='linear')\n",
    "df_time['Prev_Sales'] = df_time['Sales_fill'].shift(1)\n",
    "result2 = df_time['Sales_fill'].corr(df_time['Prev_Sales'])\n",
    "print(round(result2, 2))\n",
    "print(df_time.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77e17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n"
     ]
    }
   ],
   "source": [
    "#print(df.head())\n",
    "df_melt = pd.melt(df, id_vars=['Product'], var_name='Quarter', value_name='Revenue')\n",
    "#print(df_melt)\n",
    "\n",
    "result3 = df_melt[df_melt['Quarter']=='2023-Q4']['Revenue'].sum()\n",
    "print(round(result3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa070290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "min_val = df_time['Price'].min()\n",
    "max_val = df_time['Price'].max()\n",
    "df_time['Price_Scaled'] = (df_time['Price'] - min_val) / (max_val - min_val)\n",
    "result4 = sum(df_time['Price_Scaled'] > 0.5)\n",
    "print(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53649f5f",
   "metadata": {},
   "source": [
    "ğŸ“ ì‹¤ì „ ì—°ìŠµ ë¬¸ì œ\n",
    "ë¬¸ì œ 1. (ì¡°ê±´ í•„í„°ë§ & ì¤‘ì•™ê°’ ëŒ€ì¹˜) Price ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜(NaN)ë¥¼ **Cityë³„ Priceì˜ ì¤‘ì•™ê°’(median)**ìœ¼ë¡œ ì±„ìš°ì‹œì˜¤. ê·¸ í›„, Paymentê°€ 'Card'ì¸ ë°ì´í„°ë“¤ì˜ Price í‰ê· ê°’ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ì‹œê³„ì—´ & Groupby) Date ì»¬ëŸ¼ì—ì„œ 'ìš”ì¼'(Monday=0, ... Sunday=6) ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ Weekday ì»¬ëŸ¼ì„ ë§Œë“œì‹œì˜¤. **'ì£¼ë§' (í† ìš”ì¼, ì¼ìš”ì¼)**ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§í•œ í›„, ì´ ë°ì´í„°ë“¤ì˜ Cityë³„ Price **í•©ê³„(sum)**ë¥¼ êµ¬í–ˆì„ ë•Œ ê°€ì¥ í° ê°’ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ë°ì´í„° êµ¬ê°„í™” & ë¹ˆë„ìˆ˜) Price ì»¬ëŸ¼ ê°’(ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œëœ ìƒíƒœ ê°€ì •)ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ 3ê°œì˜ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
    "\n",
    "0 ì´ìƒ 4000 ë¯¸ë§Œ: 'Low'\n",
    "\n",
    "4000 ì´ìƒ 7000 ë¯¸ë§Œ: 'Mid'\n",
    "\n",
    "7000 ì´ìƒ: 'High'\n",
    "\n",
    "'Mid' ê·¸ë£¹ì— ì†í•˜ë©´ì„œ Productê°€ 'A'ì¸ ë°ì´í„°ì˜ **ê°œìˆ˜(í–‰ì˜ ìˆ˜)**ë¥¼ êµ¬í•˜ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8437069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Date     City Product   Price Payment\n",
      "0 2023-01-01 00:00:00    Seoul       A  2725.0    Cash\n",
      "1 2023-01-01 01:00:00    Daegu       B  9929.0    Card\n",
      "2 2023-01-01 02:00:00    Seoul       C  3118.0    Card\n",
      "3 2023-01-01 03:00:00    Seoul       C  2901.0    Card\n",
      "4 2023-01-01 04:00:00  Incheon       A  2739.0    Cash\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2024)\n",
    "\n",
    "# ë°ì´í„° ìƒì„±\n",
    "dates = pd.date_range('2023-01-01', periods=500, freq='h')\n",
    "cities = np.random.choice(['Seoul', 'Busan', 'Daegu', 'Incheon'], 500)\n",
    "products = np.random.choice(['A', 'B', 'C'], 500)\n",
    "prices = np.random.randint(1000, 10000, 500)\n",
    "payments = np.random.choice(['Card', 'Cash', 'Pay'], 500)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'City': cities,\n",
    "    'Product': products,\n",
    "    'Price': prices,\n",
    "    'Payment': payments\n",
    "})\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì„ì˜ ìƒì„± (Price ì»¬ëŸ¼)\n",
    "df.loc[10:20, 'Price'] = np.nan\n",
    "\n",
    "# ë°ì´í„° í™•ì¸\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106e157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5426.29\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1\n",
    "fill_nan = df.groupby('City')['Price'].transform('median')\n",
    "\n",
    "df['Price'] = df['Price'].fillna(fill_nan)\n",
    "#print(df.info())\n",
    "result = df[df['Payment']=='Card']['Price'].mean()\n",
    "print(round(result, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0c4c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City\n",
      "Incheon    815941.0\n",
      "Busan      647059.5\n",
      "Daegu      641636.0\n",
      "Seoul      599213.0\n",
      "Name: Price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2\n",
    "df['Weekday'] = df['Date'].dt.weekday\n",
    "q1 = df['Weekday'].isin([5, 6])\n",
    "result = df.groupby('City')['Price'].sum().sort_values(ascending=False)\n",
    "print(result)\n",
    "# loc, iloc, isin ì“°ëŠ”ë²•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e06b990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "def get_category(price):\n",
    "    if price < 4000: return 'Low'\n",
    "    elif price < 7000: return 'Mid'\n",
    "    else: return 'High'\n",
    "\n",
    "df['Category'] = df['Price'].apply(get_category)\n",
    "result = len(df[(df['Category']=='Mid') & (df['Product']=='A')])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116db132",
   "metadata": {},
   "source": [
    "ğŸ“ ì‹¤ì „ ì—°ìŠµ ë¬¸ì œ (Large Data)\n",
    "ë¬¸ì œ 1. (ì‹œê³„ì—´ ë¶„í•´ & ì§‘ê³„) Date ì»¬ëŸ¼ì„ ì´ìš©í•˜ì—¬ **2023ë…„ì˜ 'ì›”ë³„(Month)' ì´ ë²”ì£„ ê±´ìˆ˜(Violent + Theft + Traffic)**ë¥¼ ì§‘ê³„í•˜ì‹œì˜¤. ê·¸ì¤‘ ì´ ë²”ì£„ ê±´ìˆ˜ê°€ **ê°€ì¥ ë§ì•˜ë˜ ì›”(Month)**ì˜ ë²”ì£„ ê±´ìˆ˜ í•©ê³„ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ë³µí•© ì—°ì‚° & Groupby ì£¼ì˜ì ) ì „ì²´ ê¸°ê°„ ë™ì•ˆ ê° êµ¬(District)ë³„ë¡œ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. **'Zone_A'**ì˜ ì—°ê°„ 10ë§Œ ëª…ë‹¹ í‰ê·  ê°•ë ¥ ë²”ì£„(Violent) ë°œìƒ ê±´ìˆ˜ë¥¼ êµ¬í•˜ì‹œì˜¤.\n",
    "\n",
    "ê³„ì‚° ë¡œì§: (Zone_Aì˜ ì „ì²´ Violent í•©ê³„ / ë°ì´í„° ìˆ˜ì§‘ ë…„ìˆ˜) / Zone_Aì˜ ì¸êµ¬ìˆ˜ * 100,000\n",
    "\n",
    "ë°ì´í„° ìˆ˜ì§‘ ë…„ìˆ˜(Years)ëŠ” 5ë…„(2020~2024)ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ê°’ì€ ì†Œìˆ˜ì  ì´í•˜ëŠ” ë²„ë¦¬ê³  **ì •ìˆ˜(int)**ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.\n",
    "\n",
    "ë¬¸ì œ 3. (ì´ìƒì¹˜ íƒìƒ‰ & ì¡°ê±´ë¶€ í‰ê· ) ì „ì²´ ë°ì´í„° ì¤‘ Traffic ë²”ì£„ ê±´ìˆ˜ê°€ ìƒìœ„ 1%(quantile(0.99)) ì´ìƒì¸ ë‚ ë“¤ì„ **'Traffic_High'**ë¡œ ì •ì˜í•©ë‹ˆë‹¤. ì´ 'Traffic_High' ê·¸ë£¹ì— ì†í•˜ëŠ” ë°ì´í„°ë“¤ì˜ Violent ë²”ì£„ ë°œìƒ ê±´ìˆ˜ì˜ í‰ê· ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ì…‹ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4ed9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ! í¬ê¸°: (50000, 6)\n",
      "        Date District  Violent  Theft  Traffic  Population\n",
      "0 2020-01-01   Zone_N        6     21       21      662347\n",
      "1 2020-01-01   Zone_A       10      3       44      732104\n",
      "2 2020-01-01   Zone_N        4      8       38      662347\n",
      "3 2020-01-01   Zone_E       12      0       47      654593\n",
      "4 2020-01-01   Zone_K       13      5       35      474799\n",
      "5 2020-01-01   Zone_H        9      5       37      721696\n",
      "6 2020-01-01   Zone_D        0      7       20      661246\n",
      "7 2020-01-01   Zone_G       14      5       41      486794\n",
      "8 2020-01-01   Zone_O       11     28       41      466331\n",
      "9 2020-01-01   Zone_S        1     10        9      253094\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ëœë¤ ì‹œë“œ ê³ ì • (ì •ë‹µ í†µì¼ì„ ìœ„í•´)\n",
    "np.random.seed(2024)\n",
    "\n",
    "# 1. ê¸°ë³¸ ì„¤ì •\n",
    "n_rows = 50000\n",
    "districts = [f'Zone_{chr(i)}' for i in range(65, 85)] # Zone_A ~ Zone_T (20ê°œ)\n",
    "\n",
    "# 2. êµ¬ë³„ ì¸êµ¬ìˆ˜ ë§¤í•‘ (Zone_AëŠ” 30ë§Œ, Zone_BëŠ” 35ë§Œ... ëœë¤ ë°°ì •)\n",
    "pop_map = {d: np.random.randint(200000, 800000) for d in districts}\n",
    "\n",
    "# 3. ë°ì´í„° ìƒì„±\n",
    "df = pd.DataFrame({\n",
    "    'Date': np.random.choice(pd.date_range('2020-01-01', '2024-12-31'), n_rows),\n",
    "    'District': np.random.choice(districts, n_rows),\n",
    "    'Violent': np.random.randint(0, 15, n_rows),  # ì¼ì¼ ë°œìƒ ê±´ìˆ˜ë¼ ì ê²Œ ì„¤ì •\n",
    "    'Theft': np.random.randint(0, 30, n_rows),\n",
    "    'Traffic': np.random.randint(0, 50, n_rows)\n",
    "})\n",
    "\n",
    "# 4. ì¸êµ¬ìˆ˜ ë§¤í•‘ ë° ì •ë ¬\n",
    "df['Population'] = df['District'].map(pop_map)\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "print(f\"ë°ì´í„° ìƒì„± ì™„ë£Œ! í¬ê¸°: {df.shape}\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf932e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41536\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "\n",
    "df['Total'] = df['Violent'] + df['Theft'] + df['Traffic']\n",
    "q1 = df[df['year']==2023]\n",
    "result = q1.groupby('month')['Total'].sum().sort_values(ascending=False)\n",
    "print(result.iloc[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba7f3002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2\n",
    "q2 = df[df['District']=='Zone_A']\n",
    "year_ratio = (q2['Violent'].sum() / 5) / q2['Population'].iloc[0] * 100000\n",
    "print(int(year_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ef011f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.94\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3\n",
    "var = df['Traffic'].quantile(0.99)\n",
    "def cond(traffic):\n",
    "    if traffic >= var: return 'Traffic_High'\n",
    "    else: return 'NoNan'\n",
    "\n",
    "df['Traffic_check'] = df['Traffic'].apply(cond)\n",
    "\n",
    "result = df[df['Traffic_check']=='Traffic_High']['Violent'].mean()\n",
    "print(round(result, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a71b8eb",
   "metadata": {},
   "source": [
    "ğŸ“ ì‹¤ì „ ì—°ìŠµ ë¬¸ì œ (ì•½ì  ë³´ì™„ & ë¬¸ìì—´)\n",
    "ë¬¸ì œ 1. (ë¬¸ìì—´ ì¶”ì¶œ & ë¹ˆë„ ë¶„ì„) Product ì»¬ëŸ¼ì—ëŠ” ëŒ€ê´„í˜¸ [ ... ] ì•ˆì— ì œí’ˆì˜ ì˜µì…˜ ì •ë³´ê°€ ë“¤ì–´ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: [Black]) ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì´ ì˜µì…˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ(ê´„í˜¸ ì œì™¸)í•˜ì—¬ Optionì´ë¼ëŠ” ìƒˆ ì»¬ëŸ¼ì„ ë§Œë“œì„¸ìš”. ê°€ì¥ ë§ì´ íŒë§¤ëœ(í–‰ ê°œìˆ˜ ê¸°ì¤€) Optionì˜ ì´ë¦„ì„ ì¶œë ¥í•˜ì‹œì˜¤.\n",
    "\n",
    "ë¬¸ì œ 2. (ê·¸ë£¹ë³„ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ & í‰ê·  ê³„ì‚°) Price ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ë¥¼ **Categoryë³„ Priceì˜ í‰ê· ê°’(mean)**ìœ¼ë¡œ ì±„ìš°ì„¸ìš”. (ì£¼ì˜: ì „ì²´ í‰ê· ì´ ì•„ë‹ˆë¼, ElectronicsëŠ” Electronicsë¼ë¦¬, AccessoriesëŠ” Accessoriesë¼ë¦¬ í‰ê· ì„ êµ¬í•´ì„œ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤.) ê²°ì¸¡ì¹˜ ì²˜ë¦¬ê°€ ì™„ë£Œëœ í›„, Priceì˜ **í‘œì¤€í¸ì°¨(std)**ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ì´í•˜ëŠ” ë²„ë¦¬ê³  **ì •ìˆ˜(int)**ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ì‹œê³„ì—´ ì§‘ê³„ & ì´ìƒì¹˜ ë²”ìœ„ - ì§€ë‚œë²ˆ ì‹¤ìˆ˜ ë³µìŠµ) ì¼ë³„ ë§¤ì¶œì•¡(Daily_Sales)ì„ ê³„ì‚°í•˜ë ¤ê³  í•©ë‹ˆë‹¤. (ë§¤ì¶œì•¡ = Price * Quantity, ê²°ì¸¡ì¹˜ ì²˜ë¦¬ëœ Price ì‚¬ìš©) ë‚ ì§œ(Date)ë³„ë¡œ ì´ ë§¤ì¶œì•¡ì„ ì§‘ê³„í•œ ë’¤, ì´ ë§¤ì¶œì•¡ì´ **ìƒìœ„ 10% ì´ìƒ(>= 0.9 quantile)**ì¸ ë‚ ì§œë“¤ì„ **'High_Sales_Day'**ë¡œ ì •ì˜í•©ë‹ˆë‹¤. ì´ 'High_Sales_Day'ì— í•´ë‹¹í•˜ëŠ” ë‚ ë“¤ì˜ ì¼í‰ê·  ë§¤ì¶œì•¡ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ì´í•˜ëŠ” ë²„ë¦¬ê³  **ì •ìˆ˜(int)**ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cefe8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ! (í–‰: 5000)\n",
      "        Date             Product     Category      Price  Quantity\n",
      "0 2023-08-11  Monitor [Wireless]  Electronics  1030000.0         2\n",
      "1 2023-12-26       Laptop [16GB]  Electronics        NaN         1\n",
      "2 2023-10-19    Mouse [Wireless]  Accessories   410000.0         4\n",
      "3 2023-07-24      Laptop [Black]  Electronics   930000.0         1\n",
      "4 2023-03-09     Monitor [White]  Electronics  1437000.0         4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 5000\n",
    "\n",
    "# 1. ìƒí’ˆëª… ìƒì„± (ëŒ€ê´„í˜¸ ì•ˆì— ì˜µì…˜ í¬í•¨)\n",
    "products_base = ['Laptop', 'Phone', 'Monitor', 'Mouse', 'Keyboard']\n",
    "options = ['[Black]', '[White]', '[Silver]', '[16GB]', '[Wireless]']\n",
    "categories = ['Electronics', 'Electronics', 'Electronics', 'Accessories', 'Accessories']\n",
    "\n",
    "prod_list = []\n",
    "cat_list = []\n",
    "for _ in range(n_rows):\n",
    "    idx = np.random.randint(0, 5)\n",
    "    opt_idx = np.random.randint(0, 5)\n",
    "    # ìƒí’ˆëª… ì˜ˆ: \"Laptop [Black]\"\n",
    "    prod_name = f\"{products_base[idx]} {options[opt_idx]}\"\n",
    "    prod_list.append(prod_name)\n",
    "    cat_list.append(categories[idx])\n",
    "\n",
    "# 2. ë°ì´í„° ìƒì„±\n",
    "df = pd.DataFrame({\n",
    "    'Date': np.random.choice(pd.date_range('2023-01-01', '2023-12-31'), n_rows),\n",
    "    'Product': prod_list,\n",
    "    'Category': cat_list,\n",
    "    'Price': np.random.randint(50, 2000, n_rows) * 1000, # 50,000 ~ 2,000,000\n",
    "    'Quantity': np.random.randint(1, 5, n_rows)\n",
    "})\n",
    "\n",
    "# 3. ê²°ì¸¡ì¹˜ ìƒì„± (Price)\n",
    "df.loc[np.random.choice(df.index, 500), 'Price'] = np.nan\n",
    "\n",
    "print(f\"ë°ì´í„° ìƒì„± ì™„ë£Œ! (í–‰: {df.shape[0]})\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca8321de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1\n",
    "df['Option'] = df['Product'].str.extract(r'\\[(.*?)\\]')\n",
    "result = df['Option'].value_counts().sort_values(ascending=False)\n",
    "print(result.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62786703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533145\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2\n",
    "fill_val = df.groupby('Category')['Price'].transform('mean')\n",
    "\n",
    "df['Price'] = df['Price'].fillna(fill_val)\n",
    "result = df['Price'].std()\n",
    "print(int(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3fe2a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55587015\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3\n",
    "df['Revenue'] = df['Price'] * df['Quantity']\n",
    "daily_sales = df.groupby('Date')['Revenue'].sum()\n",
    "#print(daily_sales)\n",
    "\n",
    "var = daily_sales.quantile(0.9)\n",
    "high_sales_days = daily_sales[daily_sales >= var]\n",
    "result = high_sales_days.mean()\n",
    "print(int(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c318badb",
   "metadata": {},
   "source": [
    "ğŸ“ ì‹¤ì „ ì—°ìŠµ ë¬¸ì œ (ë°ì´í„°ì…‹: Ecommerce_Sales)\n",
    "ë¬¸ì œ 1. (ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€ ê²€ìƒ‰) Product ì´ë¦„ì— **'Wireless'**ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ìƒí’ˆë“¤ë§Œ ë³„ë„ë¡œ ë¶„ì„í•˜ë ¤ê³  í•©ë‹ˆë‹¤. 'Wireless'ê°€ í¬í•¨ëœ ìƒí’ˆë“¤ì˜ **Price ì¤‘ì•™ê°’(median)**ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, Price ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ëŠ” ì œê±°(dropna)í•œ í›„ ê³„ì‚°í•˜ê³ , ê²°ê³¼ëŠ” **ì •ìˆ˜(int)**ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ì‹œê³„ì—´ ì§‘ê³„ & ì •ë ¬) Date ì»¬ëŸ¼ì—ì„œ 'ì›”(Month)' ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. 'Electronics' ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§í•œ í›„, **ì›”ë³„ ì´ ë§¤ì¶œì•¡(Price * Quantity)**ì„ ì§‘ê³„í–ˆì„ ë•Œ, ë§¤ì¶œì•¡ì´ ê°€ì¥ ë†’ì€ **ì›”(Month)**ì€ ëª‡ ì›”ì…ë‹ˆê¹Œ? (ë‹¨, ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ì€ ë§¤ì¶œì•¡ ê³„ì‚° ì „ ì œê±°í•˜ê³ , ì •ìˆ˜ë¡œ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ìˆœìœ„ êµ¬í•˜ê¸° & ì¸ë±ì‹±) ì „ì²´ ë°ì´í„°(ê²°ì¸¡ì¹˜ ì œê±° í›„)ë¥¼ Price(ê°€ê²©)ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•©ë‹ˆë‹¤. ì´ë•Œ, ê°€ê²©ì´ 5ë²ˆì§¸ë¡œ ë†’ì€ ì£¼ë¬¸ì˜ **Order_ID**ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ? (ì£¼ì˜: 0ë¶€í„° ì‹œì‘í•˜ëŠ” ì¸ë±ìŠ¤ ê¸°ì¤€ì´ ì•„ë‹ˆë¼, ì‹¤ì œ ìˆœìœ„ ê¸°ì¤€ 5ë“±ì…ë‹ˆë‹¤. ë™ì ìëŠ” ë¬´ì‹œí•˜ê³  í–‰ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0050a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date             Product     Category         Price  Quantity  \\\n",
      "0 2023-08-11  Monitor [Wireless]  Electronics  1.030000e+06         2   \n",
      "1 2023-12-26       Laptop [16GB]  Electronics  1.022305e+06         1   \n",
      "2 2023-10-19    Mouse [Wireless]  Accessories  4.100000e+05         4   \n",
      "3 2023-07-24      Laptop [Black]  Electronics  9.300000e+05         1   \n",
      "4 2023-03-09     Monitor [White]  Electronics  1.437000e+06         4   \n",
      "\n",
      "     Option       Revenue  \n",
      "0  Wireless  2.060000e+06  \n",
      "1      16GB  1.022305e+06  \n",
      "2  Wireless  1.640000e+06  \n",
      "3     Black  9.300000e+05  \n",
      "4     White  5.748000e+06  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c49c47b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022305\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1\n",
    "q1 = df.dropna(subset=['Price'])\n",
    "result = q1[q1['Product'].str.contains('Wireless')]['Price'].median()\n",
    "print(int(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "087ea252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sangh\\AppData\\Local\\Temp\\ipykernel_4896\\3975182502.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q1['Revenue'] = q1['Price'] * q1['Quantity']\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "q1 = df[df['Category']=='Electronics']\n",
    "q1['Revenue'] = q1['Price'] * q1['Quantity']\n",
    "result = q1.groupby('Month')['Revenue'].sum().sort_values(ascending=False)\n",
    "print(result.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19a63283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        2023-11-20 00:00:00\n",
      "Product      Monitor [Wireless]\n",
      "Category            Electronics\n",
      "Price                 1998000.0\n",
      "Quantity                      3\n",
      "Option                 Wireless\n",
      "Revenue               5994000.0\n",
      "Month                        11\n",
      "Name: 2770, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3\n",
    "df = df.dropna(subset=['Price'])\n",
    "df = df.sort_values(by='Price', ascending=False)\n",
    "print(df.iloc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287f64d",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ2ìœ í˜•] ì€í–‰ ê³ ê° ì´íƒˆ ì˜ˆì¸¡\n",
    "ë¬¸ì œ: ì€í–‰ ê³ ê° ë°ì´í„°(train)ë¥¼ ì´ìš©í•˜ì—¬ ê³ ê°ì˜ ì´íƒˆ ì—¬ë¶€(Exited)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³ , ì œê³µëœ í‰ê°€ìš© ë°ì´í„°(test)ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ csv íŒŒì¼ë¡œ ì œì¶œí•˜ì‹œì˜¤.\n",
    "\n",
    "1. ë°ì´í„° ì„¤ëª…\n",
    "\n",
    "Target: Exited (1: ì´íƒˆ, 0: ìœ ì§€)\n",
    "\n",
    "Features:\n",
    "\n",
    "CustomerId: ê³ ê° ID (ì‹ë³„ì)\n",
    "\n",
    "Surname: ì„± (String)\n",
    "\n",
    "CreditScore: ì‹ ìš© ì ìˆ˜\n",
    "\n",
    "Geography: êµ­ê°€ (France, Germany, Spain)\n",
    "\n",
    "Gender: ì„±ë³„\n",
    "\n",
    "Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary\n",
    "\n",
    "2. ì œì¶œ í˜•ì‹\n",
    "\n",
    "result.csv íŒŒì¼ë¡œ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë°˜ë“œì‹œ **CustomerId**ì™€ Exited ë‘ ê°œì˜ ì»¬ëŸ¼ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "Exited ì»¬ëŸ¼ì—ëŠ” **ì´íƒˆí•  í™•ë¥ (Probability)**ì„ ì œì¶œí•˜ì‹œì˜¤. (0ê³¼ 1 ì‚¬ì´ì˜ ì†Œìˆ˜)\n",
    "\n",
    "3. í‰ê°€ ì§€í‘œ\n",
    "\n",
    "ROC-AUC (ê°’ì´ í´ìˆ˜ë¡ ì¢‹ìŒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2a02fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "train shape: (2100, 13)\n",
      "test shape: (900, 12)\n",
      "   CustomerId   Surname  CreditScore Geography  Gender   Age  Tenure  \\\n",
      "0       10001  Williams          423    France    Male  43.0       5   \n",
      "1       10002     Jones          532   Germany  Female  54.0       9   \n",
      "2       10003     Smith          470     Spain    Male  75.0       8   \n",
      "3       10004     Brown          627   Germany  Female  81.0       0   \n",
      "4       10005     Brown          520     Spain    Male  67.0       5   \n",
      "\n",
      "         Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
      "0  156207.782854              3          0               0     61837.658280   \n",
      "1  149914.101471              2          1               1     54490.748664   \n",
      "2  132768.028528              3          0               1    126846.371424   \n",
      "3   44238.586796              1          0               0    172944.034041   \n",
      "4  105158.756047              2          1               1     58251.970535   \n",
      "\n",
      "   Exited  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 3000\n",
    "\n",
    "# 1. ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'CustomerId': np.arange(10001, 10001 + n_rows),\n",
    "    'Surname': np.random.choice(['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], n_rows),\n",
    "    'CreditScore': np.random.randint(350, 850, n_rows),\n",
    "    'Geography': np.random.choice(['France', 'Germany', 'Spain'], n_rows),\n",
    "    'Gender': np.random.choice(['Male', 'Female'], n_rows),\n",
    "    'Age': np.random.randint(18, 92, n_rows),\n",
    "    'Tenure': np.random.randint(0, 10, n_rows),\n",
    "    'Balance': np.random.uniform(0, 250000, n_rows),\n",
    "    'NumOfProducts': np.random.randint(1, 4, n_rows),\n",
    "    'HasCrCard': np.random.randint(0, 2, n_rows),\n",
    "    'IsActiveMember': np.random.randint(0, 2, n_rows),\n",
    "    'EstimatedSalary': np.random.uniform(11, 200000, n_rows),\n",
    "    'Exited': np.random.randint(0, 2, n_rows) # Target\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ ê°•ì œ ì£¼ì… (ì „ì²˜ë¦¬ ì—°ìŠµìš©)\n",
    "# Age ê²°ì¸¡ì¹˜\n",
    "df.loc[np.random.choice(df.index, 50), 'Age'] = np.nan\n",
    "# Balance ê²°ì¸¡ì¹˜\n",
    "df.loc[np.random.choice(df.index, 30), 'Balance'] = np.nan\n",
    "\n",
    "# 3. Train / Test ë¶„ë¦¬ (ì‹œí—˜ í™˜ê²½ í‰ë‚´)\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']\n",
    "\n",
    "# ì‹¤ì œ ì‹œí—˜ì—ì„œëŠ” X_testì— ì •ë‹µ(y)ì´ ì—†ìŠµë‹ˆë‹¤.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ í•©ì¹˜ê¸° (ì‹œí—˜ì—ì„œ ì œê³µë˜ëŠ” í˜•íƒœ)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = X_test # y_testëŠ” ìˆ¨ê²¨ì ¸ ìˆìŒ (ì±„ì ìš©)\n",
    "\n",
    "# CSV íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆë‹¤ê³  ê°€ì •í•˜ê³  ë³€ìˆ˜ëª…ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "print(f\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"test shape: {test.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdd15584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532\n",
      "      Id  pred\n",
      "0  11802     1\n",
      "1  11191     1\n",
      "2  11818     1\n",
      "3  10252     1\n",
      "4  12506     1\n"
     ]
    }
   ],
   "source": [
    "#print(train.info())\n",
    "# ê²°ì¸¡ì¹˜: Age, Balance\n",
    "# object: Geography, Gender\n",
    "\n",
    "#print(test.info())\n",
    "# ê²°ì¸¡ì¹˜: Age, Balance\n",
    "\n",
    "train['Age'] = train['Age'].fillna(train['Age'].mean())\n",
    "test['Age'] = test['Age'].fillna(train['Age'].mean())\n",
    "\n",
    "train['Balance'] = train['Balance'].fillna(train['Balance'].mean())\n",
    "test['Balance'] = test['Balance'].fillna(train['Balance'].mean())\n",
    "\n",
    "#print(test.info())\n",
    "\n",
    "X = train.drop(['CustomerId', 'Surname', 'Exited'], axis=1)\n",
    "y = train['Exited']\n",
    "X_submit = test.drop(['CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "cols = ['Geography', 'Gender']\n",
    "\n",
    "X = pd.get_dummies(X, columns=cols)\n",
    "X_submit = pd.get_dummies(X_submit, columns=cols)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc = roc_auc_score(y_val, pred_proba)\n",
    "print(round(roc, 3))\n",
    "\n",
    "model.fit(X, y)\n",
    "final_pred = model.predict(X_submit)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'Id': test['CustomerId'],\n",
    "    'pred': final_pred\n",
    "})\n",
    "result.to_csv('result.csv', index=False)\n",
    "print(pd.read_csv('result.csv').head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b8524",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ2ìœ í˜•] ìì „ê±° ëŒ€ì—¬ëŸ‰ ì˜ˆì¸¡ (íšŒê·€)\n",
    "ë¬¸ì œ: ì œê³µëœ ìì „ê±° ëŒ€ì—¬ ë°ì´í„°(train)ë¥¼ ì´ìš©í•˜ì—¬ ëŒ€ì—¬ íšŸìˆ˜(count)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³ , í‰ê°€ìš© ë°ì´í„°(test)ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ csv íŒŒì¼ë¡œ ì œì¶œí•˜ì‹œì˜¤.\n",
    "\n",
    "1. ë°ì´í„° ì„¤ëª…\n",
    "\n",
    "Target: count (ëŒ€ì—¬ íšŸìˆ˜, ìˆ˜ì¹˜í˜•)\n",
    "\n",
    "Features:\n",
    "\n",
    "ID: ê³ ìœ  ì‹ë³„ì\n",
    "\n",
    "Date: ë‚ ì§œ (datetime)\n",
    "\n",
    "Temperature, Humidity, Windspeed, Visibility: ë‚ ì”¨ ì •ë³´\n",
    "\n",
    "Holiday: ê³µíœ´ì¼ ì—¬ë¶€ (Yes/No)\n",
    "\n",
    "Hour: ì‹œê°„ (0~23)\n",
    "\n",
    "2. ì œì¶œ í˜•ì‹\n",
    "\n",
    "result.csv íŒŒì¼ë¡œ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ID**ì™€ pred ë‘ ê°œì˜ ì»¬ëŸ¼ë§Œ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "pred ì»¬ëŸ¼ì—ëŠ” ì˜ˆì¸¡í•œ ëŒ€ì—¬ íšŸìˆ˜(ì‹¤ìˆ˜ ë˜ëŠ” ì •ìˆ˜)ë¥¼ ì…ë ¥í•˜ì‹œì˜¤.\n",
    "\n",
    "3. í‰ê°€ ì§€í‘œ\n",
    "\n",
    "MAE (Mean Absolute Error)\n",
    "\n",
    "(ê°’ì´ ì‘ì„ìˆ˜ë¡ ì¢‹ì€ ì„±ëŠ¥ì…ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bcb496c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "train shape: (1400, 9)\n",
      "test shape: (600, 8)\n",
      "        ID                Date  Temperature  Humidity  Windspeed  Visibility  \\\n",
      "836   1836 2023-02-04 20:00:00    27.741598        39   4.947782         836   \n",
      "575   1575 2023-01-24 23:00:00    20.760819        80        NaN        1787   \n",
      "557   1557 2023-01-24 05:00:00    15.534825        61   2.401177        1261   \n",
      "1235  2235 2023-02-21 11:00:00    26.003205        64   7.495187         971   \n",
      "1360  2360 2023-02-26 16:00:00    18.989828        52   0.973485         958   \n",
      "\n",
      "     Holiday  Hour  count  \n",
      "836       No    14    205  \n",
      "575       No     5    153  \n",
      "557       No    10    204  \n",
      "1235      No     7    152  \n",
      "1360      No     8    138  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 2000\n",
    "\n",
    "# 1. ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'ID': np.arange(1000, 1000 + n_rows),\n",
    "    'Date': pd.date_range('2023-01-01', periods=n_rows, freq='h'),\n",
    "    'Temperature': np.random.normal(20, 5, n_rows), # ê¸°ì˜¨\n",
    "    'Humidity': np.random.randint(30, 90, n_rows),  # ìŠµë„\n",
    "    'Windspeed': np.random.uniform(0, 10, n_rows),  # í’ì†\n",
    "    'Visibility': np.random.randint(500, 2000, n_rows), # ê°€ì‹œê±°ë¦¬\n",
    "    'Holiday': np.random.choice(['No', 'Yes'], n_rows, p=[0.95, 0.05]), # ê³µíœ´ì¼\n",
    "    'Hour': np.random.randint(0, 24, n_rows), # ì‹œê°„\n",
    "    'count': 0 # Target ì´ˆê¸°í™”\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Target ìƒì„± (ëŒ€ì—¬ëŸ‰ì€ ê¸°ì˜¨ì´ ë†’ê³ , í‡´ê·¼ì‹œê°„ì— ë§ë‹¤ëŠ” ê°€ì •)\n",
    "df['count'] = 100 + (df['Temperature'] * 3) + (df['Hour'] * 5) - (df['Humidity'] * 0.5)\n",
    "df['count'] = df['count'] + np.random.normal(0, 20, n_rows) # ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "df['count'] = df['count'].apply(lambda x: max(0, int(x))) # ìŒìˆ˜ ë°©ì§€ ë° ì •ìˆ˜í™”\n",
    "\n",
    "# 2. ê²°ì¸¡ì¹˜ ì£¼ì… (ì „ì²˜ë¦¬ ì—°ìŠµìš©)\n",
    "df.loc[np.random.choice(df.index, 50), 'Windspeed'] = np.nan\n",
    "\n",
    "# 3. Train / Test ë¶„ë¦¬\n",
    "X = df.drop('count', axis=1)\n",
    "y = df['count']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = X_test\n",
    "\n",
    "print(f\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"test shape: {test.shape}\")\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13724801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.27\n",
      "     ID    pred\n",
      "0  2860  127.66\n",
      "1  1353  118.44\n",
      "2  2333  182.31\n",
      "3  1905  221.30\n",
      "4  2289  205.26\n"
     ]
    }
   ],
   "source": [
    "#print(test.info())\n",
    "# ê²°ì¸¡ì¹˜: windspeed\n",
    "# ì¸ì½”ë”©: Holiday\n",
    "# ì‚­ì œ: ID, Date\n",
    "\n",
    "train['Windspeed'] = train['Windspeed'].fillna(train['Windspeed'].mean())\n",
    "test['Windspeed'] = test['Windspeed'].fillna(train['Windspeed'].mean())\n",
    "\n",
    "X = train.drop(['ID', 'Date', 'count'], axis=1)\n",
    "y = train['count']\n",
    "X_submit = test.drop(['ID', 'Date'], axis=1)\n",
    "\n",
    "X = pd.get_dummies(X, columns=['Holiday'])\n",
    "X_submit = pd.get_dummies(X_submit, columns=['Holiday'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pred_val = mean_absolute_error(y_val, pred)\n",
    "print(round(pred_val, 3))\n",
    "\n",
    "model.fit(X, y)\n",
    "final_pred = model.predict(X_submit)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'pred': final_pred\n",
    "})\n",
    "result.to_csv('result1.csv', index=False)\n",
    "print(pd.read_csv('result1.csv').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b73708",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ2ìœ í˜•] ì „ììƒê±°ë˜ êµ¬ë§¤ ì˜ˆì¸¡\n",
    "ë¬¸ì œ: ì œê³µëœ ê³ ê° ë°ì´í„°(train)ë¥¼ ì´ìš©í•˜ì—¬ ê³ ê°ì´ ìƒí’ˆì„ êµ¬ë§¤í• ì§€(Purchase) ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ê³ , í‰ê°€ìš© ë°ì´í„°(test)ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ result.csv íŒŒì¼ë¡œ ì œì¶œí•˜ì‹œì˜¤.\n",
    "\n",
    "1. ë°ì´í„° ì„¤ëª…\n",
    "\n",
    "Target: Purchase (1: êµ¬ë§¤, 0: ë¹„êµ¬ë§¤)\n",
    "\n",
    "Features:\n",
    "\n",
    "UserID: ê³ ê° ID (ë¶ˆí•„ìš”í•œ ì‹ë³„ì)\n",
    "\n",
    "Age, AnnualIncome, BrowsingTime, PagesViewed: ìˆ˜ì¹˜í˜• ì •ë³´\n",
    "\n",
    "MembershipTier: íšŒì› ë“±ê¸‰ (Bronze, Silver, Gold)\n",
    "\n",
    "DeviceType: ì ‘ì† ê¸°ê¸° (Mobile, Desktop, Tablet)\n",
    "\n",
    "2. ì œì¶œ í˜•ì‹\n",
    "\n",
    "result.csv íŒŒì¼ë¡œ ì €ì¥.\n",
    "\n",
    "**UserID**ì™€ pred ë‘ ê°œì˜ ì»¬ëŸ¼ë§Œ í¬í•¨.\n",
    "\n",
    "pred ì»¬ëŸ¼ì—ëŠ” **êµ¬ë§¤í•  í™•ë¥ (Probability)**ì„ ì œì¶œí•˜ì‹œì˜¤. (0~1 ì‚¬ì´ ê°’)\n",
    "\n",
    "3. í‰ê°€ ì§€í‘œ\n",
    "\n",
    "ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18d8d25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ! (ê²°ì¸¡ì¹˜ ì—†ìŒ)\n",
      "train shape: (2800, 8)\n",
      "test shape: (1200, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2025)\n",
    "n_rows = 4000\n",
    "\n",
    "# 1. ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'UserID': np.arange(10001, 10001 + n_rows),\n",
    "    'Age': np.random.randint(18, 70, n_rows),\n",
    "    'AnnualIncome': np.random.randint(20000, 150000, n_rows),\n",
    "    'BrowsingTime': np.random.normal(30, 10, n_rows), # ë¶„ ë‹¨ìœ„\n",
    "    'PagesViewed': np.random.randint(1, 20, n_rows),\n",
    "    'MembershipTier': np.random.choice(['Bronze', 'Silver', 'Gold'], n_rows, p=[0.5, 0.3, 0.2]),\n",
    "    'DeviceType': np.random.choice(['Mobile', 'Desktop', 'Tablet'], n_rows),\n",
    "    'Purchase': 0 # Target ì´ˆê¸°í™”\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Target ìƒì„± (êµ¬ë§¤ í™•ë¥ : ê³¨ë“œ íšŒì›ì¼ìˆ˜ë¡, ìˆ˜ì…ì´ ë§ì„ìˆ˜ë¡, ë§ì´ ë³¼ìˆ˜ë¡ ë†’ìŒ)\n",
    "logits = -5 + (df['AnnualIncome'] / 50000) + (df['BrowsingTime'] / 20) + (df['PagesViewed'] / 5)\n",
    "logits += np.where(df['MembershipTier'] == 'Gold', 2, 0)\n",
    "logits += np.where(df['MembershipTier'] == 'Silver', 1, 0)\n",
    "probs = 1 / (1 + np.exp(-logits))\n",
    "df['Purchase'] = np.random.binomial(1, probs)\n",
    "\n",
    "# 3. ë°ì´í„° ë¶„ë¦¬\n",
    "X = df.drop('Purchase', axis=1)\n",
    "y = df['Purchase']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ì‹œí—˜ ì œê³µ í˜•íƒœ\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = X_test\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ! (ê²°ì¸¡ì¹˜ ì—†ìŒ)\")\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00ab57ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787\n",
      "      UserID  pred\n",
      "0      10556  0.51\n",
      "1      13492  0.71\n",
      "2      10528  0.99\n",
      "3      13926  0.62\n",
      "4      12990  0.95\n",
      "...      ...   ...\n",
      "1195   13857  0.73\n",
      "1196   10227  0.50\n",
      "1197   11613  0.91\n",
      "1198   10536  0.64\n",
      "1199   13849  0.66\n",
      "\n",
      "[1200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(test.info())\n",
    "# ì œê±°: UserID\n",
    "# ì¸ì½”ë”©: MembershipTier, DeviceType\n",
    "# í™•ë¥  -> classfier\n",
    "\n",
    "X = train.drop(['UserID', 'Purchase'], axis=1)\n",
    "y = train['Purchase']\n",
    "X_submit = test.drop('UserID', axis=1)\n",
    "\n",
    "cols = ['MembershipTier', 'DeviceType']\n",
    "\n",
    "X = pd.get_dummies(X, columns=cols)\n",
    "X_submit = pd.get_dummies(X_submit, columns=cols)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "pred_proba = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "score = roc_auc_score(y_val, pred_proba)\n",
    "print(round(score, 3))\n",
    "\n",
    "model.fit(X, y)\n",
    "pred_proba_final = model.predict_proba(X_submit)[:,1]\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'UserID': test['UserID'],\n",
    "    'pred': pred_proba_final\n",
    "})\n",
    "\n",
    "result.to_csv('result2.csv', index=False)\n",
    "print(pd.read_csv('result2.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45360579",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ3ìœ í˜•] í†µê³„ì  ê°€ì„¤ ê²€ì •\n",
    "ë¬¸ì œ 1. (ëŒ€ì‘í‘œë³¸ t-ê²€ì •) 'Treatment'(íˆ¬ì•½êµ°) ê·¸ë£¹ì— ì†í•œ í™˜ìë“¤ì˜ **íˆ¬ì•½ ì „(BP_Pre)**ê³¼ íˆ¬ì•½ í›„(BP_Post) í˜ˆì•• ì°¨ì´ê°€ ìœ ì˜ë¯¸í•œì§€ ê²€ì •í•˜ë ¤ê³  í•©ë‹ˆë‹¤. (ê°€ì„¤: íˆ¬ì•½ í›„ í˜ˆì••ì´ íˆ¬ì•½ ì „ê³¼ ë‹¤ë¥´ë‹¤.) **ëŒ€ì‘í‘œë³¸ t-ê²€ì •(Paired t-test)**ì„ ìˆ˜í–‰í•˜ê³ , **ê²€ì •í†µê³„ëŸ‰(t-value)**ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •) íˆ¬ì—¬ ê·¸ë£¹(Group)ê³¼ ë¶€ì‘ìš© ë°œìƒ ì—¬ë¶€(Side_Effects)ê°€ ì„œë¡œ ê´€ë ¨ì´ ìˆëŠ”ì§€(ë…ë¦½ì´ ì•„ë‹Œì§€) ê²€ì •í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •ì„ ìˆ˜í–‰í•˜ê³ , **p-ê°’(p-value)**ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ë„·ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ & ì˜¤ì¦ˆë¹„) ì¹˜ë£Œ ì„±ê³µ ì—¬ë¶€(Success)ë¥¼ ì¢…ì†ë³€ìˆ˜ë¡œ í•˜ê³ , Ageì™€ BMIë¥¼ ë…ë¦½ë³€ìˆ˜ë¡œ í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì„ ìˆ˜í–‰í•˜ì‹œì˜¤. ì´ë•Œ **BMI ë³€ìˆ˜ì˜ ì˜¤ì¦ˆë¹„(Odds Ratio)**ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, statsmodelsë¥¼ ì‚¬ìš©í•˜ê³ , ê²°ê³¼ê°’ì€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75ccdee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "   ID      Group  Age        BMI      BP_Pre Side_Effects     BP_Post  Success\n",
      "0   1  Treatment   49  25.536214  115.545523          Yes  107.602568        0\n",
      "1   2  Treatment   75  25.708310  118.339493           No  114.446628        0\n",
      "2   3  Treatment   45  25.510836  115.130393           No  114.998380        0\n",
      "3   4  Treatment   29  27.439367  128.171946           No  125.530657        0\n",
      "4   5  Treatment   32  19.326160  129.338332           No  119.815970        0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n = 300\n",
    "\n",
    "data = {\n",
    "    'ID': range(1, n + 1),\n",
    "    'Group': np.random.choice(['Treatment', 'Control'], n),\n",
    "    'Age': np.random.randint(25, 80, n),\n",
    "    'BMI': np.random.normal(25, 4, n),\n",
    "    'BP_Pre': np.random.normal(130, 10, n),\n",
    "    'Side_Effects': np.random.choice(['Yes', 'No'], n, p=[0.15, 0.85])\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# íˆ¬ì•½ í›„ í˜ˆì•• ìƒì„± (Treatment ê·¸ë£¹ë§Œ í˜ˆì••ì´ ë–¨ì–´ì§€ëŠ” íš¨ê³¼ ë¶€ì—¬)\n",
    "def get_bp_post(row):\n",
    "    change = np.random.normal(-5, 5) if row['Group'] == 'Treatment' else np.random.normal(0, 3)\n",
    "    return row['BP_Pre'] + change\n",
    "\n",
    "df['BP_Post'] = df.apply(get_bp_post, axis=1)\n",
    "\n",
    "# ì¹˜ë£Œ ì„±ê³µ ì—¬ë¶€ (BMIê°€ ë‚®ì„ìˆ˜ë¡, ë‚˜ì´ê°€ ì ì„ìˆ˜ë¡ ì„±ê³µ í™•ë¥  ë†’ìŒ)\n",
    "logits = 2 - 0.1 * df['BMI'] - 0.02 * df['Age'] + np.random.normal(0, 1, n)\n",
    "probs = 1 / (1 + np.exp(-logits))\n",
    "df['Success'] = np.random.binomial(1, probs)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9674ec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.205\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 1\n",
    "target_df = df[df['Group']=='Treatment']\n",
    "before = target_df['BP_Pre']\n",
    "after = target_df['BP_Post']\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "t_stat, p_val = ttest_rel(before, after)\n",
    "print(round(t_stat, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87fb4fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.283\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 2\n",
    "from scipy.stats import chi2_contingency\n",
    "group = df['Group']\n",
    "side_effects = df['Side_Effects']\n",
    "\n",
    "ct = pd.crosstab(group, side_effects)\n",
    "\n",
    "chi2, p_val, ddof, expected = chi2_contingency(ct)\n",
    "print(round(p_val, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5184f4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.465692\n",
      "         Iterations 6\n",
      "0.939\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì œ 3\n",
    "from statsmodels.formula.api import logit\n",
    "model = logit('Success ~ Age + BMI', data=df).fit()\n",
    "#print(model.summary())\n",
    "\n",
    "import numpy as np\n",
    "odds_ratio = np.exp(model.params['BMI'])\n",
    "print(round(odds_ratio, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed132f2",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ3ìœ í˜•] íšŒê·€ë¶„ì„ ì¢…í•© ë¬¸ì œ\n",
    "ë¬¸ì œ 1. (ë‹¤ì¤‘íšŒê·€ë¶„ì„ - OLS) íˆ¬ì•½ í›„ í˜ˆì••(BP_Post)ì„ ì¢…ì†ë³€ìˆ˜ë¡œ í•˜ê³ , íˆ¬ì•½ ì „ í˜ˆì••(BP_Pre), ë‚˜ì´(Age), ì²´ì§ˆëŸ‰ì§€ìˆ˜(BMI)ë¥¼ ë…ë¦½ë³€ìˆ˜ë¡œ í•˜ëŠ” ë‹¤ì¤‘ì„ í˜•íšŒê·€ ëª¨ë¸ì„ ìƒì„±í•˜ì‹œì˜¤. ì´ë•Œ, **BP_Pre (íˆ¬ì•½ ì „ í˜ˆì••)ì˜ íšŒê·€ê³„ìˆ˜(Coefficient)**ë¥¼ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ì†Œìˆ˜ì  ë„·ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ë¡œì§€ìŠ¤í‹± íšŒê·€ - ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ì˜¤ì¦ˆë¹„) ì¹˜ë£Œ ì„±ê³µ ì—¬ë¶€(Success)ë¥¼ ì¢…ì†ë³€ìˆ˜ë¡œ í•˜ê³ , Age, BMI, Groupì„ ë…ë¦½ë³€ìˆ˜ë¡œ í•˜ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ ìƒì„±í•˜ì‹œì˜¤. ì´ë•Œ, 'Treatment'(íˆ¬ì•½êµ°) ê·¸ë£¹ì˜ í™˜ìëŠ” 'Control'(ëŒ€ì¡°êµ°) ê·¸ë£¹ì˜ í™˜ìë³´ë‹¤ ì¹˜ë£Œ ì„±ê³µ ì˜¤ì¦ˆ(Odds)ê°€ ëª‡ ë°°ì¸ì§€(ì˜¤ì¦ˆë¹„) êµ¬í•˜ì‹œì˜¤. (ë‹¨, Controlì„ ê¸°ì¤€(0), Treatmentë¥¼ ë¹„êµ(1)ë¡œ ì²˜ë¦¬í•˜ë©°, ì˜¤ì¦ˆë¹„ëŠ” ì†Œìˆ˜ì  ë„·ì§¸ ìë¦¬ì—ì„œ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (ë¡œì§€ìŠ¤í‹± íšŒê·€ - í™•ë¥  ì˜ˆì¸¡) 2ë²ˆ ë¬¸ì œì—ì„œ ë§Œë“  ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬, ì „ì²´ ë°ì´í„°(df) í™˜ìë“¤ì˜ **ì¹˜ë£Œ ì„±ê³µ í™•ë¥ (Probability)**ì„ ì˜ˆì¸¡í•˜ì‹œì˜¤. ì˜ˆì¸¡ëœ ì¹˜ë£Œ ì„±ê³µ í™•ë¥ ì´ **0.6 ì´ìƒ(>= 0.6)**ì¸ í™˜ìì˜ **ì¸ì›ìˆ˜(ëª…)**ë¥¼ êµ¬í•˜ì‹œì˜¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7edf1e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "   ID      Group  Age        BMI      BP_Pre     BP_Post  Treatment_Code  \\\n",
      "0   1  Treatment   39  30.087421  128.659704  135.787762               1   \n",
      "1   2  Treatment   75  27.065314  128.106733  136.317723               1   \n",
      "2   3  Treatment   73  25.347528  138.199694  144.206251               1   \n",
      "\n",
      "   Success  \n",
      "0        0  \n",
      "1        1  \n",
      "2        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n = 500\n",
    "\n",
    "# ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'ID': range(1, n + 1),\n",
    "    'Group': np.random.choice(['Treatment', 'Control'], n), # íˆ¬ì•½êµ°, ëŒ€ì¡°êµ°\n",
    "    'Age': np.random.randint(25, 80, n),\n",
    "    'BMI': np.random.normal(25, 4, n),\n",
    "    'BP_Pre': np.random.normal(130, 10, n), # íˆ¬ì•½ ì „ í˜ˆì••\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ì¢…ì†ë³€ìˆ˜ ìƒì„± (ì„ í˜• ê´€ê³„)\n",
    "# íˆ¬ì•½ í›„ í˜ˆì•• = íˆ¬ì•½ ì „ * 0.9 + ë‚˜ì´ * 0.1 + BMI * 0.5 - (Treatmentì¸ ê²½ìš° 10)\n",
    "def get_bp_post(row):\n",
    "    effect = -10 if row['Group'] == 'Treatment' else 0\n",
    "    base = row['BP_Pre'] * 0.9 + row['Age'] * 0.1 + row['BMI'] * 0.5 + 10\n",
    "    return base + effect + np.random.normal(0, 2, 1)[0]\n",
    "\n",
    "df['BP_Post'] = df.apply(get_bp_post, axis=1)\n",
    "\n",
    "# ì¢…ì†ë³€ìˆ˜ ìƒì„± (ë¡œì§€ìŠ¤í‹± ê´€ê³„)\n",
    "# Treatmentì¼ ë•Œ ì„±ê³µ í™•ë¥  ì¦ê°€, BMI ë‚®ì„ìˆ˜ë¡ ì„±ê³µ\n",
    "df['Treatment_Code'] = df['Group'].map({'Treatment': 1, 'Control': 0})\n",
    "logits = -2 + 1.5 * df['Treatment_Code'] - 0.1 * df['BMI'] + 0.02 * df['Age']\n",
    "probs = 1 / (1 + np.exp(-logits))\n",
    "df['Success'] = np.random.binomial(1, probs)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9697e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.895\n"
     ]
    }
   ],
   "source": [
    "# 1ë²ˆ ë¬¸ì œ\n",
    "from statsmodels.formula.api import ols\n",
    "model = ols('BP_Post ~ BP_Pre + Age + BMI', data=df).fit()\n",
    "coef = model.params['BP_Pre']\n",
    "print(round(coef, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.208368\n",
      "         Iterations 9\n",
      "19.577\n"
     ]
    }
   ],
   "source": [
    "# 2ë²ˆ ë¬¸ì œ\n",
    "from statsmodels.formula.api import logit\n",
    "model = logit('Success ~ Age + BMI + Group', data=df).fit()\n",
    "coef = model.params['Group[T.Treatment]']\n",
    "# ì„¤ëª… (ìë™ ë”ë¯¸ ë³€ìˆ˜í™” - ë¬¸ìì—´)\n",
    "odds_ratio = np.exp(coef)\n",
    "print(round(odds_ratio, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 3ë²ˆ ë¬¸ì œ - ì™¸ìš°ê¸°\n",
    "pred_proba = model.predict(df)\n",
    "target = pred_proba[pred_proba >= 0.6]\n",
    "result = len(target)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3eda20",
   "metadata": {},
   "source": [
    "ğŸ“ [ì œ3ìœ í˜•] ë¶„ì‚°ë¶„ì„í‘œ (ANOVA Table) í•´ì„\n",
    "ë¬¸ì œ 1. (ANOVA ëª¨ë¸ ì í•©) ì‹ì´ìš”ë²• ìœ í˜•(Diet)ì— ë”°ë¥¸ ì²´ì¤‘ ê°ëŸ‰(Weight_Loss)ì˜ ì°¨ì´ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•´, ols í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ ìƒì„±í•˜ê³  ì í•©(fit)ì‹œí‚¤ì‹œì˜¤. ìƒì„±ëœ ëª¨ë¸ ê°ì²´ë¥¼ ì´ìš©í•˜ì—¬ anova_lm í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ í…Œì´ë¸”ì—ì„œ **Diet ë³€ìˆ˜ì˜ F-í†µê³„ëŸ‰(F-value)**ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 2. (ì”ì°¨ ì œê³±í•© - SSE) 1ë²ˆì—ì„œ êµ¬í•œ ë¶„ì‚°ë¶„ì„í‘œ(ANOVA Table)ë¥¼ í™•ì¸í•˜ì—¬, ì„¤ëª…ë˜ì§€ ì•ŠëŠ” ë³€ë™ì¸ **ì”ì°¨(Residual)ì˜ ì œê³±í•©(Sum of Squares)**ì„ êµ¬í•˜ì‹œì˜¤. (ë‹¨, ë°˜ì˜¬ë¦¼í•˜ì—¬ ì†Œìˆ˜ ì…‹ì§¸ ìë¦¬ê¹Œì§€ ì¶œë ¥í•˜ì‹œì˜¤.)\n",
    "\n",
    "ë¬¸ì œ 3. (p-value í•´ì„) ë¶„ì‚°ë¶„ì„ ê²°ê³¼ì˜ **p-ê°’(PR(>F))**ì„ êµ¬í•˜ê³ , ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì—ì„œ ê·€ë¬´ê°€ì„¤(ì„¸ ê·¸ë£¹ì˜ í‰ê· ì€ ê°™ë‹¤)ì„ ê¸°ê°í•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨í•˜ì‹œì˜¤. (p-ê°’ì€ ì†Œìˆ˜ ë„·ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ì—¬ ì¶œë ¥í•˜ê³ , ê¸°ê° ì—¬ë¶€ëŠ” \"ê¸°ê°\" ë˜ëŠ” \"ì±„íƒ\"ìœ¼ë¡œ ì¶œë ¥í•˜ì‹œì˜¤. ì •ë‹µ ì˜ˆì‹œ: 0.0123 ê¸°ê°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f7434c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ!\n",
      "   ID    Diet  Weight_Loss\n",
      "0   1  Type_C     6.616633\n",
      "1   2  Type_C     5.644096\n",
      "2   3  Type_C     6.007296\n",
      "3   4  Type_C     3.862329\n",
      "4   5  Type_A     2.226040\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2025)\n",
    "n = 150\n",
    "\n",
    "# ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'ID': range(1, n + 1),\n",
    "    'Diet': np.random.choice(['Type_A', 'Type_B', 'Type_C'], n),\n",
    "    'Weight_Loss': np.zeros(n)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ê·¸ë£¹ë³„ íš¨ê³¼ ë¶€ì—¬ (C > B > A ìˆœìœ¼ë¡œ ê°ëŸ‰ íš¨ê³¼ í¼)\n",
    "def get_weight_loss(diet):\n",
    "    base = np.random.normal(2, 1) # ê¸°ë³¸ ê°ëŸ‰\n",
    "    if diet == 'Type_B': return base + 2  # BëŠ” +2kg ë” ê°ëŸ‰\n",
    "    elif diet == 'Type_C': return base + 4 # CëŠ” +4kg ë” ê°ëŸ‰\n",
    "    else: return base # AëŠ” ê¸°ë³¸\n",
    "\n",
    "df['Weight_Loss'] = df['Diet'].apply(get_weight_loss)\n",
    "\n",
    "print(\"ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cc46efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             df      sum_sq     mean_sq          F        PR(>F)\n",
      "C(Diet)     2.0  433.580080  216.790040  238.35233  7.359841e-47\n",
      "Residual  147.0  133.701801    0.909536        NaN           NaN\n",
      "238.352\n",
      "133.702\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "model = ols('Weight_Loss ~C(Diet)', data=df).fit()\n",
    "anova_table = anova_lm(model)\n",
    "print(anova_table)\n",
    "\n",
    "f_stat = anova_table.loc['C(Diet)', 'F']\n",
    "print(round(f_stat, 3))\n",
    "\n",
    "sse = anova_table.loc['Residual', 'sum_sq']\n",
    "print(round(sse, 3))\n",
    "\n",
    "p_val = anova_table.loc['C(Diet)', 'PR(>F)']\n",
    "print(round(p_val, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
